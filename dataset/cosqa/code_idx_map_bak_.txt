{
"def is_iterable_but_not_string(obj):\n    \"\"\"\n    Determine whether or not obj is iterable but not a string (eg, a list, set, tuple etc).\n    \"\"\"\n    return hasattr(obj, '__iter__') and not isinstance(obj, str) and not isinstance(obj, bytes)": 1640,
"def make_file_readable (filename):\n    \"\"\"Make file user readable if it is not a link.\"\"\"\n    if not os.path.islink(filename):\n        util.set_mode(filename, stat.S_IRUSR)": 4294,
"def apply(filter):\n    \"\"\"Manufacture decorator that filters return value with given function.\n\n    ``filter``:\n      Callable that takes a single parameter.\n    \"\"\"\n    def decorator(callable):\n        return lambda *args, **kwargs: filter(callable(*args, **kwargs))\n    return decorator": 5176,
"def ensure_newline(self):\n        \"\"\"\n        use before any custom printing when using the progress iter to ensure\n        your print statement starts on a new line instead of at the end of a\n        progress line\n        \"\"\"\n        DECTCEM_SHOW = '\\033[?25h'  # show cursor\n        AT_END = DECTCEM_SHOW + '\\n'\n        if not self._cursor_at_newline:\n            self.write(AT_END)\n            self._cursor_at_newline = True": 3812,
"def variance(arr):\n  \"\"\"variance of the values, must have 2 or more entries.\n\n  :param arr: list of numbers\n  :type arr: number[] a number array\n  :return: variance\n  :rtype: float\n\n  \"\"\"\n  avg = average(arr)\n  return sum([(float(x)-avg)**2 for x in arr])/float(len(arr)-1)": 2108,
"def is_bool_matrix(l):\n    r\"\"\"Checks if l is a 2D numpy array of bools\n\n    \"\"\"\n    if isinstance(l, np.ndarray):\n        if l.ndim == 2 and (l.dtype == bool):\n            return True\n    return False": 1574,
"def is_integer_array(val):\n    \"\"\"\n    Checks whether a variable is a numpy integer array.\n\n    Parameters\n    ----------\n    val\n        The variable to check.\n\n    Returns\n    -------\n    bool\n        True if the variable is a numpy integer array. Otherwise False.\n\n    \"\"\"\n    return is_np_array(val) and issubclass(val.dtype.type, np.integer)": 2675,
"def rrmdir(directory):\n    \"\"\"\n    Recursivly delete a directory\n\n    :param directory: directory to remove\n    \"\"\"\n    for root, dirs, files in os.walk(directory, topdown=False):\n        for name in files:\n            os.remove(os.path.join(root, name))\n        for name in dirs:\n            os.rmdir(os.path.join(root, name))\n    os.rmdir(directory)": 1013,
"def values(self):\n        \"\"\"Gets the user enter max and min values of where the \n        raster points should appear on the y-axis\n\n        :returns: (float, float) -- (min, max) y-values to bound the raster plot by\n        \"\"\"\n        lower = float(self.lowerSpnbx.value())\n        upper = float(self.upperSpnbx.value())\n        return (lower, upper)": 314,
"def list_formatter(handler, item, value):\n    \"\"\"Format list.\"\"\"\n    return u', '.join(str(v) for v in value)": 892,
"def distinct(xs):\n    \"\"\"Get the list of distinct values with preserving order.\"\"\"\n    # don't use collections.OrderedDict because we do support Python 2.6\n    seen = set()\n    return [x for x in xs if x not in seen and not seen.add(x)]": 714,
"def graph_from_dot_file(path):\n    \"\"\"Load graph as defined by a DOT file.\n    \n    The file is assumed to be in DOT format. It will\n    be loaded, parsed and a Dot class will be returned, \n    representing the graph.\n    \"\"\"\n    \n    fd = file(path, 'rb')\n    data = fd.read()\n    fd.close()\n    \n    return graph_from_dot_data(data)": 2908,
"def butlast(iterable):\n    \"\"\"Yield all items from ``iterable`` except the last one.\n\n    >>> list(butlast(['spam', 'eggs', 'ham']))\n    ['spam', 'eggs']\n\n    >>> list(butlast(['spam']))\n    []\n\n    >>> list(butlast([]))\n    []\n    \"\"\"\n    iterable = iter(iterable)\n    try:\n        first = next(iterable)\n    except StopIteration:\n        return\n    for second in iterable:\n        yield first\n        first = second": 5721,
"def _read_stream_for_size(stream, buf_size=65536):\n    \"\"\"Reads a stream discarding the data read and returns its size.\"\"\"\n    size = 0\n    while True:\n        buf = stream.read(buf_size)\n        size += len(buf)\n        if not buf:\n            break\n    return size": 3708,
"def s3_get(url: str, temp_file: IO) -> None:\n    \"\"\"Pull a file directly from S3.\"\"\"\n    s3_resource = boto3.resource(\"s3\")\n    bucket_name, s3_path = split_s3_path(url)\n    s3_resource.Bucket(bucket_name).download_fileobj(s3_path, temp_file)": 5656,
"def Proxy(f):\n  \"\"\"A helper to create a proxy method in a class.\"\"\"\n\n  def Wrapped(self, *args):\n    return getattr(self, f)(*args)\n\n  return Wrapped": 577,
"def is_float(value):\n    \"\"\"must be a float\"\"\"\n    return isinstance(value, float) or isinstance(value, int) or isinstance(value, np.float64), float(value)": 772,
"def cross_join(df1, df2):\n    \"\"\"\n    Return a dataframe that is a cross between dataframes\n    df1 and df2\n\n    ref: https://github.com/pydata/pandas/issues/5401\n    \"\"\"\n    if len(df1) == 0:\n        return df2\n\n    if len(df2) == 0:\n        return df1\n\n    # Add as lists so that the new index keeps the items in\n    # the order that they are added together\n    all_columns = pd.Index(list(df1.columns) + list(df2.columns))\n    df1['key'] = 1\n    df2['key'] = 1\n    return pd.merge(df1, df2, on='key').loc[:, all_columns]": 793,
"def cli_run():\n    \"\"\"docstring for argparse\"\"\"\n    parser = argparse.ArgumentParser(description='Stupidly simple code answers from StackOverflow')\n    parser.add_argument('query', help=\"What's the problem ?\", type=str, nargs='+')\n    parser.add_argument('-t','--tags', help='semicolon separated tags -> python;lambda')\n    args = parser.parse_args()\n    main(args)": 5600,
"def setdefault(obj, field, default):\n    \"\"\"Set an object's field to default if it doesn't have a value\"\"\"\n    setattr(obj, field, getattr(obj, field, default))": 1500,
"def unique(seq):\n    \"\"\"Return the unique elements of a collection even if those elements are\n       unhashable and unsortable, like dicts and sets\"\"\"\n    cleaned = []\n    for each in seq:\n        if each not in cleaned:\n            cleaned.append(each)\n    return cleaned": 581,
"def clean_int(x) -> int:\n    \"\"\"\n    Returns its parameter as an integer, or raises\n    ``django.forms.ValidationError``.\n    \"\"\"\n    try:\n        return int(x)\n    except ValueError:\n        raise forms.ValidationError(\n            \"Cannot convert to integer: {}\".format(repr(x)))": 5836,
"def contains_empty(features):\n    \"\"\"Check features data are not empty\n\n    :param features: The features data to check.\n    :type features: list of numpy arrays.\n\n    :return: True if one of the array is empty, False else.\n\n    \"\"\"\n    if not features:\n        return True\n    for feature in features:\n        if feature.shape[0] == 0:\n            return True\n    return False": 847,
"def _go_to_line(editor, line):\n    \"\"\"\n    Move cursor to this line in the current buffer.\n    \"\"\"\n    b = editor.application.current_buffer\n    b.cursor_position = b.document.translate_row_col_to_index(max(0, int(line) - 1), 0)": 814,
"def test_value(self, value):\n        \"\"\"Test if value is an instance of int.\"\"\"\n        if not isinstance(value, int):\n            raise ValueError('expected int value: ' + str(type(value)))": 4573,
"def truncate(value: Decimal, n_digits: int) -> Decimal:\n    \"\"\"Truncates a value to a number of decimals places\"\"\"\n    return Decimal(math.trunc(value * (10 ** n_digits))) / (10 ** n_digits)": 5704,
"def add_exec_permission_to(target_file):\n    \"\"\"Add executable permissions to the file\n\n    :param target_file: the target file whose permission to be changed\n    \"\"\"\n    mode = os.stat(target_file).st_mode\n    os.chmod(target_file, mode | stat.S_IXUSR)": 2659,
"def _manhattan_distance(vec_a, vec_b):\n    \"\"\"Return manhattan distance between two lists of numbers.\"\"\"\n    if len(vec_a) != len(vec_b):\n        raise ValueError('len(vec_a) must equal len(vec_b)')\n    return sum(map(lambda a, b: abs(a - b), vec_a, vec_b))": 1828,
"def dag_longest_path(graph, source, target):\n    \"\"\"\n    Finds the longest path in a dag between two nodes\n    \"\"\"\n    if source == target:\n        return [source]\n    allpaths = nx.all_simple_paths(graph, source, target)\n    longest_path = []\n    for l in allpaths:\n        if len(l) > len(longest_path):\n            longest_path = l\n    return longest_path": 5910,
"def getpackagepath():\n    \"\"\"\n     *Get the root path for this python package - used in unit testing code*\n    \"\"\"\n    moduleDirectory = os.path.dirname(__file__)\n    packagePath = os.path.dirname(__file__) + \"/../\"\n\n    return packagePath": 1712,
"def to_bin(data, width):\n    \"\"\"\n    Convert an unsigned integer to a numpy binary array with the first\n    element the MSB and the last element the LSB.\n    \"\"\"\n    data_str = bin(data & (2**width-1))[2:].zfill(width)\n    return [int(x) for x in tuple(data_str)]": 4059,
"def __remove_trailing_zeros(self, collection):\n        \"\"\"Removes trailing zeroes from indexable collection of numbers\"\"\"\n        index = len(collection) - 1\n        while index >= 0 and collection[index] == 0:\n            index -= 1\n\n        return collection[:index + 1]": 5636,
"def fix(h, i):\n    \"\"\"Rearrange the heap after the item at position i got updated.\"\"\"\n    down(h, i, h.size())\n    up(h, i)": 3468,
"def crop_box(im, box=False, **kwargs):\n    \"\"\"Uses box coordinates to crop an image without resizing it first.\"\"\"\n    if box:\n        im = im.crop(box)\n    return im": 613,
"def _linear_interpolation(x, X, Y):\n    \"\"\"Given two data points [X,Y], linearly interpolate those at x.\n    \"\"\"\n    return (Y[1] * (x - X[0]) + Y[0] * (X[1] - x)) / (X[1] - X[0])": 1490,
"def is_numeric_dtype(dtype):\n    \"\"\"Return ``True`` if ``dtype`` is a numeric type.\"\"\"\n    dtype = np.dtype(dtype)\n    return np.issubsctype(getattr(dtype, 'base', None), np.number)": 3424,
"def delimited(items, character='|'):\n    \"\"\"Returns a character delimited version of the provided list as a Python string\"\"\"\n    return '|'.join(items) if type(items) in (list, tuple, set) else items": 1295,
"def json_iter (path):\n    \"\"\"\n    iterator for JSON-per-line in a file pattern\n    \"\"\"\n    with open(path, 'r') as f:\n        for line in f.readlines():\n            yield json.loads(line)": 983,
"def is_valid(number):\n    \"\"\"determines whether the card number is valid.\"\"\"\n    n = str(number)\n    if not n.isdigit():\n        return False\n    return int(n[-1]) == get_check_digit(n[:-1])": 357,
"def isbinary(*args):\n    \"\"\"Checks if value can be part of binary/bitwise operations.\"\"\"\n    return all(map(lambda c: isnumber(c) or isbool(c), args))": 371,
"def rm_empty_indices(*args):\n    \"\"\"\n    Remove unwanted list indices. First argument is the list\n    of indices to remove. Other elements are the lists\n    to trim.\n    \"\"\"\n    rm_inds = args[0]\n\n    if not rm_inds:\n        return args[1:]\n\n    keep_inds = [i for i in range(len(args[1])) if i not in rm_inds]\n\n    return [[a[i] for i in keep_inds] for a in args[1:]]": 841,
"def clear_instance(cls):\n        \"\"\"unset _instance for this class and singleton parents.\n        \"\"\"\n        if not cls.initialized():\n            return\n        for subclass in cls._walk_mro():\n            if isinstance(subclass._instance, cls):\n                # only clear instances that are instances\n                # of the calling class\n                subclass._instance = None": 4238,
"def stderr(a):\n    \"\"\"\n    Calculate the standard error of a.\n    \"\"\"\n    return np.nanstd(a) / np.sqrt(sum(np.isfinite(a)))": 715,
"def __init__(self, capacity=10):\n        \"\"\"\n        Initialize python List with capacity of 10 or user given input.\n        Python List type is a dynamic array, so we have to restrict its\n        dynamic nature to make it work like a static array.\n        \"\"\"\n        super().__init__()\n        self._array = [None] * capacity\n        self._front = 0\n        self._rear = 0": 3243,
"def login(self, user: str, passwd: str) -> None:\n        \"\"\"Log in to instagram with given username and password and internally store session object.\n\n        :raises InvalidArgumentException: If the provided username does not exist.\n        :raises BadCredentialsException: If the provided password is wrong.\n        :raises ConnectionException: If connection to Instagram failed.\n        :raises TwoFactorAuthRequiredException: First step of 2FA login done, now call :meth:`Instaloader.two_factor_login`.\"\"\"\n        self.context.login(user, passwd)": 6158,
"def get_shape(img):\n    \"\"\"Return the shape of img.\n\n    Paramerers\n    -----------\n    img:\n\n    Returns\n    -------\n    shape: tuple\n    \"\"\"\n    if hasattr(img, 'shape'):\n        shape = img.shape\n    else:\n        shape = img.get_data().shape\n    return shape": 2021,
"def rotateImage(image, angle):\n    \"\"\"\n        rotates a 2d array to a multiple of 90 deg.\n        0 = default\n        1 = 90 deg. cw\n        2 = 180 deg.\n        3 = 90 deg. ccw\n    \"\"\"\n    image = [list(row) for row in image]\n\n    for n in range(angle % 4):\n        image = list(zip(*image[::-1]))\n\n    return image": 1993,
"def staticdir():\n    \"\"\"Return the location of the static data directory.\"\"\"\n    root = os.path.abspath(os.path.dirname(__file__))\n    return os.path.join(root, \"static\")": 1813,
"def add_chart(self, chart, row, col):\n        \"\"\"\n        Adds a chart to the worksheet at (row, col).\n\n        :param xltable.Chart Chart: chart to add to the workbook.\n        :param int row: Row to add the chart at.\n        \"\"\"\n        self.__charts.append((chart, (row, col)))": 4433,
"def from_series(cls, series):\n        \"\"\"Convert a pandas.Series into an xarray.DataArray.\n\n        If the series's index is a MultiIndex, it will be expanded into a\n        tensor product of one-dimensional coordinates (filling in missing\n        values with NaN). Thus this operation should be the inverse of the\n        `to_series` method.\n        \"\"\"\n        # TODO: add a 'name' parameter\n        name = series.name\n        df = pd.DataFrame({name: series})\n        ds = Dataset.from_dataframe(df)\n        return ds[name]": 3319,
"def genfirstvalues(cursor: Cursor, arraysize: int = 1000) \\\n        -> Generator[Any, None, None]:\n    \"\"\"\n    Generate the first value in each row.\n\n    Args:\n        cursor: the cursor\n        arraysize: split fetches into chunks of this many records\n\n    Yields:\n        the first value of each row\n    \"\"\"\n    return (row[0] for row in genrows(cursor, arraysize))": 5650,
"def contains(self, token: str) -> bool:\n        \"\"\"Return if the token is in the list or not.\"\"\"\n        self._validate_token(token)\n        return token in self": 5789,
"def sem(inlist):\n    \"\"\"\nReturns the estimated standard error of the mean (sx-bar) of the\nvalues in the passed list.  sem = stdev / sqrt(n)\n\nUsage:   lsem(inlist)\n\"\"\"\n    sd = stdev(inlist)\n    n = len(inlist)\n    return sd / math.sqrt(n)": 2315,
"def get(key, default=None):\n    \"\"\" return the key from the request\n    \"\"\"\n    data = get_form() or get_query_string()\n    return data.get(key, default)": 1873,
"def use_kwargs(self, *args, **kwargs) -> typing.Callable:\n        \"\"\"Decorator that injects parsed arguments into a view function or method.\n\n        Receives the same arguments as `webargs.core.Parser.use_kwargs`.\n\n        \"\"\"\n        return super().use_kwargs(*args, **kwargs)": 6175,
"def _check_whitespace(string):\n    \"\"\"\n    Make sure thre is no whitespace in the given string. Will raise a\n    ValueError if whitespace is detected\n    \"\"\"\n    if string.count(' ') + string.count('\\t') + string.count('\\n') > 0:\n        raise ValueError(INSTRUCTION_HAS_WHITESPACE)": 5747,
"def eof(fd):\n    \"\"\"Determine if end-of-file is reached for file fd.\"\"\"\n    b = fd.read(1)\n    end = len(b) == 0\n    if not end:\n        curpos = fd.tell()\n        fd.seek(curpos - 1)\n    return end": 2556,
"def clear_globals_reload_modules(self):\n        \"\"\"Clears globals and reloads modules\"\"\"\n\n        self.code_array.clear_globals()\n        self.code_array.reload_modules()\n\n        # Clear result cache\n        self.code_array.result_cache.clear()": 1680,
"def raw_connection_from(engine_or_conn):\n    \"\"\"Extract a raw_connection and determine if it should be automatically closed.\n\n    Only connections opened by this package will be closed automatically.\n    \"\"\"\n    if hasattr(engine_or_conn, 'cursor'):\n        return engine_or_conn, False\n    if hasattr(engine_or_conn, 'connection'):\n        return engine_or_conn.connection, False\n    return engine_or_conn.raw_connection(), True": 2143,
"def selectnone(table, field, complement=False):\n    \"\"\"Select rows where the given field is `None`.\"\"\"\n\n    return select(table, field, lambda v: v is None, complement=complement)": 670,
"def axes_off(ax):\n    \"\"\"Get rid of all axis ticks, lines, etc.\n    \"\"\"\n    ax.set_frame_on(False)\n    ax.axes.get_yaxis().set_visible(False)\n    ax.axes.get_xaxis().set_visible(False)": 2111,
"def is_defined(self, objtxt, force_import=False):\n        \"\"\"Return True if object is defined\"\"\"\n        return self.interpreter.is_defined(objtxt, force_import)": 202,
"def filter_query_string(query):\n    \"\"\"\n        Return a version of the query string with the _e, _k and _s values\n        removed.\n    \"\"\"\n    return '&'.join([q for q in query.split('&')\n        if not (q.startswith('_k=') or q.startswith('_e=') or q.startswith('_s'))])": 2871,
"def get_timezone() -> Tuple[datetime.tzinfo, str]:\n    \"\"\"Discover the current time zone and it's standard string representation (for source{d}).\"\"\"\n    dt = get_datetime_now().astimezone()\n    tzstr = dt.strftime(\"%z\")\n    tzstr = tzstr[:-2] + \":\" + tzstr[-2:]\n    return dt.tzinfo, tzstr": 5552,
"def normalise_string(string):\n    \"\"\" Strips trailing whitespace from string, lowercases it and replaces\n        spaces with underscores\n    \"\"\"\n    string = (string.strip()).lower()\n    return re.sub(r'\\W+', '_', string)": 1117,
"def transpose(table):\n    \"\"\"\n    transpose matrix\n    \"\"\"\n    t = []\n    for i in range(0, len(table[0])):\n        t.append([row[i] for row in table])\n    return t": 2681,
"def is_same_shape(self, other_im, check_channels=False):\n        \"\"\" Checks if two images have the same height and width (and optionally channels).\n\n        Parameters\n        ----------\n        other_im : :obj:`Image`\n            image to compare\n        check_channels : bool\n            whether or not to check equality of the channels\n\n        Returns\n        -------\n        bool\n            True if the images are the same shape, False otherwise\n        \"\"\"\n        if self.height == other_im.height and self.width == other_im.width:\n            if check_channels and self.channels != other_im.channels:\n                return False\n            return True\n        return False": 205,
"def is_identifier(string):\n    \"\"\"Check if string could be a valid python identifier\n\n    :param string: string to be tested\n    :returns: True if string can be a python identifier, False otherwise\n    :rtype: bool\n    \"\"\"\n    matched = PYTHON_IDENTIFIER_RE.match(string)\n    return bool(matched) and not keyword.iskeyword(string)": 167,
"def remove_hop_by_hop_headers(headers):\n    \"\"\"Remove all HTTP/1.1 \"Hop-by-Hop\" headers from a list or\n    :class:`Headers` object.  This operation works in-place.\n\n    .. versionadded:: 0.5\n\n    :param headers: a list or :class:`Headers` object.\n    \"\"\"\n    headers[:] = [\n        (key, value) for key, value in headers if not is_hop_by_hop_header(key)\n    ]": 3548,
"def coerce(self, value):\n        \"\"\"Convert from whatever is given to a list of scalars for the lookup_field.\"\"\"\n        if isinstance(value, dict):\n            value = [value]\n        if not isiterable_notstring(value):\n            value = [value]\n        return [coerce_single_instance(self.lookup_field, v) for v in value]": 1216,
"def rlognormal(mu, tau, size=None):\n    \"\"\"\n    Return random lognormal variates.\n    \"\"\"\n\n    return np.random.lognormal(mu, np.sqrt(1. / tau), size)": 551,
"def on_train_end(self, logs):\n        \"\"\" Print training time at end of training \"\"\"\n        duration = timeit.default_timer() - self.train_start\n        print('done, took {:.3f} seconds'.format(duration))": 4162,
"def guess_title(basename):\n    \"\"\" Attempt to guess the title from the filename \"\"\"\n\n    base, _ = os.path.splitext(basename)\n    return re.sub(r'[ _-]+', r' ', base).title()": 3790,
"def log_no_newline(self, msg):\n      \"\"\" print the message to the predefined log file without newline \"\"\"\n      self.print2file(self.logfile, False, False, msg)": 2091,
"def read_text_from_file(path: str) -> str:\n    \"\"\" Reads text file contents \"\"\"\n    with open(path) as text_file:\n        content = text_file.read()\n\n    return content": 5554,
"def remove_duplicates(lst):\n    \"\"\"\n    Emulate what a Python ``set()`` does, but keeping the element's order.\n    \"\"\"\n    dset = set()\n    return [l for l in lst if l not in dset and not dset.add(l)]": 278,
"def computeDelaunayTriangulation(points):\n    \"\"\" Takes a list of point objects (which must have x and y fields).\n        Returns a list of 3-tuples: the indices of the points that form a\n        Delaunay triangle.\n    \"\"\"\n    siteList = SiteList(points)\n    context  = Context()\n    context.triangulate = True\n    voronoi(siteList,context)\n    return context.triangles": 386,
"def is_string_dtype(arr_or_dtype):\n    \"\"\"\n    Check whether the provided array or dtype is of the string dtype.\n\n    Parameters\n    ----------\n    arr_or_dtype : array-like\n        The array or dtype to check.\n\n    Returns\n    -------\n    boolean\n        Whether or not the array or dtype is of the string dtype.\n\n    Examples\n    --------\n    >>> is_string_dtype(str)\n    True\n    >>> is_string_dtype(object)\n    True\n    >>> is_string_dtype(int)\n    False\n    >>>\n    >>> is_string_dtype(np.array(['a', 'b']))\n    True\n    >>> is_string_dtype(pd.Series([1, 2]))\n    False\n    \"\"\"\n\n    # TODO: gh-15585: consider making the checks stricter.\n    def condition(dtype):\n        return dtype.kind in ('O', 'S', 'U') and not is_period_dtype(dtype)\n    return _is_dtype(arr_or_dtype, condition)": 6152,
"def to_str(obj):\n    \"\"\"Attempts to convert given object to a string object\n    \"\"\"\n    if not isinstance(obj, str) and PY3 and isinstance(obj, bytes):\n        obj = obj.decode('utf-8')\n    return obj if isinstance(obj, string_types) else str(obj)": 2806,
"def dedupe_list(seq):\n    \"\"\"\n    Utility function to remove duplicates from a list\n    :param seq: The sequence (list) to deduplicate\n    :return: A list with original duplicates removed\n    \"\"\"\n    seen = set()\n    return [x for x in seq if not (x in seen or seen.add(x))]": 1450,
"def smooth_array(array, amount=1):\n    \"\"\"\n\n    Returns the nearest-neighbor (+/- amount) smoothed array.\n    This does not modify the array or slice off the funny end points.\n\n    \"\"\"\n    if amount==0: return array\n\n    # we have to store the old values in a temp array to keep the\n    # smoothing from affecting the smoothing\n    new_array = _n.array(array)\n\n    for n in range(len(array)):\n        new_array[n] = smooth(array, n, amount)\n\n    return new_array": 2378,
"def get_case_insensitive_dict_key(d: Dict, k: str) -> Optional[str]:\n    \"\"\"\n    Within the dictionary ``d``, find a key that matches (in case-insensitive\n    fashion) the key ``k``, and return it (or ``None`` if there isn't one).\n    \"\"\"\n    for key in d.keys():\n        if k.lower() == key.lower():\n            return key\n    return None": 5951,
"def sort_func(self, key):\n        \"\"\"Sorting logic for `Quantity` objects.\"\"\"\n        if key == self._KEYS.VALUE:\n            return 'aaa'\n        if key == self._KEYS.SOURCE:\n            return 'zzz'\n        return key": 3265,
"def _index_ordering(redshift_list):\n        \"\"\"\n\n        :param redshift_list: list of redshifts\n        :return: indexes in acending order to be evaluated (from z=0 to z=z_source)\n        \"\"\"\n        redshift_list = np.array(redshift_list)\n        sort_index = np.argsort(redshift_list)\n        return sort_index": 2034,
"def cprint(string, fg=None, bg=None, end='\\n', target=sys.stdout):\n    \"\"\"Print a colored string to the target handle.\n\n    fg and bg specify foreground- and background colors, respectively. The\n    remaining keyword arguments are the same as for Python's built-in print\n    function. Colors are returned to their defaults before the function\n    returns.\n\n    \"\"\"\n    _color_manager.set_color(fg, bg)\n    target.write(string + end)\n    target.flush()  # Needed for Python 3.x\n    _color_manager.set_defaults()": 1026,
"def indexes_equal(a: Index, b: Index) -> bool:\n    \"\"\"\n    Are two indexes equal? Checks by comparing ``str()`` versions of them.\n    (AM UNSURE IF THIS IS ENOUGH.)\n    \"\"\"\n    return str(a) == str(b)": 5584,
"def is_readable(filename):\n    \"\"\"Check if file is a regular file and is readable.\"\"\"\n    return os.path.isfile(filename) and os.access(filename, os.R_OK)": 2445,
"def ln_norm(x, mu, sigma=1.0):\n    \"\"\" Natural log of scipy norm function truncated at zero \"\"\"\n    return np.log(stats.norm(loc=mu, scale=sigma).pdf(x))": 1336,
"def ensure_dir(f):\n    \"\"\" Ensure a a file exists and if not make the relevant path \"\"\"\n    d = os.path.dirname(f)\n    if not os.path.exists(d):\n        os.makedirs(d)": 3678,
"def redirect_output(fileobj):\n    \"\"\"Redirect standard out to file.\"\"\"\n    old = sys.stdout\n    sys.stdout = fileobj\n    try:\n        yield fileobj\n    finally:\n        sys.stdout = old": 1485,
"def close_database_session(session):\n    \"\"\"Close connection with the database\"\"\"\n\n    try:\n        session.close()\n    except OperationalError as e:\n        raise DatabaseError(error=e.orig.args[1], code=e.orig.args[0])": 4030,
"def parse_cookies(self, req, name, field):\n        \"\"\"Pull the value from the cookiejar.\"\"\"\n        return core.get_value(req.COOKIES, name, field)": 3111,
"def save(self, fname):\n        \"\"\" Saves the dictionary in json format\n        :param fname: file to save to\n        \"\"\"\n        with open(fname, 'wb') as f:\n            json.dump(self, f)": 686,
"def redirect_stdout(new_stdout):\n    \"\"\"Redirect the stdout\n\n    Args:\n        new_stdout (io.StringIO): New stdout to use instead\n    \"\"\"\n    old_stdout, sys.stdout = sys.stdout, new_stdout\n    try:\n        yield None\n    finally:\n        sys.stdout = old_stdout": 1386,
"def command_py2to3(args):\n    \"\"\"\n    Apply '2to3' tool (Python2 to Python3 conversion tool) to Python sources.\n    \"\"\"\n    from lib2to3.main import main\n    sys.exit(main(\"lib2to3.fixes\", args=args.sources))": 1469,
"def _skip_section(self):\n        \"\"\"Skip a section\"\"\"\n        self._last = self._f.readline()\n        while len(self._last) > 0 and len(self._last[0].strip()) == 0:\n            self._last = self._f.readline()": 5576,
"def get_git_branch(git_path='git'):\n    \"\"\"Returns the name of the current git branch\n    \"\"\"\n    branch_match = call((git_path, 'rev-parse', '--symbolic-full-name', 'HEAD'))\n    if branch_match == \"HEAD\":\n        return None\n    else:\n        return os.path.basename(branch_match)": 1869,
"def check_auth(email, password):\n    \"\"\"Check if a username/password combination is valid.\n    \"\"\"\n    try:\n        user = User.get(User.email == email)\n    except User.DoesNotExist:\n        return False\n    return password == user.password": 3593,
"def _read_date_from_string(str1):\n    \"\"\"\n    Reads the date from a string in the format YYYY/MM/DD and returns\n    :class: datetime.date\n    \"\"\"\n    full_date = [int(x) for x in str1.split('/')]\n    return datetime.date(full_date[0], full_date[1], full_date[2])": 571,
"def find_le(a, x):\n    \"\"\"Find rightmost value less than or equal to x.\"\"\"\n    i = bs.bisect_right(a, x)\n    if i: return i - 1\n    raise ValueError": 612,
"def write_line(self, line, count=1):\n        \"\"\"writes the line and count newlines after the line\"\"\"\n        self.write(line)\n        self.write_newlines(count)": 2415,
"def is_int(value):\n    \"\"\"Return `True` if ``value`` is an integer.\"\"\"\n    if isinstance(value, bool):\n        return False\n    try:\n        int(value)\n        return True\n    except (ValueError, TypeError):\n        return False": 637,
"def ma(self):\n        \"\"\"Represent data as a masked array.\n\n        The array is returned with column-first indexing, i.e. for a data file with\n        columns X Y1 Y2 Y3 ... the array a will be a[0] = X, a[1] = Y1, ... .\n\n        inf and nan are filtered via :func:`numpy.isfinite`.\n        \"\"\"\n        a = self.array\n        return numpy.ma.MaskedArray(a, mask=numpy.logical_not(numpy.isfinite(a)))": 861,
"def isetdiff_flags(list1, list2):\n    \"\"\"\n    move to util_iter\n    \"\"\"\n    set2 = set(list2)\n    return (item not in set2 for item in list1)": 281,
"def text(value, encoding=\"utf-8\", errors=\"strict\"):\n    \"\"\"Convert a value to str on Python 3 and unicode on Python 2.\"\"\"\n    if isinstance(value, text_type):\n        return value\n    elif isinstance(value, bytes):\n        return text_type(value, encoding, errors)\n    else:\n        return text_type(value)": 4478,
"def filter_dict(d, keys):\n    \"\"\"\n    Creates a new dict from an existing dict that only has the given keys\n    \"\"\"\n    return {k: v for k, v in d.items() if k in keys}": 177,
"def _dt_to_epoch(dt):\n        \"\"\"Convert datetime to epoch seconds.\"\"\"\n        try:\n            epoch = dt.timestamp()\n        except AttributeError:  # py2\n            epoch = (dt - datetime(1970, 1, 1)).total_seconds()\n        return epoch": 459,
"def sanitize_word(s):\n    \"\"\"Remove non-alphanumerical characters from metric word.\n    And trim excessive underscores.\n    \"\"\"\n    s = re.sub('[^\\w-]+', '_', s)\n    s = re.sub('__+', '_', s)\n    return s.strip('_')": 2339,
"def web(host, port):\n    \"\"\"Start web application\"\"\"\n    from .webserver.web import get_app\n    get_app().run(host=host, port=port)": 1338,
"def valid_date(x: str) -> bool:\n    \"\"\"\n    Retrun ``True`` if ``x`` is a valid YYYYMMDD date;\n    otherwise return ``False``.\n    \"\"\"\n    try:\n        if x != dt.datetime.strptime(x, DATE_FORMAT).strftime(DATE_FORMAT):\n            raise ValueError\n        return True\n    except ValueError:\n        return False": 5581,
"def datetime_delta_to_ms(delta):\n    \"\"\"\n    Given a datetime.timedelta object, return the delta in milliseconds\n    \"\"\"\n    delta_ms = delta.days * 24 * 60 * 60 * 1000\n    delta_ms += delta.seconds * 1000\n    delta_ms += delta.microseconds / 1000\n    delta_ms = int(delta_ms)\n    return delta_ms": 2902,
"def reset(self):\n\t\t\"\"\"\n\t\tResets the iterator to the start.\n\n\t\tAny remaining values in the current iteration are discarded.\n\t\t\"\"\"\n\t\tself.__iterator, self.__saved = itertools.tee(self.__saved)": 1126,
"def median_high(data):\n    \"\"\"Return the high median of data.\n\n    When the number of data points is odd, the middle value is returned.\n    When it is even, the larger of the two middle values is returned.\n\n    \"\"\"\n    data = sorted(data)\n    n = len(data)\n    if n == 0:\n        raise StatisticsError(\"no median for empty data\")\n    return data[n // 2]": 1979,
"def pop(self, index=-1):\n\t\t\"\"\"Remove and return the item at index.\"\"\"\n\t\tvalue = self._list.pop(index)\n\t\tdel self._dict[value]\n\t\treturn value": 1019,
"def is_same_file (filename1, filename2):\n    \"\"\"Check if filename1 and filename2 point to the same file object.\n    There can be false negatives, ie. the result is False, but it is\n    the same file anyway. Reason is that network filesystems can create\n    different paths to the same physical file.\n    \"\"\"\n    if filename1 == filename2:\n        return True\n    if os.name == 'posix':\n        return os.path.samefile(filename1, filename2)\n    return is_same_filename(filename1, filename2)": 2832,
"def writeCSV(data, headers, csvFile):\n  \"\"\"Write data with column headers to a CSV.\"\"\"\n  with open(csvFile, \"wb\") as f:\n    writer = csv.writer(f, delimiter=\",\")\n    writer.writerow(headers)\n    writer.writerows(data)": 4044,
"def DeleteLog() -> None:\n        \"\"\"Delete log file.\"\"\"\n        if os.path.exists(Logger.FileName):\n            os.remove(Logger.FileName)": 6095,
"def join(mapping, bind, values):\n    \"\"\" Merge all the strings. Put space between them. \"\"\"\n    return [' '.join([six.text_type(v) for v in values if v is not None])]": 2587,
"def clean(some_string, uppercase=False):\n    \"\"\"\n    helper to clean up an input string\n    \"\"\"\n    if uppercase:\n        return some_string.strip().upper()\n    else:\n        return some_string.strip().lower()": 3327,
"def _count_leading_whitespace(text):\n  \"\"\"Returns the number of characters at the beginning of text that are whitespace.\"\"\"\n  idx = 0\n  for idx, char in enumerate(text):\n    if not char.isspace():\n      return idx\n  return idx + 1": 1859,
"def cos_sin_deg(deg):\n    \"\"\"Return the cosine and sin for the given angle\n    in degrees, with special-case handling of multiples\n    of 90 for perfect right angles\n    \"\"\"\n    deg = deg % 360.0\n    if deg == 90.0:\n        return 0.0, 1.0\n    elif deg == 180.0:\n        return -1.0, 0\n    elif deg == 270.0:\n        return 0, -1.0\n    rad = math.radians(deg)\n    return math.cos(rad), math.sin(rad)": 4132,
"def __add__(self, other):\n        \"\"\"Handle the `+` operator.\"\"\"\n        return self._handle_type(other)(self.value + other.value)": 23,
"def create_conda_env(sandbox_dir, env_name, dependencies, options=()):\n    \"\"\"\n    Create a conda environment inside the current sandbox for the given list of dependencies and options.\n\n    Parameters\n    ----------\n    sandbox_dir : str\n    env_name : str\n    dependencies : list\n        List of conda specs\n    options\n        List of additional options to pass to conda.  Things like [\"-c\", \"conda-forge\"]\n\n    Returns\n    -------\n    (env_dir, env_name)\n    \"\"\"\n\n    env_dir = os.path.join(sandbox_dir, env_name)\n    cmdline = [\"conda\", \"create\", \"--yes\", \"--copy\", \"--quiet\", \"-p\", env_dir] + list(options) + dependencies\n\n    log.info(\"Creating conda environment: \")\n    log.info(\"  command line: %s\", cmdline)\n    subprocess.check_call(cmdline, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n    log.debug(\"Environment created\")\n\n    return env_dir, env_name": 1839,
"def _get_pretty_string(obj):\n    \"\"\"Return a prettier version of obj\n\n    Parameters\n    ----------\n    obj : object\n        Object to pretty print\n\n    Returns\n    -------\n    s : str\n        Pretty print object repr\n    \"\"\"\n    sio = StringIO()\n    pprint.pprint(obj, stream=sio)\n    return sio.getvalue()": 1942,
"def _npiter(arr):\n    \"\"\"Wrapper for iterating numpy array\"\"\"\n    for a in np.nditer(arr, flags=[\"refs_ok\"]):\n        c = a.item()\n        if c is not None:\n            yield c": 3140,
"def get_value(key, obj, default=missing):\n    \"\"\"Helper for pulling a keyed value off various types of objects\"\"\"\n    if isinstance(key, int):\n        return _get_value_for_key(key, obj, default)\n    return _get_value_for_keys(key.split('.'), obj, default)": 2593,
"def itervalues(d, **kw):\n    \"\"\"Return an iterator over the values of a dictionary.\"\"\"\n    if not PY2:\n        return iter(d.values(**kw))\n    return d.itervalues(**kw)": 1287,
"def load_feature(fname, language):\n    \"\"\" Load and parse a feature file. \"\"\"\n\n    fname = os.path.abspath(fname)\n    feat = parse_file(fname, language)\n    return feat": 3282,
"def split(text: str) -> List[str]:\n    \"\"\"Split a text into a list of tokens.\n\n    :param text: the text to split\n    :return: tokens\n    \"\"\"\n    return [word for word in SEPARATOR.split(text) if word.strip(' \\t')]": 5571,
"def normal_noise(points):\n    \"\"\"Init a noise variable.\"\"\"\n    return np.random.rand(1) * np.random.randn(points, 1) \\\n        + random.sample([2, -2], 1)": 3344,
"def connect(host, port, username, password):\n        \"\"\"Connect and login to an FTP server and return ftplib.FTP object.\"\"\"\n        # Instantiate ftplib client\n        session = ftplib.FTP()\n\n        # Connect to host without auth\n        session.connect(host, port)\n\n        # Authenticate connection\n        session.login(username, password)\n        return session": 350,
"def numchannels(samples:np.ndarray) -> int:\n    \"\"\"\n    return the number of channels present in samples\n\n    samples: a numpy array as returned by sndread\n\n    for multichannel audio, samples is always interleaved,\n    meaning that samples[n] returns always a frame, which\n    is either a single scalar for mono audio, or an array\n    for multichannel audio.\n    \"\"\"\n    if len(samples.shape) == 1:\n        return 1\n    else:\n        return samples.shape[1]": 5756,
"def sort_key(x):\n    \"\"\"\n    >>> sort_key(('name', ('ROUTE', 'URL')))\n    -3\n    \"\"\"\n    name, (r, u) = x\n    return - len(u) + u.count('}') * 100": 5890,
"def _mid(pt1, pt2):\n    \"\"\"\n    (Point, Point) -> Point\n    Return the point that lies in between the two input points.\n    \"\"\"\n    (x0, y0), (x1, y1) = pt1, pt2\n    return 0.5 * (x0 + x1), 0.5 * (y0 + y1)": 5853,
"def convert_ajax_data(self, field_data):\n        \"\"\"\n        Due to the way Angular organizes it model, when this Form data is sent using Ajax,\n        then for this kind of widget, the sent data has to be converted into a format suitable\n        for Django's Form validation.\n        \"\"\"\n        data = [key for key, val in field_data.items() if val]\n        return data": 4888,
"def count_string_diff(a,b):\n    \"\"\"Return the number of characters in two strings that don't exactly match\"\"\"\n    shortest = min(len(a), len(b))\n    return sum(a[i] != b[i] for i in range(shortest))": 1824,
"def MessageToDict(message,\n                  including_default_value_fields=False,\n                  preserving_proto_field_name=False):\n  \"\"\"Converts protobuf message to a JSON dictionary.\n\n  Args:\n    message: The protocol buffers message instance to serialize.\n    including_default_value_fields: If True, singular primitive fields,\n        repeated fields, and map fields will always be serialized.  If\n        False, only serialize non-empty fields.  Singular message fields\n        and oneof fields are not affected by this option.\n    preserving_proto_field_name: If True, use the original proto field\n        names as defined in the .proto file. If False, convert the field\n        names to lowerCamelCase.\n\n  Returns:\n    A dict representation of the JSON formatted protocol buffer message.\n  \"\"\"\n  printer = _Printer(including_default_value_fields,\n                     preserving_proto_field_name)\n  # pylint: disable=protected-access\n  return printer._MessageToJsonObject(message)": 4806,
"def argsort_indices(a, axis=-1):\n    \"\"\"Like argsort, but returns an index suitable for sorting the\n    the original array even if that array is multidimensional\n    \"\"\"\n    a = np.asarray(a)\n    ind = list(np.ix_(*[np.arange(d) for d in a.shape]))\n    ind[axis] = a.argsort(axis)\n    return tuple(ind)": 604,
"def register_modele(self, modele: Modele):\n        \"\"\" Register a modele onto the lemmatizer\n\n        :param modele: Modele to register\n        \"\"\"\n        self.lemmatiseur._modeles[modele.gr()] = modele": 662,
"def shape(self) -> Tuple[int, ...]:\n        \"\"\"Shape of histogram's data.\n\n        Returns\n        -------\n        One-element tuple with the number of bins along each axis.\n        \"\"\"\n        return tuple(bins.bin_count for bins in self._binnings)": 5791,
"def is_int_vector(l):\n    r\"\"\"Checks if l is a numpy array of integers\n\n    \"\"\"\n    if isinstance(l, np.ndarray):\n        if l.ndim == 1 and (l.dtype.kind == 'i' or l.dtype.kind == 'u'):\n            return True\n    return False": 1618,
"def get_key_by_value(dictionary, search_value):\n    \"\"\"\n    searchs a value in a dicionary and returns the key of the first occurrence\n\n    :param dictionary: dictionary to search in\n    :param search_value: value to search for\n    \"\"\"\n    for key, value in dictionary.iteritems():\n        if value == search_value:\n            return ugettext(key)": 1056,
"def _DateToEpoch(date):\n  \"\"\"Converts python datetime to epoch microseconds.\"\"\"\n  tz_zero = datetime.datetime.utcfromtimestamp(0)\n  diff_sec = int((date - tz_zero).total_seconds())\n  return diff_sec * 1000000": 1707,
"def _GetProxies(self):\n    \"\"\"Gather a list of proxies to use.\"\"\"\n    # Detect proxies from the OS environment.\n    result = client_utils.FindProxies()\n\n    # Also try to connect directly if all proxies fail.\n    result.append(\"\")\n\n    # Also try all proxies configured in the config system.\n    result.extend(config.CONFIG[\"Client.proxy_servers\"])\n\n    return result": 5065,
"def _run_sync(self, method: Callable, *args, **kwargs) -> Any:\n        \"\"\"\n        Utility method to run commands synchronously for testing.\n        \"\"\"\n        if self.loop.is_running():\n            raise RuntimeError(\"Event loop is already running.\")\n\n        if not self.is_connected:\n            self.loop.run_until_complete(self.connect())\n\n        task = asyncio.Task(method(*args, **kwargs), loop=self.loop)\n        result = self.loop.run_until_complete(task)\n\n        self.loop.run_until_complete(self.quit())\n\n        return result": 5681,
"def check_cv(self, y):\n        \"\"\"Resolve which cross validation strategy is used.\"\"\"\n        y_arr = None\n        if self.stratified:\n            # Try to convert y to numpy for sklearn's check_cv; if conversion\n            # doesn't work, still try.\n            try:\n                y_arr = to_numpy(y)\n            except (AttributeError, TypeError):\n                y_arr = y\n\n        if self._is_float(self.cv):\n            return self._check_cv_float()\n        return self._check_cv_non_float(y_arr)": 4567,
"def _remove_blank(l):\n        \"\"\" Removes trailing zeros in the list of integers and returns a new list of integers\"\"\"\n        ret = []\n        for i, _ in enumerate(l):\n            if l[i] == 0:\n                break\n            ret.append(l[i])\n        return ret": 1006,
"def split_every(iterable, n):  # TODO: Remove this, or make it return a generator.\n    \"\"\"\n    A generator of n-length chunks of an input iterable\n    \"\"\"\n    i = iter(iterable)\n    piece = list(islice(i, n))\n    while piece:\n        yield piece\n        piece = list(islice(i, n))": 2914,
"def dot_v3(v, w):\n    \"\"\"Return the dotproduct of two vectors.\"\"\"\n\n    return sum([x * y for x, y in zip(v, w)])": 871,
"def detach_all(self):\n        \"\"\"\n        Detach from all tracked classes and objects.\n        Restore the original constructors and cleanse the tracking lists.\n        \"\"\"\n        self.detach_all_classes()\n        self.objects.clear()\n        self.index.clear()\n        self._keepalive[:] = []": 1842,
"def is_valid_row(cls, row):\n        \"\"\"Indicates whether or not the given row contains valid data.\"\"\"\n        for k in row.keys():\n            if row[k] is None:\n                return False\n        return True": 1620,
"def border(self):\n        \"\"\"Region formed by taking border elements.\n\n        :returns: :class:`jicimagelib.region.Region`\n        \"\"\"\n\n        border_array = self.bitmap - self.inner.bitmap\n        return Region(border_array)": 3568,
"def substitute(dict_, source):\n    \"\"\" Perform re.sub with the patterns in the given dict\n    Args:\n      dict_: {pattern: repl}\n      source: str\n    \"\"\"\n    d_esc = (re.escape(k) for k in dict_.keys())\n    pattern = re.compile('|'.join(d_esc))\n    return pattern.sub(lambda x: dict_[x.group()], source)": 4713,
"def change_dir(directory):\n  \"\"\"\n  Wraps a function to run in a given directory.\n\n  \"\"\"\n  def cd_decorator(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n      org_path = os.getcwd()\n      os.chdir(directory)\n      func(*args, **kwargs)\n      os.chdir(org_path)\n    return wrapper\n  return cd_decorator": 2811,
"def register_service(self, service):\n        \"\"\"\n            Register service into the system. Called by Services.\n        \"\"\"\n        if service not in self.services:\n            self.services.append(service)": 3784,
"def to_camel(s):\n    \"\"\"\n    :param string s: under_scored string to be CamelCased\n    :return: CamelCase version of input\n    :rtype: str\n    \"\"\"\n    # r'(?!^)_([a-zA-Z]) original regex wasn't process first groups\n    return re.sub(r'_([a-zA-Z])', lambda m: m.group(1).upper(), '_' + s)": 3683,
"def Slice(a, begin, size):\n    \"\"\"\n    Slicing op.\n    \"\"\"\n    return np.copy(a)[[slice(*tpl) for tpl in zip(begin, begin+size)]],": 1486,
"def compose(*funcs):\n    \"\"\"compose a list of functions\"\"\"\n    return lambda x: reduce(lambda v, f: f(v), reversed(funcs), x)": 1578,
"def calculate_size(name, replace_existing_values):\n    \"\"\" Calculates the request payload size\"\"\"\n    data_size = 0\n    data_size += calculate_size_str(name)\n    data_size += BOOLEAN_SIZE_IN_BYTES\n    return data_size": 4632,
"def reset(self):\n        \"\"\"Reset analyzer state\n        \"\"\"\n        self.prevframe = None\n        self.wasmoving = False\n        self.t0 = 0\n        self.ismoving = False": 2156,
"def _not(condition=None, **kwargs):\n    \"\"\"\n    Return the opposite of input condition.\n\n    :param condition: condition to process.\n\n    :result: not condition.\n    :rtype: bool\n    \"\"\"\n\n    result = True\n\n    if condition is not None:\n        result = not run(condition, **kwargs)\n\n    return result": 18,
"def _validate_key(self, key):\n        \"\"\"Returns a boolean indicating if the attribute name is valid or not\"\"\"\n        return not any([key.startswith(i) for i in self.EXCEPTIONS])": 1653,
"def get_creation_datetime(filepath):\n    \"\"\"\n    Get the date that a file was created.\n\n    Parameters\n    ----------\n    filepath : str\n\n    Returns\n    -------\n    creation_datetime : datetime.datetime or None\n    \"\"\"\n    if platform.system() == 'Windows':\n        return datetime.fromtimestamp(os.path.getctime(filepath))\n    else:\n        stat = os.stat(filepath)\n        try:\n            return datetime.fromtimestamp(stat.st_birthtime)\n        except AttributeError:\n            # We're probably on Linux. No easy way to get creation dates here,\n            # so we'll settle for when its content was last modified.\n            return None": 3577,
"def vectorize(values):\n    \"\"\"\n    Takes a value or list of values and returns a single result, joined by \",\"\n    if necessary.\n    \"\"\"\n    if isinstance(values, list):\n        return ','.join(str(v) for v in values)\n    return values": 2504,
"def memory_full():\n    \"\"\"Check if the memory is too full for further caching.\"\"\"\n    current_process = psutil.Process(os.getpid())\n    return (current_process.memory_percent() >\n            config.MAXIMUM_CACHE_MEMORY_PERCENTAGE)": 5684,
"def _assert_is_type(name, value, value_type):\n    \"\"\"Assert that a value must be a given type.\"\"\"\n    if not isinstance(value, value_type):\n        if type(value_type) is tuple:\n            types = ', '.join(t.__name__ for t in value_type)\n            raise ValueError('{0} must be one of ({1})'.format(name, types))\n        else:\n            raise ValueError('{0} must be {1}'\n                             .format(name, value_type.__name__))": 1519,
"def is_not_null(df: DataFrame, col_name: str) -> bool:\n    \"\"\"\n    Return ``True`` if the given DataFrame has a column of the given\n    name (string), and there exists at least one non-NaN value in that\n    column; return ``False`` otherwise.\n    \"\"\"\n    if (\n        isinstance(df, pd.DataFrame)\n        and col_name in df.columns\n        and df[col_name].notnull().any()\n    ):\n        return True\n    else:\n        return False": 5659,
"def from_pydatetime(cls, pydatetime):\n        \"\"\"\n        Creates sql datetime2 object from Python datetime object\n        ignoring timezone\n        @param pydatetime: Python datetime object\n        @return: sql datetime2 object\n        \"\"\"\n        return cls(date=Date.from_pydate(pydatetime.date),\n                   time=Time.from_pytime(pydatetime.time))": 2647,
"def prettyprint(d):\n        \"\"\"Print dicttree in Json-like format. keys are sorted\n        \"\"\"\n        print(json.dumps(d, sort_keys=True, \n                         indent=4, separators=(\",\" , \": \")))": 2227,
"def set_xlimits(self, row, column, min=None, max=None):\n        \"\"\"Set x-axis limits of a subplot.\n\n        :param row,column: specify the subplot.\n        :param min: minimal axis value\n        :param max: maximum axis value\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_xlimits(min, max)": 3455,
"def l2_norm(params):\n    \"\"\"Computes l2 norm of params by flattening them into a vector.\"\"\"\n    flattened, _ = flatten(params)\n    return np.dot(flattened, flattened)": 3651,
"def info(self, text):\n\t\t\"\"\" Ajout d'un message de log de type INFO \"\"\"\n\t\tself.logger.info(\"{}{}\".format(self.message_prefix, text))": 3865,
"def __remove_method(m: lmap.Map, key: T) -> lmap.Map:\n        \"\"\"Swap the methods atom to remove method with key.\"\"\"\n        return m.dissoc(key)": 5911,
"def struct2dict(struct):\n    \"\"\"convert a ctypes structure to a dictionary\"\"\"\n    return {x: getattr(struct, x) for x in dict(struct._fields_).keys()}": 3597,
"def plot3d_init(fignum):\n    \"\"\"\n    initializes 3D plot\n    \"\"\"\n    from mpl_toolkits.mplot3d import Axes3D\n    fig = plt.figure(fignum)\n    ax = fig.add_subplot(111, projection='3d')\n    return ax": 3693,
"def get_month_start_end_day():\n    \"\"\"\n    Get the month start date a nd end date\n    \"\"\"\n    t = date.today()\n    n = mdays[t.month]\n    return (date(t.year, t.month, 1), date(t.year, t.month, n))": 405,
"def delete_duplicates(seq):\n    \"\"\"\n    Remove duplicates from an iterable, preserving the order.\n\n    Args:\n        seq: Iterable of various type.\n\n    Returns:\n        list: List of unique objects.\n\n    \"\"\"\n    seen = set()\n    seen_add = seen.add\n    return [x for x in seq if not (x in seen or seen_add(x))]": 394,
"def parse_form(self, req, name, field):\n        \"\"\"Pull a form value from the request.\"\"\"\n        return get_value(req.body_arguments, name, field)": 1464,
"def _accumulate(sequence, func):\n    \"\"\"\n    Python2 accumulate implementation taken from\n    https://docs.python.org/3/library/itertools.html#itertools.accumulate\n    \"\"\"\n    iterator = iter(sequence)\n    total = next(iterator)\n    yield total\n    for element in iterator:\n        total = func(total, element)\n        yield total": 325,
"def from_bytes(cls, b):\n\t\t\"\"\"Create :class:`PNG` from raw bytes.\n\t\t\n\t\t:arg bytes b: The raw bytes of the PNG file.\n\t\t:rtype: :class:`PNG`\n\t\t\"\"\"\n\t\tim = cls()\n\t\tim.chunks = list(parse_chunks(b))\n\t\tim.init()\n\t\treturn im": 907,
"def get_time(filename):\n\t\"\"\"\n\tGet the modified time for a file as a datetime instance\n\t\"\"\"\n\tts = os.stat(filename).st_mtime\n\treturn datetime.datetime.utcfromtimestamp(ts)": 1794,
"def getfirstline(file, default):\n    \"\"\"\n    Returns the first line of a file.\n    \"\"\"\n    with open(file, 'rb') as fh:\n        content = fh.readlines()\n        if len(content) == 1:\n            return content[0].decode('utf-8').strip('\\n')\n\n    return default": 971,
"def batch(items, size):\n    \"\"\"Batches a list into a list of lists, with sub-lists sized by a specified\n    batch size.\"\"\"\n    return [items[x:x + size] for x in xrange(0, len(items), size)]": 654,
"def all_versions(req):\n    \"\"\"Get all versions of req from PyPI.\"\"\"\n    import requests\n    url = \"https://pypi.python.org/pypi/\" + req + \"/json\"\n    return tuple(requests.get(url).json()[\"releases\"].keys())": 4321,
"def natural_sort(list, key=lambda s:s):\n    \"\"\"\n    Sort the list into natural alphanumeric order.\n    \"\"\"\n    def get_alphanum_key_func(key):\n        convert = lambda text: int(text) if text.isdigit() else text\n        return lambda s: [convert(c) for c in re.split('([0-9]+)', key(s))]\n    sort_key = get_alphanum_key_func(key)\n    list.sort(key=sort_key)": 4334,
"def _pip_exists(self):\n        \"\"\"Returns True if pip exists inside the virtual environment. Can be\n        used as a naive way to verify that the environment is installed.\"\"\"\n        return os.path.isfile(os.path.join(self.path, 'bin', 'pip'))": 239,
"def hasattrs(object, *names):\n    \"\"\"\n    Takes in an object and a variable length amount of named attributes,\n    and checks to see if the object has each property. If any of the\n    attributes are missing, this returns false.\n\n    :param object: an object that may or may not contain the listed attributes\n    :param names: a variable amount of attribute names to check for\n    :return: True if the object contains each named attribute, false otherwise\n    \"\"\"\n    for name in names:\n        if not hasattr(object, name):\n            return False\n    return True": 178,
"def list_to_str(list, separator=','):\n    \"\"\"\n    >>> list = [0, 0, 7]\n    >>> list_to_str(list)\n    '0,0,7'\n    \"\"\"\n    list = [str(x) for x in list]\n    return separator.join(list)": 5700,
"def needs_check(self):\n        \"\"\"\n        Check if enough time has elapsed to perform a check().\n\n        If this time has elapsed, a state change check through\n        has_state_changed() should be performed and eventually a sync().\n\n        :rtype: boolean\n        \"\"\"\n        if self.lastcheck is None:\n            return True\n        return time.time() - self.lastcheck >= self.ipchangedetection_sleep": 6125,
"def execute(self, cmd, *args, **kwargs):\n        \"\"\" Execute the SQL command and return the data rows as tuples\n        \"\"\"\n        self.cursor.execute(cmd, *args, **kwargs)": 4611,
"def _get_loggers():\n    \"\"\"Return list of Logger classes.\"\"\"\n    from .. import loader\n    modules = loader.get_package_modules('logger')\n    return list(loader.get_plugins(modules, [_Logger]))": 1928,
"def parse(self, s):\n        \"\"\"\n        Parses a date string formatted like ``YYYY-MM-DD``.\n        \"\"\"\n        return datetime.datetime.strptime(s, self.date_format).date()": 107,
"def is_integer(obj):\n    \"\"\"Is this an integer.\n\n    :param object obj:\n    :return:\n    \"\"\"\n    if PYTHON3:\n        return isinstance(obj, int)\n    return isinstance(obj, (int, long))": 2128,
"def bisect_index(a, x):\n    \"\"\" Find the leftmost index of an element in a list using binary search.\n\n    Parameters\n    ----------\n    a: list\n        A sorted list.\n    x: arbitrary\n        The element.\n\n    Returns\n    -------\n    int\n        The index.\n\n    \"\"\"\n    i = bisect.bisect_left(a, x)\n    if i != len(a) and a[i] == x:\n        return i\n    raise ValueError": 1588,
"def find_one(cls, *args, **kw):\n\t\t\"\"\"Get a single document from the collection this class is bound to.\n\t\t\n\t\tAdditional arguments are processed according to `_prepare_find` prior to passing to PyMongo, where positional\n\t\tparameters are interpreted as query fragments, parametric keyword arguments combined, and other keyword\n\t\targuments passed along with minor transformation.\n\t\t\n\t\tAutomatically calls `to_mongo` with the retrieved data.\n\t\t\n\t\thttps://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.find_one\n\t\t\"\"\"\n\t\t\n\t\tif len(args) == 1 and not isinstance(args[0], Filter):\n\t\t\targs = (getattr(cls, cls.__pk__) == args[0], )\n\t\t\n\t\tDoc, collection, query, options = cls._prepare_find(*args, **kw)\n\t\tresult = Doc.from_mongo(collection.find_one(query, **options))\n\t\t\n\t\treturn result": 4414,
"def parse(text, showToc=True):\n\t\"\"\"Returns HTML from MediaWiki markup\"\"\"\n\tp = Parser(show_toc=showToc)\n\treturn p.parse(text)": 4798,
"def update_screen(self):\n        \"\"\"Refresh the screen. You don't need to override this except to update only small portins of the screen.\"\"\"\n        self.clock.tick(self.FPS)\n        pygame.display.update()": 1913,
"def setDictDefaults (d, defaults):\n  \"\"\"Sets all defaults for the given dictionary to those contained in a\n  second defaults dictionary.  This convenience method calls:\n\n    d.setdefault(key, value)\n\n  for each key and value in the given defaults dictionary.\n  \"\"\"\n  for key, val in defaults.items():\n    d.setdefault(key, val)\n\n  return d": 3846,
"def region_from_segment(image, segment):\n    \"\"\"given a segment (rectangle) and an image, returns it's corresponding subimage\"\"\"\n    x, y, w, h = segment\n    return image[y:y + h, x:x + w]": 941,
"def _clean_dict(target_dict, whitelist=None):\n    \"\"\" Convenience function that removes a dicts keys that have falsy values\n    \"\"\"\n    assert isinstance(target_dict, dict)\n    return {\n        ustr(k).strip(): ustr(v).strip()\n        for k, v in target_dict.items()\n        if v not in (None, Ellipsis, [], (), \"\")\n        and (not whitelist or k in whitelist)\n    }": 695,
"def timed_rotating_file_handler(name, logname, filename, when='h',\n                                interval=1, backupCount=0,\n                                encoding=None, delay=False, utc=False):\n    \"\"\"\n    A Bark logging handler logging output to a named file.  At\n    intervals specified by the 'when', the file will be rotated, under\n    control of 'backupCount'.\n\n    Similar to logging.handlers.TimedRotatingFileHandler.\n    \"\"\"\n\n    return wrap_log_handler(logging.handlers.TimedRotatingFileHandler(\n        filename, when=when, interval=interval, backupCount=backupCount,\n        encoding=encoding, delay=delay, utc=utc))": 166,
"def _get_column_types(self, data):\n        \"\"\"Get a list of the data types for each column in *data*.\"\"\"\n        columns = list(zip_longest(*data))\n        return [self._get_column_type(column) for column in columns]": 461,
"def delete_index(self):\n        \"\"\"\n        Delete the index, if it exists.\n        \"\"\"\n        es = self._init_connection()\n        if es.indices.exists(index=self.index):\n            es.indices.delete(index=self.index)": 5167,
"def _linear_seaborn_(self, label=None, style=None, opts=None):\n        \"\"\"\n        Returns a Seaborn linear regression plot\n        \"\"\"\n        xticks, yticks = self._get_ticks(opts)\n        try:\n            fig = sns.lmplot(self.x, self.y, data=self.df)\n            fig = self._set_with_height(fig, opts)\n            return fig\n        except Exception as e:\n            self.err(e, self.linear_,\n                     \"Can not draw linear regression chart\")": 3277,
"def load_streams(chunks):\n    \"\"\"\n    Given a gzipped stream of data, yield streams of decompressed data.\n    \"\"\"\n    chunks = peekable(chunks)\n    while chunks:\n        if six.PY3:\n            dc = zlib.decompressobj(wbits=zlib.MAX_WBITS | 16)\n        else:\n            dc = zlib.decompressobj(zlib.MAX_WBITS | 16)\n        yield load_stream(dc, chunks)\n        if dc.unused_data:\n            chunks = peekable(itertools.chain((dc.unused_data,), chunks))": 3586,
"def split_len(s, length):\n    \"\"\"split string *s* into list of strings no longer than *length*\"\"\"\n    return [s[i:i+length] for i in range(0, len(s), length)]": 3224,
"def json(body, charset='utf-8', **kwargs):\n    \"\"\"Takes JSON formatted data, converting it into native Python objects\"\"\"\n    return json_converter.loads(text(body, charset=charset))": 2057,
"def __call__(self, img):\n        \"\"\"\n        Args:\n            img (PIL Image): Image to be padded.\n\n        Returns:\n            PIL Image: Padded image.\n        \"\"\"\n        return F.pad(img, self.padding, self.fill, self.padding_mode)": 2553,
"def remove_series(self, series):\n        \"\"\"Removes a :py:class:`.Series` from the chart.\n\n        :param Series series: The :py:class:`.Series` to remove.\n        :raises ValueError: if you try to remove the last\\\n        :py:class:`.Series`.\"\"\"\n\n        if len(self.all_series()) == 1:\n            raise ValueError(\"Cannot remove last series from %s\" % str(self))\n        self._all_series.remove(series)\n        series._chart = None": 1100,
"def is_valid_ipv6(ip_str):\n    \"\"\"\n    Check the validity of an IPv6 address\n    \"\"\"\n    try:\n        socket.inet_pton(socket.AF_INET6, ip_str)\n    except socket.error:\n        return False\n    return True": 1249,
"def multi_replace(instr, search_list=[], repl_list=None):\n    \"\"\"\n    Does a string replace with a list of search and replacements\n\n    TODO: rename\n    \"\"\"\n    repl_list = [''] * len(search_list) if repl_list is None else repl_list\n    for ser, repl in zip(search_list, repl_list):\n        instr = instr.replace(ser, repl)\n    return instr": 1023,
"def format(self, record, *args, **kwargs):\n        \"\"\"\n        Format a message in the log\n\n        Act like the normal format, but indent anything that is a\n        newline within the message.\n\n        \"\"\"\n        return logging.Formatter.format(\n            self, record, *args, **kwargs).replace('\\n', '\\n' + ' ' * 8)": 748,
"def get_stripped_file_lines(filename):\n    \"\"\"\n    Return lines of a file with whitespace removed\n    \"\"\"\n    try:\n        lines = open(filename).readlines()\n    except FileNotFoundError:\n        fatal(\"Could not open file: {!r}\".format(filename))\n\n    return [line.strip() for line in lines]": 3099,
"def find_geom(geom, geoms):\n    \"\"\"\n    Returns the index of a geometry in a list of geometries avoiding\n    expensive equality checks of `in` operator.\n    \"\"\"\n    for i, g in enumerate(geoms):\n        if g is geom:\n            return i": 1272,
"def inverted_dict(d):\n    \"\"\"Return a dict with swapped keys and values\n\n    >>> inverted_dict({0: ('a', 'b'), 1: 'cd'}) == {'cd': 1, ('a', 'b'): 0}\n    True\n    \"\"\"\n    return dict((force_hashable(v), k) for (k, v) in viewitems(dict(d)))": 5553,
"def disable_stdout_buffering():\n    \"\"\"This turns off stdout buffering so that outputs are immediately\n    materialized and log messages show up before the program exits\"\"\"\n    stdout_orig = sys.stdout\n    sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)\n    # NOTE(brandyn): This removes the original stdout\n    return stdout_orig": 2887,
"def generate_unique_host_id():\n    \"\"\"Generate a unique ID, that is somewhat guaranteed to be unique among all\n    instances running at the same time.\"\"\"\n    host = \".\".join(reversed(socket.gethostname().split(\".\")))\n    pid = os.getpid()\n    return \"%s.%d\" % (host, pid)": 335,
"def write(self, text):\n        \"\"\"Write text. An additional attribute terminator with a value of\n           None is added to the logging record to indicate that StreamHandler\n           should not add a newline.\"\"\"\n        self.logger.log(self.loglevel, text, extra={'terminator': None})": 2097,
"def required_header(header):\n    \"\"\"Function that verify if the header parameter is a essential header\n\n    :param header:  A string represented a header\n    :returns:       A boolean value that represent if the header is required\n    \"\"\"\n    if header in IGNORE_HEADERS:\n        return False\n\n    if header.startswith('HTTP_') or header == 'CONTENT_TYPE':\n        return True\n\n    return False": 233,
"def compare(dicts):\n    \"\"\"Compare by iteration\"\"\"\n\n    common_members = {}\n    common_keys = reduce(lambda x, y: x & y, map(dict.keys, dicts))\n    for k in common_keys:\n        common_members[k] = list(\n            reduce(lambda x, y: x & y, [set(d[k]) for d in dicts]))\n\n    return common_members": 522,
"def endless_permutations(N, random_state=None):\n    \"\"\"\n    Generate an endless sequence of random integers from permutations of the\n    set [0, ..., N).\n\n    If we call this N times, we will sweep through the entire set without\n    replacement, on the (N+1)th call a new permutation will be created, etc.\n\n    Parameters\n    ----------\n    N: int\n        the length of the set\n    random_state: int or RandomState, optional\n        random seed\n\n    Yields\n    ------\n    int:\n        a random int from the set [0, ..., N)\n    \"\"\"\n    generator = check_random_state(random_state)\n    while True:\n        batch_inds = generator.permutation(N)\n        for b in batch_inds:\n            yield b": 957,
"def dedupe_list(l):\n    \"\"\"Remove duplicates from a list preserving the order.\n\n    We might be tempted to use the list(set(l)) idiom, but it doesn't preserve\n    the order, which hinders testability and does not work for lists with\n    unhashable elements.\n    \"\"\"\n    result = []\n\n    for el in l:\n        if el not in result:\n            result.append(el)\n\n    return result": 721,
"def getvariable(name):\n    \"\"\"Get the value of a local variable somewhere in the call stack.\"\"\"\n    import inspect\n    fr = inspect.currentframe()\n    try:\n        while fr:\n            fr = fr.f_back\n            vars = fr.f_locals\n            if name in vars:\n                return vars[name]\n    except:\n        pass\n    return None": 1793,
"def _split_str(s, n):\n    \"\"\"\n    split string into list of strings by specified number.\n    \"\"\"\n    length = len(s)\n    return [s[i:i + n] for i in range(0, length, n)]": 424,
"def set_verbosity(verbosity):\n        \"\"\"Banana banana\n        \"\"\"\n        Logger._verbosity = min(max(0, WARNING - verbosity), 2)\n        debug(\"Verbosity set to %d\" % (WARNING - Logger._verbosity), 'logging')": 5020,
"def setPixel(self, x, y, color):\n        \"\"\"Set the pixel at (x,y) to the integers in sequence 'color'.\"\"\"\n        return _fitz.Pixmap_setPixel(self, x, y, color)": 1518,
"def _get_compiled_ext():\n    \"\"\"Official way to get the extension of compiled files (.pyc or .pyo)\"\"\"\n    for ext, mode, typ in imp.get_suffixes():\n        if typ == imp.PY_COMPILED:\n            return ext": 523,
"def hline(self, x, y, width, color):\n        \"\"\"Draw a horizontal line up to a given length.\"\"\"\n        self.rect(x, y, width, 1, color, fill=True)": 225,
"def detokenize(s):\n    \"\"\" Detokenize a string by removing spaces before punctuation.\"\"\"\n    print(s)\n    s = re.sub(\"\\s+([;:,\\.\\?!])\", \"\\\\1\", s)\n    s = re.sub(\"\\s+(n't)\", \"\\\\1\", s)\n    return s": 398,
"def commajoin_as_strings(iterable):\n    \"\"\" Join the given iterable with ',' \"\"\"\n    return _(u',').join((six.text_type(i) for i in iterable))": 160,
"def install_postgres(user=None, dbname=None, password=None):\n    \"\"\"Install Postgres on remote\"\"\"\n    execute(pydiploy.django.install_postgres_server,\n            user=user, dbname=dbname, password=password)": 3451,
"def filter_greys_using_image(image, target):\n    \"\"\"Filter out any values in target not in image\n\n    :param image: image containing values to appear in filtered image\n    :param target: the image to filter\n    :rtype: 2d  :class:`numpy.ndarray` containing only value in image\n        and with the same dimensions as target\n\n    \"\"\"\n    maskbase = numpy.array(range(256), dtype=numpy.uint8)\n    mask = numpy.where(numpy.in1d(maskbase, numpy.unique(image)), maskbase, 0)\n    return mask[target]": 3528,
"def longest_run_1d(arr):\n    \"\"\"Return the length of the longest consecutive run of identical values.\n\n    Parameters\n    ----------\n    arr : bool array\n      Input array\n\n    Returns\n    -------\n    int\n      Length of longest run.\n    \"\"\"\n    v, rl = rle_1d(arr)[:2]\n    return np.where(v, rl, 0).max()": 1368,
"def load_yaml(yaml_file: str) -> Any:\n    \"\"\"\n    Load YAML from file.\n\n    :param yaml_file: path to YAML file\n    :return: content of the YAML as dict/list\n    \"\"\"\n    with open(yaml_file, 'r') as file:\n        return ruamel.yaml.load(file, ruamel.yaml.RoundTripLoader)": 6002,
"def get_methods(*objs):\n    \"\"\" Return the names of all callable attributes of an object\"\"\"\n    return set(\n        attr\n        for obj in objs\n        for attr in dir(obj)\n        if not attr.startswith('_') and callable(getattr(obj, attr))\n    )": 385,
"def comma_converter(float_string):\n    \"\"\"Convert numbers to floats whether the decimal point is '.' or ','\"\"\"\n    trans_table = maketrans(b',', b'.')\n    return float(float_string.translate(trans_table))": 736,
"def dtypes(self):\n        \"\"\"Returns all column names and their data types as a list.\n\n        >>> df.dtypes\n        [('age', 'int'), ('name', 'string')]\n        \"\"\"\n        return [(str(f.name), f.dataType.simpleString()) for f in self.schema.fields]": 5803,
"def __rmatmul__(self, other):\n        \"\"\"\n        Matrix multiplication using binary `@` operator in Python>=3.5.\n        \"\"\"\n        return self.T.dot(np.transpose(other)).T": 5730,
"def product(*args, **kwargs):\n    \"\"\" Yields all permutations with replacement:\n        list(product(\"cat\", repeat=2)) => \n        [(\"c\", \"c\"), \n         (\"c\", \"a\"), \n         (\"c\", \"t\"), \n         (\"a\", \"c\"), \n         (\"a\", \"a\"), \n         (\"a\", \"t\"), \n         (\"t\", \"c\"), \n         (\"t\", \"a\"), \n         (\"t\", \"t\")]\n    \"\"\"\n    p = [[]]\n    for iterable in map(tuple, args) * kwargs.get(\"repeat\", 1):\n        p = [x + [y] for x in p for y in iterable]\n    for p in p:\n        yield tuple(p)": 5967,
"def validate_string(option, value):\n    \"\"\"Validates that 'value' is an instance of `basestring` for Python 2\n    or `str` for Python 3.\n    \"\"\"\n    if isinstance(value, string_type):\n        return value\n    raise TypeError(\"Wrong type for %s, value must be \"\n                    \"an instance of %s\" % (option, string_type.__name__))": 2584,
"def _show(self, message, indent=0, enable_verbose=True):  # pragma: no cover\n        \"\"\"Message printer.\n        \"\"\"\n        if enable_verbose:\n            print(\"    \" * indent + message)": 1030,
"def cmd_dot(conf: Config):\n    \"\"\"Print out a neat targets dependency tree based on requested targets.\n\n    Use graphviz to render the dot file, e.g.:\n\n    > ybt dot :foo :bar | dot -Tpng -o graph.png\n    \"\"\"\n    build_context = BuildContext(conf)\n    populate_targets_graph(build_context, conf)\n    if conf.output_dot_file is None:\n        write_dot(build_context, conf, sys.stdout)\n    else:\n        with open(conf.output_dot_file, 'w') as out_file:\n            write_dot(build_context, conf, out_file)": 5811,
"def BROADCAST_FILTER_NOT(func):\n        \"\"\"\n        Composes the passed filters into an and-joined filter.\n        \"\"\"\n        return lambda u, command, *args, **kwargs: not func(u, command, *args, **kwargs)": 2927,
"def ensure_index(self, key, unique=False):\n        \"\"\"Wrapper for pymongo.Collection.ensure_index\n        \"\"\"\n        return self.collection.ensure_index(key, unique=unique)": 3314,
"def get(url):\n    \"\"\"Recieving the JSON file from uulm\"\"\"\n    response = urllib.request.urlopen(url)\n    data = response.read()\n    data = data.decode(\"utf-8\")\n    data = json.loads(data)\n    return data": 1410,
"def column_exists(cr, table, column):\n    \"\"\" Check whether a certain column exists \"\"\"\n    cr.execute(\n        'SELECT count(attname) FROM pg_attribute '\n        'WHERE attrelid = '\n        '( SELECT oid FROM pg_class WHERE relname = %s ) '\n        'AND attname = %s',\n        (table, column))\n    return cr.fetchone()[0] == 1": 2194,
"def clear_matplotlib_ticks(self, axis=\"both\"):\n        \"\"\"Clears the default matplotlib ticks.\"\"\"\n        ax = self.get_axes()\n        plotting.clear_matplotlib_ticks(ax=ax, axis=axis)": 788,
"def build_parser():\n    \"\"\"Build argument parsers.\"\"\"\n\n    parser = argparse.ArgumentParser(\"Release packages to pypi\")\n    parser.add_argument('--check', '-c', action=\"store_true\", help=\"Do a dry run without uploading\")\n    parser.add_argument('component', help=\"The component to release as component-version\")\n    return parser": 1508,
"def get_anchor_href(markup):\n    \"\"\"\n    Given HTML markup, return a list of hrefs for each anchor tag.\n    \"\"\"\n    soup = BeautifulSoup(markup, 'lxml')\n    return ['%s' % link.get('href') for link in soup.find_all('a')]": 4158,
"def toBase64(s):\n    \"\"\"Represent string / bytes s as base64, omitting newlines\"\"\"\n    if isinstance(s, str):\n        s = s.encode(\"utf-8\")\n    return binascii.b2a_base64(s)[:-1]": 554,
"def shot_noise(x, severity=1):\n  \"\"\"Shot noise corruption to images.\n\n  Args:\n    x: numpy array, uncorrupted image, assumed to have uint8 pixel in [0,255].\n    severity: integer, severity of corruption.\n\n  Returns:\n    numpy array, image with uint8 pixels in [0,255]. Added shot noise.\n  \"\"\"\n  c = [60, 25, 12, 5, 3][severity - 1]\n  x = np.array(x) / 255.\n  x_clip = np.clip(np.random.poisson(x * c) / float(c), 0, 1) * 255\n  return around_and_astype(x_clip)": 1396,
"def get_count(self, query):\n        \"\"\"\n        Returns a number of query results. This is faster than .count() on the query\n        \"\"\"\n        count_q = query.statement.with_only_columns(\n            [func.count()]).order_by(None)\n        count = query.session.execute(count_q).scalar()\n        return count": 2396,
"def safe_int(val, default=None):\n    \"\"\"\n    Returns int() of val if val is not convertable to int use default\n    instead\n\n    :param val:\n    :param default:\n    \"\"\"\n\n    try:\n        val = int(val)\n    except (ValueError, TypeError):\n        val = default\n\n    return val": 2494,
"def head(filename, n=10):\n    \"\"\" prints the top `n` lines of a file \"\"\"\n    with freader(filename) as fr:\n        for _ in range(n):\n            print(fr.readline().strip())": 1073,
"def erase_lines(n=1):\n    \"\"\" Erases n lines from the screen and moves the cursor up to follow\n    \"\"\"\n    for _ in range(n):\n        print(codes.cursor[\"up\"], end=\"\")\n        print(codes.cursor[\"eol\"], end=\"\")": 783,
"def conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)": 1075,
"def inpaint(self):\n        \"\"\" Replace masked-out elements in an array using an iterative image inpainting algorithm. \"\"\"\n\n        import inpaint\n        filled = inpaint.replace_nans(np.ma.filled(self.raster_data, np.NAN).astype(np.float32), 3, 0.01, 2)\n        self.raster_data = np.ma.masked_invalid(filled)": 1803,
"def flatten_multidict(multidict):\n    \"\"\"Return flattened dictionary from ``MultiDict``.\"\"\"\n    return dict([(key, value if len(value) > 1 else value[0])\n                 for (key, value) in multidict.iterlists()])": 5724,
"def url_host(url: str) -> str:\n    \"\"\"\n    Parses hostname from URL.\n    :param url: URL\n    :return: hostname\n    \"\"\"\n    from urllib.parse import urlparse\n    res = urlparse(url)\n    return res.netloc.split(':')[0] if res.netloc else ''": 5694,
"def csv_to_numpy(string_like, dtype=None):  # type: (str) -> np.array\n    \"\"\"Convert a CSV object to a numpy array.\n\n    Args:\n        string_like (str): CSV string.\n        dtype (dtype, optional):  Data type of the resulting array. If None, the dtypes will be determined by the\n                                        contents of each column, individually. This argument can only be used to\n                                        'upcast' the array.  For downcasting, use the .astype(t) method.\n    Returns:\n        (np.array): numpy array\n    \"\"\"\n    stream = StringIO(string_like)\n    return np.genfromtxt(stream, dtype=dtype, delimiter=',')": 5746,
"def debugTreePrint(node,pfx=\"->\"):\n  \"\"\"Purely a debugging aid: Ascii-art picture of a tree descended from node\"\"\"\n  print pfx,node.item\n  for c in node.children:\n    debugTreePrint(c,\"  \"+pfx)": 5626,
"def _repr(obj):\n    \"\"\"Show the received object as precise as possible.\"\"\"\n    vals = \", \".join(\"{}={!r}\".format(\n        name, getattr(obj, name)) for name in obj._attribs)\n    if vals:\n        t = \"{}(name={}, {})\".format(obj.__class__.__name__, obj.name, vals)\n    else:\n        t = \"{}(name={})\".format(obj.__class__.__name__, obj.name)\n    return t": 1533,
"def dumped(text, level, indent=2):\n    \"\"\"Put curly brackets round an indented text\"\"\"\n    return indented(\"{\\n%s\\n}\" % indented(text, level + 1, indent) or \"None\", level, indent) + \"\\n\"": 29,
"def basic_word_sim(word1, word2):\n    \"\"\"\n    Simple measure of similarity: Number of letters in common / max length\n    \"\"\"\n    return sum([1 for c in word1 if c in word2]) / max(len(word1), len(word2))": 1901,
"def show_xticklabels(self, row, column):\n        \"\"\"Show the x-axis tick labels for a subplot.\n\n        :param row,column: specify the subplot.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.show_xticklabels()": 944,
"def load_image(fname):\n    \"\"\" read an image from file - PIL doesnt close nicely \"\"\"\n    with open(fname, \"rb\") as f:\n        i = Image.open(fname)\n        #i.load()\n        return i": 2485,
"def set_subparsers_args(self, *args, **kwargs):\n        \"\"\"\n        Sets args and kwargs that are passed when creating a subparsers group\n        in an argparse.ArgumentParser i.e. when calling\n        argparser.ArgumentParser.add_subparsers\n        \"\"\"\n        self.subparsers_args = args\n        self.subparsers_kwargs = kwargs": 2613,
"def strip_spaces(s):\n    \"\"\" Strip excess spaces from a string \"\"\"\n    return u\" \".join([c for c in s.split(u' ') if c])": 366,
"def datetime_local_to_utc(local):\n    \"\"\"\n    Simple function to convert naive :std:`datetime.datetime` object containing\n    local time to a naive :std:`datetime.datetime` object with UTC time.\n    \"\"\"\n    timestamp = time.mktime(local.timetuple())\n    return datetime.datetime.utcfromtimestamp(timestamp)": 737,
"def has_changed (filename):\n    \"\"\"Check if filename has changed since the last check. If this\n    is the first check, assume the file is changed.\"\"\"\n    key = os.path.abspath(filename)\n    mtime = get_mtime(key)\n    if key not in _mtime_cache:\n        _mtime_cache[key] = mtime\n        return True\n    return mtime > _mtime_cache[key]": 5690,
"def _short_repr(obj):\n  \"\"\"Helper function returns a truncated repr() of an object.\"\"\"\n  stringified = pprint.saferepr(obj)\n  if len(stringified) > 200:\n    return '%s... (%d bytes)' % (stringified[:200], len(stringified))\n  return stringified": 5740,
"def closing_plugin(self, cancelable=False):\n        \"\"\"Perform actions before parent main window is closed\"\"\"\n        self.dialog_manager.close_all()\n        self.shell.exit_interpreter()\n        return True": 141,
"def open_json(file_name):\n    \"\"\"\n    returns json contents as string\n    \"\"\"\n    with open(file_name, \"r\") as json_data:\n        data = json.load(json_data)\n        return data": 977,
"def _get_sql(filename):\n    \"\"\"Returns the contents of the sql file from the given ``filename``.\"\"\"\n    with open(os.path.join(SQL_DIR, filename), 'r') as f:\n        return f.read()": 1052,
"def directory_files(path):\n    \"\"\"Yield directory file names.\"\"\"\n\n    for entry in os.scandir(path):\n        if not entry.name.startswith('.') and entry.is_file():\n            yield entry.name": 665,
"def sort_data(data, cols):\n    \"\"\"Sort `data` rows and order columns\"\"\"\n    return data.sort_values(cols)[cols + ['value']].reset_index(drop=True)": 1180,
"def scale_min(im, targ, interpolation=cv2.INTER_AREA):\n    \"\"\" Scale the image so that the smallest axis is of size targ.\n\n    Arguments:\n        im (array): image\n        targ (int): target size\n    \"\"\"\n    r,c,*_ = im.shape\n    ratio = targ/min(r,c)\n    sz = (scale_to(c, ratio, targ), scale_to(r, ratio, targ))\n    return cv2.resize(im, sz, interpolation=interpolation)": 4795,
"def build_output(self, fout):\n        \"\"\"Squash self.out into string.\n\n        Join every line in self.out with a new line and write the\n        result to the output file.\n        \"\"\"\n        fout.write('\\n'.join([s for s in self.out]))": 688,
"def get_file_size(filename):\n    \"\"\"\n    Get the file size of a given file\n\n    :param filename: string: pathname of a file\n    :return: human readable filesize\n    \"\"\"\n    if os.path.isfile(filename):\n        return convert_size(os.path.getsize(filename))\n    return None": 288,
"def timestamp_to_datetime(timestamp):\n    \"\"\"Convert an ARF timestamp to a datetime.datetime object (naive local time)\"\"\"\n    from datetime import datetime, timedelta\n    obj = datetime.fromtimestamp(timestamp[0])\n    return obj + timedelta(microseconds=int(timestamp[1]))": 1263,
"def _updateItemComboBoxIndex(self, item, column, num):\n        \"\"\"Callback for comboboxes: notifies us that a combobox for the given item and column has changed\"\"\"\n        item._combobox_current_index[column] = num\n        item._combobox_current_value[column] = item._combobox_option_list[column][num][0]": 3358,
"def dict_to_enum_fn(d: Dict[str, Any], enum_class: Type[Enum]) -> Enum:\n    \"\"\"\n    Converts an ``dict`` to a ``Enum``.\n    \"\"\"\n    return enum_class[d['name']]": 5688,
"def _is_override(meta, method):\n        \"\"\"Checks whether given class or instance method has been marked\n        with the ``@override`` decorator.\n        \"\"\"\n        from taipan.objective.modifiers import _OverriddenMethod\n        return isinstance(method, _OverriddenMethod)": 531,
"def _unordered_iterator(self):\n        \"\"\"\n        Return the value of each QuerySet, but also add the '#' property to each\n        return item.\n        \"\"\"\n        for i, qs in zip(self._queryset_idxs, self._querysets):\n            for item in qs:\n                setattr(item, '#', i)\n                yield item": 2051,
"def cfloat64_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes double pointer array to a numpy array.\"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_double)):\n        return np.fromiter(cptr, dtype=np.float64, count=length)\n    else:\n        raise RuntimeError('Expected double pointer')": 64,
"def find_first_in_list(txt: str, str_list: [str]) -> int:  # type: ignore\n    \"\"\"\n    Returns the index of the earliest occurence of an item from a list in a string\n\n    Ex: find_first_in_list('foobar', ['bar', 'fin']) -> 3\n    \"\"\"\n    start = len(txt) + 1\n    for item in str_list:\n        if start > txt.find(item) > -1:\n            start = txt.find(item)\n    return start if len(txt) + 1 > start > -1 else -1": 5545,
"def intround(value):\n    \"\"\"Given a float returns a rounded int. Should give the same result on\n    both Py2/3\n    \"\"\"\n\n    return int(decimal.Decimal.from_float(\n        value).to_integral_value(decimal.ROUND_HALF_EVEN))": 323,
"def mouse_get_pos():\n    \"\"\"\n\n    :return:\n    \"\"\"\n    p = POINT()\n    AUTO_IT.AU3_MouseGetPos(ctypes.byref(p))\n    return p.x, p.y": 3715,
"def delete_all_eggs(self):\n        \"\"\" delete all the eggs in the directory specified \"\"\"\n        path_to_delete = os.path.join(self.egg_directory, \"lib\", \"python\")\n        if os.path.exists(path_to_delete):\n            shutil.rmtree(path_to_delete)": 145,
"def split_every(n, iterable):\n    \"\"\"Returns a generator that spits an iteratable into n-sized chunks. The last chunk may have\n    less than n elements.\n\n    See http://stackoverflow.com/a/22919323/503377.\"\"\"\n    items = iter(iterable)\n    return itertools.takewhile(bool, (list(itertools.islice(items, n)) for _ in itertools.count()))": 663,
"def FindMethodByName(self, name):\n    \"\"\"Searches for the specified method, and returns its descriptor.\"\"\"\n    for method in self.methods:\n      if name == method.name:\n        return method\n    return None": 1374,
"def split_multiline(value):\n    \"\"\"Split a multiline string into a list, excluding blank lines.\"\"\"\n    return [element for element in (line.strip() for line in value.split('\\n'))\n            if element]": 2133,
"def _get_col_index(name):\n    \"\"\"Convert column name to index.\"\"\"\n\n    index = string.ascii_uppercase.index\n    col = 0\n    for c in name.upper():\n        col = col * 26 + index(c) + 1\n    return col": 4617,
"def memory_read(self, start_position: int, size: int) -> memoryview:\n        \"\"\"\n        Read and return a view of ``size`` bytes from memory starting at ``start_position``.\n        \"\"\"\n        return self._memory.read(start_position, size)": 6189,
"def purge_cache(self, object_type):\n        \"\"\" Purge the named cache of all values. If no cache exists for object_type, nothing is done \"\"\"\n        if object_type in self.mapping:\n            cache = self.mapping[object_type]\n            log.debug(\"Purging [{}] cache of {} values.\".format(object_type, len(cache)))\n            cache.purge()": 5001,
"def _is_leap_year(year):\n    \"\"\"Determine if a year is leap year.\n\n    Parameters\n    ----------\n    year : numeric\n\n    Returns\n    -------\n    isleap : array of bools\n    \"\"\"\n    isleap = ((np.mod(year, 4) == 0) &\n              ((np.mod(year, 100) != 0) | (np.mod(year, 400) == 0)))\n    return isleap": 1475,
"def get_login_credentials(args):\n  \"\"\"\n    Gets the login credentials from the user, if not specified while invoking\n    the script.\n    @param args: arguments provided to the script.\n    \"\"\"\n  if not args.username:\n    args.username = raw_input(\"Enter Username: \")\n  if not args.password:\n    args.password = getpass.getpass(\"Enter Password: \")": 3994,
"def isin(elems, line):\n    \"\"\"Check if an element from a list is in a string.\n\n    :type elems: list\n    :type line: str\n\n    \"\"\"\n    found = False\n    for e in elems:\n        if e in line.lower():\n            found = True\n            break\n    return found": 648,
"def _str_to_list(value, separator):\n    \"\"\"Convert a string to a list with sanitization.\"\"\"\n    value_list = [item.strip() for item in value.split(separator)]\n    value_list_sanitized = builtins.list(filter(None, value_list))\n    if len(value_list_sanitized) > 0:\n        return value_list_sanitized\n    else:\n        raise ValueError('Invalid list variable.')": 5723,
"def get_adjacent_matrix(self):\n        \"\"\"Get adjacency matrix.\n\n        Returns:\n            :param adj: adjacency matrix\n            :type adj: np.ndarray\n        \"\"\"\n        edges = self.edges\n        num_edges = len(edges) + 1\n        adj = np.zeros([num_edges, num_edges])\n\n        for k in range(num_edges - 1):\n            adj[edges[k].L, edges[k].R] = 1\n            adj[edges[k].R, edges[k].L] = 1\n\n        return adj": 2149,
"def _gcd_array(X):\n    \"\"\"\n    Return the largest real value h such that all elements in x are integer\n    multiples of h.\n    \"\"\"\n    greatest_common_divisor = 0.0\n    for x in X:\n        greatest_common_divisor = _gcd(greatest_common_divisor, x)\n\n    return greatest_common_divisor": 302,
"def move_up(lines=1, file=sys.stdout):\n    \"\"\" Move the cursor up a number of lines.\n\n        Esc[ValueA:\n        Moves the cursor up by the specified number of lines without changing\n        columns. If the cursor is already on the top line, ANSI.SYS ignores\n        this sequence.\n    \"\"\"\n    move.up(lines).write(file=file)": 2129,
"def py(self, output):\n        \"\"\"Output data as a nicely-formatted python data structure\"\"\"\n        import pprint\n        pprint.pprint(output, stream=self.outfile)": 925,
"def to_json(value, **kwargs):\n        \"\"\"Return a copy of the tuple as a list\n\n        If the tuple contains HasProperties instances, they are serialized.\n        \"\"\"\n        serial_list = [\n            val.serialize(**kwargs) if isinstance(val, HasProperties)\n            else val for val in value\n        ]\n        return serial_list": 4919,
"def get_latex_table(self, parameters=None, transpose=False, caption=None,\n                        label=\"tab:model_params\", hlines=True, blank_fill=\"--\"):  # pragma: no cover\n        \"\"\" Generates a LaTeX table from parameter summaries.\n\n        Parameters\n        ----------\n        parameters : list[str], optional\n            A list of what parameters to include in the table. By default, includes all parameters\n        transpose : bool, optional\n            Defaults to False, which gives each column as a parameter, each chain (framework)\n            as a row. You can swap it so that you have a parameter each row and a framework\n            each column by setting this to True\n        caption : str, optional\n            If you want to generate a caption for the table through Python, use this.\n            Defaults to an empty string\n        label : str, optional\n            If you want to generate a label for the table through Python, use this.\n            Defaults to an empty string\n        hlines : bool, optional\n            Inserts ``\\\\hline`` before and after the header, and at the end of table.\n        blank_fill : str, optional\n            If a framework does not have a particular parameter, will fill that cell of\n            the table with this string.\n\n        Returns\n        -------\n        str\n            the LaTeX table.\n        \"\"\"\n        if parameters is None:\n            parameters = self.parent._all_parameters\n        for p in parameters:\n            assert isinstance(p, str), \\\n                \"Generating a LaTeX table requires all parameters have labels\"\n        num_parameters = len(parameters)\n        num_chains = len(self.parent.chains)\n        fit_values = self.get_summary(squeeze=False)\n        if label is None:\n            label = \"\"\n        if caption is None:\n            caption = \"\"\n\n        end_text = \" \\\\\\\\ \\n\"\n        if transpose:\n            column_text = \"c\" * (num_chains + 1)\n        else:\n            column_text = \"c\" * (num_parameters + 1)\n\n        center_text = \"\"\n        hline_text = \"\\\\hline\\n\"\n        if hlines:\n            center_text += hline_text + \"\\t\\t\"\n        if transpose:\n            center_text += \" & \".join([\"Parameter\"] + [c.name for c in self.parent.chains]) + end_text\n            if hlines:\n                center_text += \"\\t\\t\" + hline_text\n            for p in parameters:\n                arr = [\"\\t\\t\" + p]\n                for chain_res in fit_values:\n                    if p in chain_res:\n                        arr.append(self.get_parameter_text(*chain_res[p], wrap=True))\n                    else:\n                        arr.append(blank_fill)\n                center_text += \" & \".join(arr) + end_text\n        else:\n            center_text += \" & \".join([\"Model\"] + parameters) + end_text\n            if hlines:\n                center_text += \"\\t\\t\" + hline_text\n            for name, chain_res in zip([c.name for c in self.parent.chains], fit_values):\n                arr = [\"\\t\\t\" + name]\n                for p in parameters:\n                    if p in chain_res:\n                        arr.append(self.get_parameter_text(*chain_res[p], wrap=True))\n                    else:\n                        arr.append(blank_fill)\n                center_text += \" & \".join(arr) + end_text\n        if hlines:\n            center_text += \"\\t\\t\" + hline_text\n        final_text = get_latex_table_frame(caption, label) % (column_text, center_text)\n\n        return final_text": 789,
"def _help():\n    \"\"\" Display both SQLAlchemy and Python help statements \"\"\"\n\n    statement = '%s%s' % (shelp, phelp % ', '.join(cntx_.keys()))\n    print statement.strip()": 2266,
"def heappush_max(heap, item):\n    \"\"\"Push item onto heap, maintaining the heap invariant.\"\"\"\n    heap.append(item)\n    _siftdown_max(heap, 0, len(heap) - 1)": 508,
"def first_unique_char(s):\n    \"\"\"\n    :type s: str\n    :rtype: int\n    \"\"\"\n    if (len(s) == 1):\n        return 0\n    ban = []\n    for i in range(len(s)):\n        if all(s[i] != s[k] for k in range(i + 1, len(s))) == True and s[i] not in ban:\n            return i\n        else:\n            ban.append(s[i])\n    return -1": 3503,
"def pick_unused_port(self):\n    \"\"\" Pick an unused port. There is a slight chance that this wont work. \"\"\"\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.bind(('127.0.0.1', 0))\n    _, port = s.getsockname()\n    s.close()\n    return port": 2379,
"def validate(self):\n        \"\"\"Validate the configuration file.\"\"\"\n        validator = Draft4Validator(self.SCHEMA)\n        if not validator.is_valid(self.config):\n            for err in validator.iter_errors(self.config):\n                LOGGER.error(str(err.message))\n            validator.validate(self.config)": 2808,
"def count_rows(self, table, cols='*'):\n        \"\"\"Get the number of rows in a particular table.\"\"\"\n        query = 'SELECT COUNT({0}) FROM {1}'.format(join_cols(cols), wrap(table))\n        result = self.fetch(query)\n        return result if result is not None else 0": 4609,
"def to_index(self, index_type, index_name, includes=None):\n        \"\"\" Create an index field from this field \"\"\"\n        return IndexField(self.name, self.data_type, index_type, index_name, includes)": 3472,
"def _parse_tuple_string(argument):\n        \"\"\" Return a tuple from parsing 'a,b,c,d' -> (a,b,c,d) \"\"\"\n        if isinstance(argument, str):\n            return tuple(int(p.strip()) for p in argument.split(','))\n        return argument": 5669,
"def strip_figures(figure):\n\t\"\"\"\n\tStrips a figure into multiple figures with a trace on each of them\n\n\tParameters:\n\t-----------\n\t\tfigure : Figure\n\t\t\tPlotly Figure\n\t\"\"\"\n\tfig=[]\n\tfor trace in figure['data']:\n\t\tfig.append(dict(data=[trace],layout=figure['layout']))\n\treturn fig": 1715,
"def url_syntax_check(url):  # pragma: no cover\n    \"\"\"\n    Check the syntax of the given URL.\n\n    :param url: The URL to check the syntax for.\n    :type url: str\n\n    :return: The syntax validity.\n    :rtype: bool\n\n    .. warning::\n        If an empty or a non-string :code:`url` is given, we return :code:`None`.\n    \"\"\"\n\n    if url and isinstance(url, str):\n        # The given URL is not empty nor None.\n        # and\n        # * The given URL is a string.\n\n        # We silently load the configuration.\n        load_config(True)\n\n        return Check(url).is_url_valid()\n\n    # We return None, there is nothing to check.\n    return None": 4006,
"def _check_for_int(x):\n    \"\"\"\n    This is a compatibility function that takes a C{float} and converts it to an\n    C{int} if the values are equal.\n    \"\"\"\n    try:\n        y = int(x)\n    except (OverflowError, ValueError):\n        pass\n    else:\n        # There is no way in AMF0 to distinguish between integers and floats\n        if x == x and y == x:\n            return y\n\n    return x": 289,
"def set_trace():\n    \"\"\"Start a Pdb instance at the calling frame, with stdout routed to sys.__stdout__.\"\"\"\n    # https://github.com/nose-devs/nose/blob/master/nose/tools/nontrivial.py\n    pdb.Pdb(stdout=sys.__stdout__).set_trace(sys._getframe().f_back)": 900,
"def _power(ctx, number, power):\n    \"\"\"\n    Returns the result of a number raised to a power\n    \"\"\"\n    return decimal_pow(conversions.to_decimal(number, ctx), conversions.to_decimal(power, ctx))": 3816,
"def _change_height(self, ax, new_value):\n        \"\"\"Make bars in horizontal bar chart thinner\"\"\"\n        for patch in ax.patches:\n            current_height = patch.get_height()\n            diff = current_height - new_value\n\n            # we change the bar height\n            patch.set_height(new_value)\n\n            # we recenter the bar\n            patch.set_y(patch.get_y() + diff * .5)": 1996,
"def add_to_js(self, name, var):\n        \"\"\"Add an object to Javascript.\"\"\"\n        frame = self.page().mainFrame()\n        frame.addToJavaScriptWindowObject(name, var)": 128,
"def dot_v2(vec1, vec2):\n    \"\"\"Return the dot product of two vectors\"\"\"\n\n    return vec1.x * vec2.x + vec1.y * vec2.y": 3581,
"def parsed_args():\n    parser = argparse.ArgumentParser(description=\"\"\"python runtime functions\"\"\", epilog=\"\")\n    parser.add_argument('command',nargs='*',\n        help=\"Name of the function to run with arguments\")\n    args = parser.parse_args()\n    return (args, parser)": 3283,
"def vline(self, x, y, height, color):\n        \"\"\"Draw a vertical line up to a given length.\"\"\"\n        self.rect(x, y, 1, height, color, fill=True)": 3875,
"def load_yaml(filepath):\n    \"\"\"Convenience function for loading yaml-encoded data from disk.\"\"\"\n    with open(filepath) as f:\n        txt = f.read()\n    return yaml.load(txt)": 1096,
"def is_symlink(self):\n        \"\"\"\n        Whether this path is a symbolic link.\n        \"\"\"\n        try:\n            return S_ISLNK(self.lstat().st_mode)\n        except OSError as e:\n            if e.errno != ENOENT:\n                raise\n            # Path doesn't exist\n            return False": 1607,
"def _not_none(items):\n    \"\"\"Whether the item is a placeholder or contains a placeholder.\"\"\"\n    if not isinstance(items, (tuple, list)):\n        items = (items,)\n    return all(item is not _none for item in items)": 208,
"def drop_column(self, tablename: str, fieldname: str) -> int:\n        \"\"\"Drops (deletes) a column from an existing table.\"\"\"\n        sql = \"ALTER TABLE {} DROP COLUMN {}\".format(tablename, fieldname)\n        log.info(sql)\n        return self.db_exec_literal(sql)": 6069,
"def center_eigenvalue_diff(mat):\n    \"\"\"Compute the eigvals of mat and then find the center eigval difference.\"\"\"\n    N = len(mat)\n    evals = np.sort(la.eigvals(mat))\n    diff = np.abs(evals[N/2] - evals[N/2-1])\n    return diff": 445,
"def list_adb_devices_by_usb_id():\n    \"\"\"List the usb id of all android devices connected to the computer that\n    are detected by adb.\n\n    Returns:\n        A list of strings that are android device usb ids. Empty if there's\n        none.\n    \"\"\"\n    out = adb.AdbProxy().devices(['-l'])\n    clean_lines = new_str(out, 'utf-8').strip().split('\\n')\n    results = []\n    for line in clean_lines:\n        tokens = line.strip().split()\n        if len(tokens) > 2 and tokens[1] == 'device':\n            results.append(tokens[2])\n    return results": 6061,
"def to_capitalized_camel_case(snake_case_string):\n    \"\"\"\n    Convert a string from snake case to camel case with the first letter capitalized. For example, \"some_var\"\n    would become \"SomeVar\".\n\n    :param snake_case_string: Snake-cased string to convert to camel case.\n    :returns: Camel-cased version of snake_case_string.\n    \"\"\"\n    parts = snake_case_string.split('_')\n    return ''.join([i.title() for i in parts])": 1625,
"def get_number(s, cast=int):\n    \"\"\"\n    Try to get a number out of a string, and cast it.\n    \"\"\"\n    import string\n    d = \"\".join(x for x in str(s) if x in string.digits)\n    return cast(d)": 40,
"def _import(module, cls):\n    \"\"\"\n    A messy way to import library-specific classes.\n    TODO: I should really make a factory class or something, but I'm lazy.\n    Plus, factories remind me a lot of java...\n    \"\"\"\n    global Scanner\n\n    try:\n        cls = str(cls)\n        mod = __import__(str(module), globals(), locals(), [cls], 1)\n        Scanner = getattr(mod, cls)\n    except ImportError:\n        pass": 3089,
"def recClearTag(element):\n    \"\"\"Applies maspy.xml.clearTag() to the tag attribute of the \"element\" and\n    recursively to all child elements.\n\n    :param element: an :instance:`xml.etree.Element`\n    \"\"\"\n    children = element.getchildren()\n    if len(children) > 0:\n        for child in children:\n            recClearTag(child)\n    element.tag = clearTag(element.tag)": 5570,
"def save_session(self, sid, session, namespace=None):\n        \"\"\"Store the user session for a client.\n\n        The only difference with the :func:`socketio.Server.save_session`\n        method is that when the ``namespace`` argument is not given the\n        namespace associated with the class is used.\n        \"\"\"\n        return self.server.save_session(\n            sid, session, namespace=namespace or self.namespace)": 1242,
"def library(func):\n    \"\"\"\n    A decorator for providing a unittest with a library and have it called only\n    once.\n    \"\"\"\n    @wraps(func)\n    def wrapped(*args, **kwargs):\n        \"\"\"Transparent wrapper.\"\"\"\n        return func(*args, **kwargs)\n    SINGLES.append(wrapped)\n    return wrapped": 4501,
"def vars_(self):\n        \"\"\" Returns symbol instances corresponding to variables\n        of the current scope.\n        \"\"\"\n        return [x for x in self[self.current_scope].values() if x.class_ == CLASS.var]": 3654,
"def stop(self):\n        \"\"\"Stop stream.\"\"\"\n        if self.stream and self.stream.session.state != STATE_STOPPED:\n            self.stream.stop()": 4342,
"def send_file(self, local_path, remote_path, user='root', unix_mode=None):\n        \"\"\"Upload a local file on the remote host.\n        \"\"\"\n        self.enable_user(user)\n        return self.ssh_pool.send_file(user, local_path, remote_path, unix_mode=unix_mode)": 2924,
"def reduce_fn(x):\n    \"\"\"\n    Aggregation function to get the first non-zero value.\n    \"\"\"\n    values = x.values if pd and isinstance(x, pd.Series) else x\n    for v in values:\n        if not is_nan(v):\n            return v\n    return np.NaN": 621,
"def _get_var_from_string(item):\n    \"\"\" Get resource variable. \"\"\"\n    modname, varname = _split_mod_var_names(item)\n    if modname:\n        mod = __import__(modname, globals(), locals(), [varname], -1)\n        return getattr(mod, varname)\n    else:\n        return globals()[varname]": 3596,
"def setwinsize(self, rows, cols):\n        \"\"\"Set the terminal window size of the child tty.\n        \"\"\"\n        self._winsize = (rows, cols)\n        self.pty.set_size(cols, rows)": 2629,
"def dict_to_numpy_array(d):\n    \"\"\"\n    Convert a dict of 1d array to a numpy recarray\n    \"\"\"\n    return fromarrays(d.values(), np.dtype([(str(k), v.dtype) for k, v in d.items()]))": 1583,
"def default_diff(latest_config, current_config):\n    \"\"\"Determine if two revisions have actually changed.\"\"\"\n    # Pop off the fields we don't care about:\n    pop_no_diff_fields(latest_config, current_config)\n\n    diff = DeepDiff(\n        latest_config,\n        current_config,\n        ignore_order=True\n    )\n    return diff": 4047,
"def get_width():\n    \"\"\"Get terminal width\"\"\"\n    # Get terminal size\n    ws = struct.pack(\"HHHH\", 0, 0, 0, 0)\n    ws = fcntl.ioctl(sys.stdout.fileno(), termios.TIOCGWINSZ, ws)\n    lines, columns, x, y = struct.unpack(\"HHHH\", ws)\n    width = min(columns * 39 // 40, columns - 2)\n    return width": 1907,
"def top(self, topn=10):\n        \"\"\"\n        Get a list of the top ``topn`` features in this :class:`.Feature`\\.\n\n        Examples\n        --------\n\n        .. code-block:: python\n\n        >>> myFeature = Feature([('the', 2), ('pine', 1), ('trapezoid', 5)])\n        >>> myFeature.top(1)\n        [('trapezoid', 5)]\n\n        Parameters\n        ----------\n        topn : int\n\n        Returns\n        -------\n        list\n        \"\"\"\n        return [self[i] for i in argsort(list(zip(*self))[1])[::-1][:topn]]": 5556,
"def get_file_md5sum(path):\n    \"\"\"Calculate the MD5 hash for a file.\"\"\"\n    with open(path, 'rb') as fh:\n        h = str(hashlib.md5(fh.read()).hexdigest())\n    return h": 1881,
"def mkdir(dir, enter):\n    \"\"\"Create directory with template for topic of the current environment\n\n    \"\"\"\n\n    if not os.path.exists(dir):\n        os.makedirs(dir)": 54,
"def check_lengths(*arrays):\n    \"\"\"\n    tool to ensure input and output data have the same number of samples\n\n    Parameters\n    ----------\n    *arrays : iterable of arrays to be checked\n\n    Returns\n    -------\n    None\n    \"\"\"\n    lengths = [len(array) for array in arrays]\n    if len(np.unique(lengths)) > 1:\n        raise ValueError('Inconsistent data lengths: {}'.format(lengths))": 5934,
"def generate_chunks(string, num_chars):\n    \"\"\"Yield num_chars-character chunks from string.\"\"\"\n    for start in range(0, len(string), num_chars):\n        yield string[start:start+num_chars]": 5338,
"def _validate_pos(df):\n    \"\"\"Validates the returned positional object\n    \"\"\"\n    assert isinstance(df, pd.DataFrame)\n    assert [\"seqname\", \"position\", \"strand\"] == df.columns.tolist()\n    assert df.position.dtype == np.dtype(\"int64\")\n    assert df.strand.dtype == np.dtype(\"O\")\n    assert df.seqname.dtype == np.dtype(\"O\")\n    return df": 740,
"def findfirst(f, coll):\n    \"\"\"Return first occurrence matching f, otherwise None\"\"\"\n    result = list(dropwhile(f, coll))\n    return result[0] if result else None": 598,
"def get_numbers(s):\n    \"\"\"Extracts all integers from a string an return them in a list\"\"\"\n\n    result = map(int, re.findall(r'[0-9]+', unicode(s)))\n    return result + [1] * (2 - len(result))": 2828,
"def assert_is_not(expected, actual, message=None, extra=None):\n    \"\"\"Raises an AssertionError if expected is actual.\"\"\"\n    assert expected is not actual, _assert_fail_message(\n        message, expected, actual, \"is\", extra\n    )": 1307,
"def start(self, test_connection=True):\n        \"\"\"Starts connection to server if not existent.\n\n        NO-OP if connection is already established.\n        Makes ping-pong test as well if desired.\n\n        \"\"\"\n        if self._context is None:\n            self._logger.debug('Starting Client')\n            self._context = zmq.Context()\n            self._poll = zmq.Poller()\n            self._start_socket()\n            if test_connection:\n                self.test_ping()": 5466,
"def get_from_gnucash26_date(date_str: str) -> date:\n    \"\"\" Creates a datetime from GnuCash 2.6 date string \"\"\"\n    date_format = \"%Y%m%d\"\n    result = datetime.strptime(date_str, date_format).date()\n    return result": 5766,
"def flatten_list(l: List[list]) -> list:\n    \"\"\" takes a list of lists, l and returns a flat list\n    \"\"\"\n    return [v for inner_l in l for v in inner_l]": 5705,
"def get_labels(labels):\n    \"\"\"Create unique labels.\"\"\"\n    label_u = unique_labels(labels)\n    label_u_line = [i + \"_line\" for i in label_u]\n    return label_u, label_u_line": 4033,
"def set_mlimits(self, row, column, min=None, max=None):\n        \"\"\"Set limits for the point meta (colormap).\n\n        Point meta values outside this range will be clipped.\n\n        :param min: value for start of the colormap.\n        :param max: value for end of the colormap.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.set_mlimits(min, max)": 4994,
"def iprotate(l, steps=1):\n    r\"\"\"Like rotate, but modifies `l` in-place.\n\n    >>> l = [1,2,3]\n    >>> iprotate(l) is l\n    True\n    >>> l\n    [2, 3, 1]\n    >>> iprotate(iprotate(l, 2), -3)\n    [1, 2, 3]\n\n    \"\"\"\n    if len(l):\n        steps %= len(l)\n        if steps:\n            firstPart = l[:steps]\n            del l[:steps]\n            l.extend(firstPart)\n    return l": 5735,
"def _remove_from_index(index, obj):\n    \"\"\"Removes object ``obj`` from the ``index``.\"\"\"\n    try:\n        index.value_map[indexed_value(index, obj)].remove(obj.id)\n    except KeyError:\n        pass": 2482,
"def wordify(text):\n    \"\"\"Generate a list of words given text, removing punctuation.\n\n    Parameters\n    ----------\n    text : unicode\n        A piece of english text.\n\n    Returns\n    -------\n    words : list\n        List of words.\n    \"\"\"\n    stopset = set(nltk.corpus.stopwords.words('english'))\n    tokens = nltk.WordPunctTokenizer().tokenize(text)\n    return [w for w in tokens if w not in stopset]": 844,
"def strip_columns(tab):\n    \"\"\"Strip whitespace from string columns.\"\"\"\n    for colname in tab.colnames:\n        if tab[colname].dtype.kind in ['S', 'U']:\n            tab[colname] = np.core.defchararray.strip(tab[colname])": 1437,
"def get_last_day_of_month(t: datetime) -> int:\n    \"\"\"\n    Returns day number of the last day of the month\n    :param t: datetime\n    :return: int\n    \"\"\"\n    tn = t + timedelta(days=32)\n    tn = datetime(year=tn.year, month=tn.month, day=1)\n    tt = tn - timedelta(hours=1)\n    return tt.day": 5645,
"def angle_between_vectors(x, y):\n    \"\"\" Compute the angle between vector x and y \"\"\"\n    dp = dot_product(x, y)\n    if dp == 0:\n        return 0\n    xm = magnitude(x)\n    ym = magnitude(y)\n    return math.acos(dp / (xm*ym)) * (180. / math.pi)": 1665,
"def ibatch(iterable, size):\n    \"\"\"Yield a series of batches from iterable, each size elements long.\"\"\"\n    source = iter(iterable)\n    while True:\n        batch = itertools.islice(source, size)\n        yield itertools.chain([next(batch)], batch)": 2638,
"def disassemble_file(filename, outstream=None):\n    \"\"\"\n    disassemble Python byte-code file (.pyc)\n\n    If given a Python source file (\".py\") file, we'll\n    try to find the corresponding compiled object.\n    \"\"\"\n    filename = check_object_path(filename)\n    (version, timestamp, magic_int, co, is_pypy,\n     source_size) = load_module(filename)\n    if type(co) == list:\n        for con in co:\n            disco(version, con, outstream)\n    else:\n        disco(version, co, outstream, is_pypy=is_pypy)\n    co = None": 1951,
"def _finish(self):\n        \"\"\"\n        Closes and waits for subprocess to exit.\n        \"\"\"\n        if self._process.returncode is None:\n            self._process.stdin.flush()\n            self._process.stdin.close()\n            self._process.wait()\n            self.closed = True": 3531,
"def _delete_keys(dct, keys):\n    \"\"\"Returns a copy of dct without `keys` keys\n    \"\"\"\n    c = deepcopy(dct)\n    assert isinstance(keys, list)\n    for k in keys:\n        c.pop(k)\n    return c": 2569,
"def process_instance(self, instance):\n        self.log.debug(\"e = mc^2\")\n        self.log.info(\"About to fail..\")\n        self.log.warning(\"Failing.. soooon..\")\n        self.log.critical(\"Ok, you're done.\")\n        assert False, \"\"\"ValidateFailureMock was destined to fail..\n\nHere's some extended information about what went wrong.\n\nIt has quite the long string associated with it, including\na few newlines and a list.\n\n- Item 1\n- Item 2\n\n\"\"\"": 2102,
"def remove_empty_text(utterances: List[Utterance]) -> List[Utterance]:\n    \"\"\"Remove empty utterances from a list of utterances\n    Args:\n        utterances: The list of utterance we are processing\n    \"\"\"\n    return [utter for utter in utterances if utter.text.strip() != \"\"]": 5557,
"def _sub_patterns(patterns, text):\n    \"\"\"\n    Apply re.sub to bunch of (pattern, repl)\n    \"\"\"\n    for pattern, repl in patterns:\n        text = re.sub(pattern, repl, text)\n    return text": 773,
"def validate_multiindex(self, obj):\n        \"\"\"validate that we can store the multi-index; reset and return the\n        new object\n        \"\"\"\n        levels = [l if l is not None else \"level_{0}\".format(i)\n                  for i, l in enumerate(obj.index.names)]\n        try:\n            return obj.reset_index(), levels\n        except ValueError:\n            raise ValueError(\"duplicate names/columns in the multi-index when \"\n                             \"storing as a table\")": 998,
"def __or__(self, other):\n        \"\"\"Return the union of two RangeSets as a new RangeSet.\n\n        (I.e. all elements that are in either set.)\n        \"\"\"\n        if not isinstance(other, set):\n            return NotImplemented\n        return self.union(other)": 3372,
"def _decode(self, obj, context):\n        \"\"\"\n        Get the python representation of the obj\n        \"\"\"\n        return b''.join(map(int2byte, [c + 0x60 for c in bytearray(obj)])).decode(\"utf8\")": 4067,
"def roundClosestValid(val, res, decimals=None):\n        \"\"\" round to closest resolution \"\"\"\n        if decimals is None and \".\" in str(res):\n            decimals = len(str(res).split('.')[1])\n\n        return round(round(val / res) * res, decimals)": 3832,
"def remove_once(gset, elem):\n    \"\"\"Remove the element from a set, lists or dict.\n    \n        >>> L = [\"Lucy\"]; S = set([\"Sky\"]); D = { \"Diamonds\": True };\n        >>> remove_once(L, \"Lucy\"); remove_once(S, \"Sky\"); remove_once(D, \"Diamonds\");\n        >>> print L, S, D\n        [] set([]) {}\n\n    Returns the element if it was removed. Raises one of the exceptions in \n    :obj:`RemoveError` otherwise.\n    \"\"\"\n    remove = getattr(gset, 'remove', None)\n    if remove is not None: remove(elem)\n    else: del gset[elem]\n    return elem": 5741,
"def generate_id(self, obj):\n        \"\"\"Generate unique document id for ElasticSearch.\"\"\"\n        object_type = type(obj).__name__.lower()\n        return '{}_{}'.format(object_type, self.get_object_id(obj))": 4302,
"def clean_map(obj: Mapping[Any, Any]) -> Mapping[Any, Any]:\n    \"\"\"\n    Return a new copied dictionary without the keys with ``None`` values from\n    the given Mapping object.\n    \"\"\"\n    return {k: v for k, v in obj.items() if v is not None}": 5748,
"def _writable_dir(path):\n    \"\"\"Whether `path` is a directory, to which the user has write access.\"\"\"\n    return os.path.isdir(path) and os.access(path, os.W_OK)": 651,
"def _to_corrected_pandas_type(dt):\n    \"\"\"\n    When converting Spark SQL records to Pandas DataFrame, the inferred data type may be wrong.\n    This method gets the corrected data type for Pandas if that type may be inferred uncorrectly.\n    \"\"\"\n    import numpy as np\n    if type(dt) == ByteType:\n        return np.int8\n    elif type(dt) == ShortType:\n        return np.int16\n    elif type(dt) == IntegerType:\n        return np.int32\n    elif type(dt) == FloatType:\n        return np.float32\n    else:\n        return None": 170,
"def setRect(self, rect):\n\t\t\"\"\"\n\t\tSets the window bounds from a tuple of (x,y,w,h)\n\t\t\"\"\"\n\t\tself.x, self.y, self.w, self.h = rect": 5190,
"def adapter(data, headers, **kwargs):\n    \"\"\"Wrap vertical table in a function for TabularOutputFormatter.\"\"\"\n    keys = ('sep_title', 'sep_character', 'sep_length')\n    return vertical_table(data, headers, **filter_dict_by_key(kwargs, keys))": 2196,
"def select_from_array(cls, array, identifier):\n        \"\"\"Return a region from a numpy array.\n        \n        :param array: :class:`numpy.ndarray`\n        :param identifier: value representing the region to select in the array\n        :returns: :class:`jicimagelib.region.Region`\n        \"\"\"\n\n        base_array = np.zeros(array.shape)\n        array_coords = np.where(array == identifier)\n        base_array[array_coords] = 1\n\n        return cls(base_array)": 3783,
"def less_strict_bool(x):\n    \"\"\"Idempotent and None-safe version of strict_bool.\"\"\"\n    if x is None:\n        return False\n    elif x is True or x is False:\n        return x\n    else:\n        return strict_bool(x)": 908,
"def is_writable_by_others(filename):\n    \"\"\"Check if file or directory is world writable.\"\"\"\n    mode = os.stat(filename)[stat.ST_MODE]\n    return mode & stat.S_IWOTH": 3186,
"def show(self):\n        \"\"\" Ensure the widget is shown.\n        Calling this method will also set the widget visibility to True.\n        \"\"\"\n        self.visible = True\n        if self.proxy_is_active:\n            self.proxy.ensure_visible()": 4884,
"def click_estimate_slope():\n    \"\"\"\n    Takes two clicks and returns the slope.\n\n    Right-click aborts.\n    \"\"\"\n\n    c1 = _pylab.ginput()\n    if len(c1)==0:\n        return None\n\n    c2 = _pylab.ginput()\n    if len(c2)==0:\n        return None\n\n    return (c1[0][1]-c2[0][1])/(c1[0][0]-c2[0][0])": 1724,
"def checkbox_uncheck(self, force_check=False):\n        \"\"\"\n        Wrapper to uncheck a checkbox\n        \"\"\"\n        if self.get_attribute('checked'):\n            self.click(force_click=force_check)": 1582,
"def deserialize_ndarray_npy(d):\n    \"\"\"\n    Deserializes a JSONified :obj:`numpy.ndarray` that was created using numpy's\n    :obj:`save` function.\n\n    Args:\n        d (:obj:`dict`): A dictionary representation of an :obj:`ndarray` object, created\n            using :obj:`numpy.save`.\n\n    Returns:\n        An :obj:`ndarray` object.\n    \"\"\"\n    with io.BytesIO() as f:\n        f.write(json.loads(d['npy']).encode('latin-1'))\n        f.seek(0)\n        return np.load(f)": 231,
"def tag_to_dict(html):\n    \"\"\"Extract tag's attributes into a `dict`.\"\"\"\n\n    element = document_fromstring(html).xpath(\"//html/body/child::*\")[0]\n    attributes = dict(element.attrib)\n    attributes[\"text\"] = element.text_content()\n    return attributes": 5031,
"def slugify(s, delimiter='-'):\n    \"\"\"\n    Normalize `s` into ASCII and replace non-word characters with `delimiter`.\n    \"\"\"\n    s = unicodedata.normalize('NFKD', to_unicode(s)).encode('ascii', 'ignore').decode('ascii')\n    return RE_SLUG.sub(delimiter, s).strip(delimiter).lower()": 4718,
"def OnUpdateFigurePanel(self, event):\n        \"\"\"Redraw event handler for the figure panel\"\"\"\n\n        if self.updating:\n            return\n\n        self.updating = True\n        self.figure_panel.update(self.get_figure(self.code))\n        self.updating = False": 1999,
"def _hash_the_file(hasher, filename):\n    \"\"\"Helper function for creating hash functions.\n\n    See implementation of :func:`dtoolcore.filehasher.shasum`\n    for more usage details.\n    \"\"\"\n    BUF_SIZE = 65536\n    with open(filename, 'rb') as f:\n        buf = f.read(BUF_SIZE)\n        while len(buf) > 0:\n            hasher.update(buf)\n            buf = f.read(BUF_SIZE)\n    return hasher": 5995,
"def get_power(self):\n        \"\"\"Check if the device is on.\"\"\"\n        power = (yield from self.handle_int(self.API.get('power')))\n        return bool(power)": 4170,
"def get_hash(self, handle):\n        \"\"\"Return the hash.\"\"\"\n        fpath = self._fpath_from_handle(handle)\n        return DiskStorageBroker.hasher(fpath)": 4926,
"def cpu_count() -> int:\n    \"\"\"Returns the number of processors on this machine.\"\"\"\n    if multiprocessing is None:\n        return 1\n    try:\n        return multiprocessing.cpu_count()\n    except NotImplementedError:\n        pass\n    try:\n        return os.sysconf(\"SC_NPROCESSORS_CONF\")\n    except (AttributeError, ValueError):\n        pass\n    gen_log.error(\"Could not detect number of processors; assuming 1\")\n    return 1": 5653,
"def is_in(self, search_list, pair):\n        \"\"\"\n        If pair is in search_list, return the index. Otherwise return -1\n        \"\"\"\n        index = -1\n        for nr, i in enumerate(search_list):\n            if(np.all(i == pair)):\n                return nr\n        return index": 2444,
"def getAllTriples(self):\n        \"\"\"Returns:\n\n        list of tuples : Each tuple holds a subject, predicate, object triple\n\n        \"\"\"\n        return [(str(s), str(p), str(o)) for s, p, o in self]": 5351,
"def iter_finds(regex_obj, s):\n    \"\"\"Generate all matches found within a string for a regex and yield each match as a string\"\"\"\n    if isinstance(regex_obj, str):\n        for m in re.finditer(regex_obj, s):\n            yield m.group()\n    else:\n        for m in regex_obj.finditer(s):\n            yield m.group()": 326,
"def strip_comments(string, comment_symbols=frozenset(('#', '//'))):\n    \"\"\"Strip comments from json string.\n\n    :param string: A string containing json with comments started by comment_symbols.\n    :param comment_symbols: Iterable of symbols that start a line comment (default # or //).\n    :return: The string with the comments removed.\n    \"\"\"\n    lines = string.splitlines()\n    for k in range(len(lines)):\n        for symbol in comment_symbols:\n            lines[k] = strip_comment_line_with_symbol(lines[k], start=symbol)\n    return '\\n'.join(lines)": 3569,
"def is_line_in_file(filename: str, line: str) -> bool:\n    \"\"\"\n    Detects whether a line is present within a file.\n\n    Args:\n        filename: file to check\n        line: line to search for (as an exact match)\n    \"\"\"\n    assert \"\\n\" not in line\n    with open(filename, \"r\") as file:\n        for fileline in file:\n            if fileline == line:\n                return True\n        return False": 5707,
"async def async_run(self) -> None:\n        \"\"\"\n        Asynchronously run the worker, does not close connections. Useful when testing.\n        \"\"\"\n        self.main_task = self.loop.create_task(self.main())\n        await self.main_task": 5728,
"def has_attribute(module_name, attribute_name):\n    \"\"\"Is this attribute present?\"\"\"\n    init_file = '%s/__init__.py' % module_name\n    return any(\n        [attribute_name in init_line for init_line in open(init_file).readlines()]\n    )": 1239,
"def drop_bad_characters(text):\n    \"\"\"Takes a text and drops all non-printable and non-ascii characters and\n    also any whitespace characters that aren't space.\n\n    :arg str text: the text to fix\n\n    :returns: text with all bad characters dropped\n\n    \"\"\"\n    # Strip all non-ascii and non-printable characters\n    text = ''.join([c for c in text if c in ALLOWED_CHARS])\n    return text": 1217,
"def imapchain(*a, **kwa):\n    \"\"\" Like map but also chains the results. \"\"\"\n\n    imap_results = map( *a, **kwa )\n    return itertools.chain( *imap_results )": 3696,
"def clean_df(df, fill_nan=True, drop_empty_columns=True):\n    \"\"\"Clean a pandas dataframe by:\n        1. Filling empty values with Nan\n        2. Dropping columns with all empty values\n\n    Args:\n        df: Pandas DataFrame\n        fill_nan (bool): If any empty values (strings, None, etc) should be replaced with NaN\n        drop_empty_columns (bool): If columns whose values are all empty should be dropped\n\n    Returns:\n        DataFrame: cleaned DataFrame\n\n    \"\"\"\n    if fill_nan:\n        df = df.fillna(value=np.nan)\n    if drop_empty_columns:\n        df = df.dropna(axis=1, how='all')\n    return df.sort_index()": 2333,
"def table_width(self):\n        \"\"\"Return the width of the table including padding and borders.\"\"\"\n        outer_widths = max_dimensions(self.table_data, self.padding_left, self.padding_right)[2]\n        outer_border = 2 if self.outer_border else 0\n        inner_border = 1 if self.inner_column_border else 0\n        return table_width(outer_widths, outer_border, inner_border)": 2671,
"def llen(self, name):\n        \"\"\"\n        Returns the length of the list.\n\n        :param name: str     the name of the redis key\n        :return: Future()\n        \"\"\"\n        with self.pipe as pipe:\n            return pipe.llen(self.redis_key(name))": 3940,
"def _prepare_proxy(self, conn):\n        \"\"\"\n        Establish tunnel connection early, because otherwise httplib\n        would improperly set Host: header to proxy's IP:port.\n        \"\"\"\n        conn.set_tunnel(self._proxy_host, self.port, self.proxy_headers)\n        conn.connect()": 2519,
"def is_value_type_valid_for_exact_conditions(self, value):\n    \"\"\" Method to validate if the value is valid for exact match type evaluation.\n\n    Args:\n      value: Value to validate.\n\n    Returns:\n      Boolean: True if value is a string, boolean, or number. Otherwise False.\n    \"\"\"\n    # No need to check for bool since bool is a subclass of int\n    if isinstance(value, string_types) or isinstance(value, (numbers.Integral, float)):\n      return True\n\n    return False": 3056,
"def filter_none(list_of_points):\n    \"\"\"\n    \n    :param list_of_points: \n    :return: list_of_points with None's removed\n    \"\"\"\n    remove_elementnone = filter(lambda p: p is not None, list_of_points)\n    remove_sublistnone = filter(lambda p: not contains_none(p), remove_elementnone)\n    return list(remove_sublistnone)": 1219,
"def caller_locals():\n    \"\"\"Get the local variables in the caller's frame.\"\"\"\n    import inspect\n    frame = inspect.currentframe()\n    try:\n        return frame.f_back.f_back.f_locals\n    finally:\n        del frame": 4156,
"def fft_bandpassfilter(data, fs, lowcut, highcut):\n    \"\"\"\n    http://www.swharden.com/blog/2009-01-21-signal-filtering-with-python/#comment-16801\n    \"\"\"\n    fft = np.fft.fft(data)\n    # n = len(data)\n    # timestep = 1.0 / fs\n    # freq = np.fft.fftfreq(n, d=timestep)\n    bp = fft.copy()\n\n    # Zero out fft coefficients\n    # bp[10:-10] = 0\n\n    # Normalise\n    # bp *= real(fft.dot(fft))/real(bp.dot(bp))\n\n    bp *= fft.dot(fft) / bp.dot(bp)\n\n    # must multipy by 2 to get the correct amplitude\n    ibp = 12 * np.fft.ifft(bp)\n    return ibp": 1552,
"def _reshuffle(mat, shape):\n    \"\"\"Reshuffle the indicies of a bipartite matrix A[ij,kl] -> A[lj,ki].\"\"\"\n    return np.reshape(\n        np.transpose(np.reshape(mat, shape), (3, 1, 2, 0)),\n        (shape[3] * shape[1], shape[0] * shape[2]))": 5652,
"def distinct(l):\n    \"\"\"\n    Return a list where the duplicates have been removed.\n\n    Args:\n        l (list): the list to filter.\n\n    Returns:\n        list: the same list without duplicates.\n    \"\"\"\n    seen = set()\n    seen_add = seen.add\n    return (_ for _ in l if not (_ in seen or seen_add(_)))": 2294,
"def round_array(array_in):\n    \"\"\"\n    arr_out = round_array(array_in)\n\n    Rounds an array and recasts it to int. Also works on scalars.\n    \"\"\"\n    if isinstance(array_in, ndarray):\n        return np.round(array_in).astype(int)\n    else:\n        return int(np.round(array_in))": 1487,
"def file_empty(fp):\n    \"\"\"Determine if a file is empty or not.\"\"\"\n    # for python 2 we need to use a homemade peek()\n    if six.PY2:\n        contents = fp.read()\n        fp.seek(0)\n        return not bool(contents)\n\n    else:\n        return not fp.peek()": 286,
"def get_tri_area(pts):\n    \"\"\"\n    Given a list of coords for 3 points,\n    Compute the area of this triangle.\n\n    Args:\n        pts: [a, b, c] three points\n    \"\"\"\n    a, b, c = pts[0], pts[1], pts[2]\n    v1 = np.array(b) - np.array(a)\n    v2 = np.array(c) - np.array(a)\n    area_tri = abs(sp.linalg.norm(sp.cross(v1, v2)) / 2)\n    return area_tri": 58,
"def copy(obj):\n    def copy(self):\n        \"\"\"\n        Copy self to a new object.\n        \"\"\"\n        from copy import deepcopy\n\n        return deepcopy(self)\n    obj.copy = copy\n    return obj": 1395,
"def _heapify_max(x):\n    \"\"\"Transform list into a maxheap, in-place, in O(len(x)) time.\"\"\"\n    n = len(x)\n    for i in reversed(range(n//2)):\n        _siftup_max(x, i)": 511,
"def information(filename):\n    \"\"\"Returns the file exif\"\"\"\n    check_if_this_file_exist(filename)\n    filename = os.path.abspath(filename)\n    result = get_json(filename)\n    result = result[0]\n    return result": 2145,
"def get_last_weekday_in_month(year, month, weekday):\n        \"\"\"Get the last weekday in a given month. e.g:\n\n        >>> # the last monday in Jan 2013\n        >>> Calendar.get_last_weekday_in_month(2013, 1, MON)\n        datetime.date(2013, 1, 28)\n        \"\"\"\n        day = date(year, month, monthrange(year, month)[1])\n        while True:\n            if day.weekday() == weekday:\n                break\n            day = day - timedelta(days=1)\n        return day": 5667,
"def argmax(self, rows: List[Row], column: ComparableColumn) -> List[Row]:\n        \"\"\"\n        Takes a list of rows and a column name and returns a list containing a single row (dict from\n        columns to cells) that has the maximum numerical value in the given column. We return a list\n        instead of a single dict to be consistent with the return type of ``select`` and\n        ``all_rows``.\n        \"\"\"\n        if not rows:\n            return []\n        value_row_pairs = [(row.values[column.name], row) for row in rows]\n        if not value_row_pairs:\n            return []\n        # Returns a list containing the row with the max cell value.\n        return [sorted(value_row_pairs, key=lambda x: x[0], reverse=True)[0][1]]": 5799,
"def negate(self):\n        \"\"\"Reverse the range\"\"\"\n        self.from_value, self.to_value = self.to_value, self.from_value\n        self.include_lower, self.include_upper = self.include_upper, self.include_lower": 1685,
"def quote(s, unsafe='/'):\n    \"\"\"Pass in a dictionary that has unsafe characters as the keys, and the percent\n    encoded value as the value.\"\"\"\n    res = s.replace('%', '%25')\n    for c in unsafe:\n        res = res.replace(c, '%' + (hex(ord(c)).upper())[2:])\n    return res": 905,
"def plot_kde(data, ax, title=None, color='r', fill_bt=True):\n    \"\"\"\n    Plot a smoothed (by kernel density estimate) histogram.\n    :type data: numpy array\n    :param data: An array containing the data to be plotted\n\n    :type ax: matplotlib.Axes\n    :param ax: The Axes object to draw to\n\n    :type title: str\n    :param title: The plot title\n\n    :type color: str\n    :param color: The color of the histogram line and fill. Note that the fill\n                  will be plotted with an alpha of 0.35.\n\n    :type fill_bt: bool\n    :param fill_bt: Specify whether to fill the area beneath the histogram line\n    \"\"\"\n    if isinstance(data, list):\n        data = np.asarray(data)\n    e = kde.KDEUnivariate(data.astype(np.float))\n    e.fit()\n    ax.plot(e.support, e.density, color=color, alpha=0.9, linewidth=2.25)\n    if fill_bt:\n        ax.fill_between(e.support, e.density, alpha=.35, zorder=1,\n                        antialiased=True, color=color)\n    if title is not None:\n        t = ax.set_title(title)\n        t.set_y(1.05)": 4630,
"def normalize(numbers):\n    \"\"\"Multiply each number by a constant such that the sum is 1.0\n    >>> normalize([1,2,1])\n    [0.25, 0.5, 0.25]\n    \"\"\"\n    total = float(sum(numbers))\n    return [n / total for n in numbers]": 5632,
"def _linearInterpolationTransformMatrix(matrix1, matrix2, value):\n    \"\"\" Linear, 'oldstyle' interpolation of the transform matrix.\"\"\"\n    return tuple(_interpolateValue(matrix1[i], matrix2[i], value) for i in range(len(matrix1)))": 1274,
"def get_public_members(obj):\n    \"\"\"\n    Retrieves a list of member-like objects (members or properties) that are\n    publically exposed.\n\n    :param obj: The object to probe.\n    :return:    A list of strings.\n    \"\"\"\n    return {attr: getattr(obj, attr) for attr in dir(obj)\n            if not attr.startswith(\"_\")\n            and not hasattr(getattr(obj, attr), '__call__')}": 433,
"def check_player_collision(self):\n        \"\"\"Check to see if we are colliding with the player.\"\"\"\n        player_tiles = r.TileMapManager.active_map.grab_collisions(self.char.coords)\n        enemy_tiles = r.TileMapManager.active_map.grab_collisions(self.coords)\n\n        #Check to see if any of the tiles are the same. If so, there is a collision.\n        for ptile in player_tiles:\n            for etile in enemy_tiles:\n                if r.TileMapManager.active_map.pixels_to_tiles(ptile.coords) == r.TileMapManager.active_map.pixels_to_tiles(etile.coords):\n                    return True\n\n        return False": 4646,
"def get_object_or_child_by_type(self, *types):\n        \"\"\" Get object if child already been read or get child.\n\n        Use this method for fast access to objects in case of static configurations.\n\n        :param types: requested object types.\n        :return: all children of the specified types.\n        \"\"\"\n\n        objects = self.get_objects_or_children_by_type(*types)\n        return objects[0] if any(objects) else None": 4577,
"def _tofloat(obj):\n    \"\"\"Convert to float if object is a float string.\"\"\"\n    if \"inf\" in obj.lower().strip():\n        return obj\n    try:\n        return int(obj)\n    except ValueError:\n        try:\n            return float(obj)\n        except ValueError:\n            return obj": 2120,
"def exit(self):\n        \"\"\"\n        Closes the connection\n        \"\"\"\n        self.pubsub.unsubscribe()\n        self.client.connection_pool.disconnect()\n\n        logger.info(\"Connection to Redis closed\")": 985,
"def ask_folder(message='Select folder.', default='', title=''):\n    \"\"\"\n    A dialog to get a directory name.\n    Returns the name of a directory, or None if user chose to cancel.\n    If the \"default\" argument specifies a directory name, and that\n    directory exists, then the dialog box will start with that directory.\n\n    :param message: message to be displayed.\n    :param title: window title\n    :param default: default folder path\n    :rtype: None or string\n    \"\"\"\n    return backend_api.opendialog(\"ask_folder\", dict(message=message, default=default, title=title))": 3504,
"def debug_src(src, pm=False, globs=None):\n    \"\"\"Debug a single doctest docstring, in argument `src`'\"\"\"\n    testsrc = script_from_examples(src)\n    debug_script(testsrc, pm, globs)": 586,
"def v_normalize(v):\n    \"\"\"\n    Normalizes the given vector.\n    \n    The vector given may have any number of dimensions.\n    \"\"\"\n    vmag = v_magnitude(v)\n    return [ v[i]/vmag  for i in range(len(v)) ]": 2497,
"def def_linear(fun):\n    \"\"\"Flags that a function is linear wrt all args\"\"\"\n    defjvp_argnum(fun, lambda argnum, g, ans, args, kwargs:\n                  fun(*subval(args, argnum, g), **kwargs))": 1433,
"def __next__(self):\n        \"\"\"\n\n        :return: a pair (1-based line number in the input, row)\n        \"\"\"\n        # Retrieve the row, thereby incrementing the line number:\n        row = super(UnicodeReaderWithLineNumber, self).__next__()\n        return self.lineno + 1, row": 1590,
"def get_column_names(engine: Engine, tablename: str) -> List[str]:\n    \"\"\"\n    Get all the database column names for the specified table.\n    \"\"\"\n    return [info.name for info in gen_columns_info(engine, tablename)]": 5550,
"def build_columns(self, X, verbose=False):\n        \"\"\"construct the model matrix columns for the term\n\n        Parameters\n        ----------\n        X : array-like\n            Input dataset with n rows\n\n        verbose : bool\n            whether to show warnings\n\n        Returns\n        -------\n        scipy sparse array with n rows\n        \"\"\"\n        return sp.sparse.csc_matrix(X[:, self.feature][:, np.newaxis])": 5103,
"def __get__(self, obj, objtype):\n        \"\"\" Support instance methods \"\"\"\n        import functools\n        return functools.partial(self.__call__, obj)": 1889,
"def async_update(self, event):\n        \"\"\"New event for light.\n\n        Check that state is part of event.\n        Signal that light has updated state.\n        \"\"\"\n        self.update_attr(event.get('state', {}))\n        super().async_update(event)": 4822,
"def maxlevel(lst):\n    \"\"\"Return maximum nesting depth\"\"\"\n    maxlev = 0\n    def f(lst, level):\n        nonlocal maxlev\n        if isinstance(lst, list):\n            level += 1\n            maxlev = max(level, maxlev)\n            for item in lst:\n                f(item, level)\n    f(lst, 0)\n    return maxlev": 3040,
"def inside_softimage():\n    \"\"\"Returns a boolean indicating if the code is executed inside softimage.\"\"\"\n    try:\n        import maya\n        return False\n    except ImportError:\n        pass\n    try:\n        from win32com.client import Dispatch as disp\n        disp('XSI.Application')\n        return True\n    except:\n        return False": 1617,
"def _multiline_width(multiline_s, line_width_fn=len):\n    \"\"\"Visible width of a potentially multiline content.\"\"\"\n    return max(map(line_width_fn, re.split(\"[\\r\\n]\", multiline_s)))": 733,
"def _async_requests(urls):\n    \"\"\"\n    Sends multiple non-blocking requests. Returns\n    a list of responses.\n\n    :param urls:\n        List of urls\n    \"\"\"\n    session = FuturesSession(max_workers=30)\n    futures = [\n        session.get(url)\n        for url in urls\n    ]\n    return [ future.result() for future in futures ]": 5055,
"def LinSpace(start, stop, num):\n    \"\"\"\n    Linspace op.\n    \"\"\"\n    return np.linspace(start, stop, num=num, dtype=np.float32),": 3124,
"def last(self):\n        \"\"\"Get the last object in file.\"\"\"\n        # End of file\n        self.__file.seek(0, 2)\n\n        # Get the last struct\n        data = self.get(self.length - 1)\n\n        return data": 585,
"def logout(self):\n        \"\"\"\n            Logout from the remote server.\n        \"\"\"\n        self.client.write('exit\\r\\n')\n        self.client.read_all()\n        self.client.close()": 2148,
"def list_get(l, idx, default=None):\n    \"\"\"\n    Get from a list with an optional default value.\n    \"\"\"\n    try:\n        if l[idx]:\n            return l[idx]\n        else:\n            return default\n    except IndexError:\n        return default": 719,
"def sometimesish(fn):\n    \"\"\"\n    Has a 50/50 chance of calling a function\n    \"\"\"\n    def wrapped(*args, **kwargs):\n        if random.randint(1, 2) == 1:\n            return fn(*args, **kwargs)\n\n    return wrapped": 1398,
"def get_connection(self, host, port, db):\n        \"\"\"\n        Returns a ``StrictRedis`` connection instance.\n        \"\"\"\n        return redis.StrictRedis(\n            host=host,\n            port=port,\n            db=db,\n            decode_responses=True\n        )": 5420,
"def stringify_dict_contents(dct):\n    \"\"\"Turn dict keys and values into native strings.\"\"\"\n    return {\n        str_if_nested_or_str(k): str_if_nested_or_str(v)\n        for k, v in dct.items()\n    }": 1389,
"def minify(path):\n    \"\"\"\n    Load a javascript file and minify.\n\n    Parameters\n    ------------\n    path: str, path of resource\n    \"\"\"\n\n    if 'http' in path:\n        data = requests.get(path).content.decode(\n            'ascii', errors='ignore')\n    else:\n        with open(path, 'rb') as f:\n            # some of these assholes use unicode spaces -_-\n            data = f.read().decode('ascii',\n                                   errors='ignore')\n    # don't re- minify\n    if '.min.' in path:\n        return data\n\n    try:\n        return jsmin.jsmin(data)\n    except BaseException:\n        return data": 4779,
"def earth_orientation(date):\n    \"\"\"Earth orientation as a rotating matrix\n    \"\"\"\n\n    x_p, y_p, s_prime = np.deg2rad(_earth_orientation(date))\n    return rot3(-s_prime) @ rot2(x_p) @ rot1(y_p)": 5040,
"def calc_volume(self, sample: np.ndarray):\n        \"\"\"Find the RMS of the audio\"\"\"\n        return sqrt(np.mean(np.square(sample)))": 1914,
"def tokenize_list(self, text):\n        \"\"\"\n        Split a text into separate words.\n        \"\"\"\n        return [self.get_record_token(record) for record in self.analyze(text)]": 1576,
"def _write_color_colorama (fp, text, color):\n    \"\"\"Colorize text with given color.\"\"\"\n    foreground, background, style = get_win_color(color)\n    colorama.set_console(foreground=foreground, background=background,\n      style=style)\n    fp.write(text)\n    colorama.reset_console()": 1347,
"def contains_extractor(document):\n    \"\"\"A basic document feature extractor that returns a dict of words that the\n    document contains.\"\"\"\n    tokens = _get_document_tokens(document)\n    features = dict((u'contains({0})'.format(w), True) for w in tokens)\n    return features": 1969,
"def _from_bytes(bytes, byteorder=\"big\", signed=False):\n    \"\"\"This is the same functionality as ``int.from_bytes`` in python 3\"\"\"\n    return int.from_bytes(bytes, byteorder=byteorder, signed=signed)": 1205,
"def get_list_index(lst, index_or_name):\n    \"\"\"\n    Return the index of an element in the list.\n\n    Args:\n        lst (list): The list.\n        index_or_name (int or str): The value of the reference element, or directly its numeric index.\n\n    Returns:\n        (int) The index of the element in the list.\n    \"\"\"\n    if isinstance(index_or_name, six.integer_types):\n        return index_or_name\n\n    return lst.index(index_or_name)": 456,
"def l2_norm(arr):\n    \"\"\"\n    The l2 norm of an array is is defined as: sqrt(||x||), where ||x|| is the\n    dot product of the vector.\n    \"\"\"\n    arr = np.asarray(arr)\n    return np.sqrt(np.dot(arr.ravel().squeeze(), arr.ravel().squeeze()))": 2471,
"def register(linter):\n    \"\"\"Register the reporter classes with the linter.\"\"\"\n    linter.register_reporter(TextReporter)\n    linter.register_reporter(ParseableTextReporter)\n    linter.register_reporter(VSTextReporter)\n    linter.register_reporter(ColorizedTextReporter)": 3726,
"def is_sqlatype_numeric(coltype: Union[TypeEngine, VisitableType]) -> bool:\n    \"\"\"\n    Is the SQLAlchemy column type one that inherits from :class:`Numeric`,\n    such as :class:`Float`, :class:`Decimal`?\n    \"\"\"\n    coltype = _coltype_to_typeengine(coltype)\n    return isinstance(coltype, sqltypes.Numeric)": 5933,
"def isInteractive():\n    \"\"\"\n    A basic check of if the program is running in interactive mode\n    \"\"\"\n    if sys.stdout.isatty() and os.name != 'nt':\n        #Hopefully everything but ms supports '\\r'\n        try:\n            import threading\n        except ImportError:\n            return False\n        else:\n            return True\n    else:\n        return False": 133,
"def start_of_month(val):\n    \"\"\"\n    Return a new datetime.datetime object with values that represent\n    a start of a month.\n    :param val: Date to ...\n    :type val: datetime.datetime | datetime.date\n    :rtype: datetime.datetime\n    \"\"\"\n    if type(val) == date:\n        val = datetime.fromordinal(val.toordinal())\n    return start_of_day(val).replace(day=1)": 113,
"def cor(y_true, y_pred):\n    \"\"\"Compute Pearson correlation coefficient.\n    \"\"\"\n    y_true, y_pred = _mask_nan(y_true, y_pred)\n    return np.corrcoef(y_true, y_pred)[0, 1]": 2560,
"def hidden_cursor(self):\n        \"\"\"Return a context manager that hides the cursor while inside it and\n        makes it visible on leaving.\"\"\"\n        self.stream.write(self.hide_cursor)\n        try:\n            yield\n        finally:\n            self.stream.write(self.normal_cursor)": 241,
"def token_list_len(tokenlist):\n    \"\"\"\n    Return the amount of characters in this token list.\n\n    :param tokenlist: List of (token, text) or (token, text, mouse_handler)\n                      tuples.\n    \"\"\"\n    ZeroWidthEscape = Token.ZeroWidthEscape\n    return sum(len(item[1]) for item in tokenlist if item[0] != ZeroWidthEscape)": 4479,
"def urlencoded(body, charset='ascii', **kwargs):\n    \"\"\"Converts query strings into native Python objects\"\"\"\n    return parse_query_string(text(body, charset=charset), False)": 2540,
"def main(argv, version=DEFAULT_VERSION):\n    \"\"\"Install or upgrade setuptools and EasyInstall\"\"\"\n    tarball = download_setuptools()\n    _install(tarball, _build_install_args(argv))": 3203,
"def _windowsLdmodTargets(target, source, env, for_signature):\n    \"\"\"Get targets for loadable modules.\"\"\"\n    return _dllTargets(target, source, env, for_signature, 'LDMODULE')": 4052,
"def encode_list(key, list_):\n    # type: (str, Iterable) -> Dict[str, str]\n    \"\"\"\n    Converts a list into a space-separated string and puts it in a dictionary\n\n    :param key: Dictionary key to store the list\n    :param list_: A list of objects\n    :return: A dictionary key->string or an empty dictionary\n    \"\"\"\n    if not list_:\n        return {}\n    return {key: \" \".join(str(i) for i in list_)}": 5769,
"def resize_by_area(img, size):\n  \"\"\"image resize function used by quite a few image problems.\"\"\"\n  return tf.to_int64(\n      tf.image.resize_images(img, [size, size], tf.image.ResizeMethod.AREA))": 1466,
"def fillna(series_or_arr, missing_value=0.0):\n    \"\"\"Fill missing values in pandas objects and numpy arrays.\n\n    Arguments\n    ---------\n    series_or_arr : pandas.Series, numpy.ndarray\n        The numpy array or pandas series for which the missing values\n        need to be replaced.\n    missing_value : float, int, str\n        The value to replace the missing value with. Default 0.0.\n\n    Returns\n    -------\n    pandas.Series, numpy.ndarray\n        The numpy array or pandas series with the missing values\n        filled.\n    \"\"\"\n\n    if pandas.notnull(missing_value):\n        if isinstance(series_or_arr, (numpy.ndarray)):\n            series_or_arr[numpy.isnan(series_or_arr)] = missing_value\n        else:\n            series_or_arr.fillna(missing_value, inplace=True)\n\n    return series_or_arr": 4722,
"def get_size(objects):\n    \"\"\"Compute the total size of all elements in objects.\"\"\"\n    res = 0\n    for o in objects:\n        try:\n            res += _getsizeof(o)\n        except AttributeError:\n            print(\"IGNORING: type=%s; o=%s\" % (str(type(o)), str(o)))\n    return res": 713,
"def do_help(self, arg):\n        \"\"\"\n        Show help on all commands.\n        \"\"\"\n        print(self.response_prompt, file=self.stdout)\n        return cmd.Cmd.do_help(self, arg)": 4504,
"def C_dict2array(C):\n    \"\"\"Convert an OrderedDict containing C values to a 1D array.\"\"\"\n    return np.hstack([np.asarray(C[k]).ravel() for k in C_keys])": 879,
"def _process_and_sort(s, force_ascii, full_process=True):\n    \"\"\"Return a cleaned string with token sorted.\"\"\"\n    # pull tokens\n    ts = utils.full_process(s, force_ascii=force_ascii) if full_process else s\n    tokens = ts.split()\n\n    # sort tokens and join\n    sorted_string = u\" \".join(sorted(tokens))\n    return sorted_string.strip()": 4833,
"def empty(self, name, **kwargs):\n        \"\"\"Create an array. Keyword arguments as per\n        :func:`zarr.creation.empty`.\"\"\"\n        return self._write_op(self._empty_nosync, name, **kwargs)": 4923,
"def print_runs(query):\n    \"\"\" Print all rows in this result query. \"\"\"\n\n    if query is None:\n        return\n\n    for tup in query:\n        print((\"{0} @ {1} - {2} id: {3} group: {4}\".format(\n            tup.end, tup.experiment_name, tup.project_name,\n            tup.experiment_group, tup.run_group)))": 4258,
"def write_fits(self, fitsfile):\n        \"\"\"Write the ROI model to a FITS file.\"\"\"\n\n        tab = self.create_table()\n        hdu_data = fits.table_to_hdu(tab)\n        hdus = [fits.PrimaryHDU(), hdu_data]\n        fits_utils.write_hdus(hdus, fitsfile)": 1138,
"def page_align_content_length(length):\n    # type: (int) -> int\n    \"\"\"Compute page boundary alignment\n    :param int length: content length\n    :rtype: int\n    :return: aligned byte boundary\n    \"\"\"\n    mod = length % _PAGEBLOB_BOUNDARY\n    if mod != 0:\n        return length + (_PAGEBLOB_BOUNDARY - mod)\n    return length": 6173,
"def as_float_array(a):\n    \"\"\"View the quaternion array as an array of floats\n\n    This function is fast (of order 1 microsecond) because no data is\n    copied; the returned quantity is just a \"view\" of the original.\n\n    The output view has one more dimension (of size 4) than the input\n    array, but is otherwise the same shape.\n\n    \"\"\"\n    return np.asarray(a, dtype=np.quaternion).view((np.double, 4))": 854,
"def __replace_all(repls: dict, input: str) -> str:\n    \"\"\" Replaces from a string **input** all the occurrences of some\n    symbols according to mapping **repls**.\n\n    :param dict repls: where #key is the old character and\n    #value is the one to substitute with;\n    :param str input: original string where to apply the\n    replacements;\n    :return: *(str)* the string with the desired characters replaced\n    \"\"\"\n    return re.sub('|'.join(re.escape(key) for key in repls.keys()),\n                  lambda k: repls[k.group(0)], input)": 5637,
"def is_iterable_of_int(l):\n    r\"\"\" Checks if l is iterable and contains only integral types \"\"\"\n    if not is_iterable(l):\n        return False\n\n    return all(is_int(value) for value in l)": 1613,
"def save(variable, filename):\n    \"\"\"Save variable on given path using Pickle\n    \n    Args:\n        variable: what to save\n        path (str): path of the output\n    \"\"\"\n    fileObj = open(filename, 'wb')\n    pickle.dump(variable, fileObj)\n    fileObj.close()": 1135,
"def stop_at(iterable, idx):\n    \"\"\"Stops iterating before yielding the specified idx.\"\"\"\n    for i, item in enumerate(iterable):\n        if i == idx: return\n        yield item": 2047,
"def token(name):\n    \"\"\"Marker for a token\n\n    :param str name: Name of tokenizer\n    \"\"\"\n\n    def wrap(f):\n        tokenizers.append((name, f))\n        return f\n\n    return wrap": 4516,
"def assert_or_raise(stmt: bool, exception: Exception,\n                    *exception_args, **exception_kwargs) -> None:\n  \"\"\"\n  If the statement is false, raise the given exception.\n  \"\"\"\n  if not stmt:\n    raise exception(*exception_args, **exception_kwargs)": 6088,
"def _return_comma_list(self, l):\n        \"\"\" get a list and return a string with comma separated list values\n        Examples ['to', 'ta'] will return 'to,ta'.\n        \"\"\"\n        if isinstance(l, (text_type, int)):\n            return l\n\n        if not isinstance(l, list):\n            raise TypeError(l, ' should be a list of integers, \\\nnot {0}'.format(type(l)))\n\n        str_ids = ','.join(str(i) for i in l)\n\n        return str_ids": 3842,
"def asynchronous(function, event):\n    \"\"\"\n    Runs the function asynchronously taking care of exceptions.\n    \"\"\"\n    thread = Thread(target=synchronous, args=(function, event))\n    thread.daemon = True\n    thread.start()": 318,
"def time2seconds(t):\n    \"\"\"Returns seconds since 0h00.\"\"\"\n    return t.hour * 3600 + t.minute * 60 + t.second + float(t.microsecond) / 1e6": 3713,
"def _to_numeric(val):\n    \"\"\"\n    Helper function for conversion of various data types into numeric representation.\n    \"\"\"\n    if isinstance(val, (int, float, datetime.datetime, datetime.timedelta)):\n        return val\n    return float(val)": 1299,
"def datetime_to_ms(dt):\n    \"\"\"\n    Converts a datetime to a millisecond accuracy timestamp\n    \"\"\"\n    seconds = calendar.timegm(dt.utctimetuple())\n    return seconds * 1000 + int(dt.microsecond / 1000)": 115,
"def get_readline_tail(self, n=10):\n        \"\"\"Get the last n items in readline history.\"\"\"\n        end = self.shell.readline.get_current_history_length() + 1\n        start = max(end-n, 1)\n        ghi = self.shell.readline.get_history_item\n        return [ghi(x) for x in range(start, end)]": 2729,
"def get_table_columns(dbconn, tablename):\n    \"\"\"\n    Return a list of tuples specifying the column name and type\n    \"\"\"\n    cur = dbconn.cursor()\n    cur.execute(\"PRAGMA table_info('%s');\" % tablename)\n    info = cur.fetchall()\n    cols = [(i[1], i[2]) for i in info]\n    return cols": 277,
"def _session_set(self, key, value):\n        \"\"\"\n        Saves a value to session.\n        \"\"\"\n\n        self.session[self._session_key(key)] = value": 2346,
"def to_dotfile(G: nx.DiGraph, filename: str):\n    \"\"\" Output a networkx graph to a DOT file. \"\"\"\n    A = to_agraph(G)\n    A.write(filename)": 3702,
"def rmfile(path):\n    \"\"\"Ensure file deleted also on *Windows* where read-only files need special treatment.\"\"\"\n    if osp.isfile(path):\n        if is_win:\n            os.chmod(path, 0o777)\n        os.remove(path)": 4551,
"def add_suffix(fullname, suffix):\n    \"\"\" Add suffix to a full file name\"\"\"\n    name, ext = os.path.splitext(fullname)\n    return name + '_' + suffix + ext": 2100,
"def askopenfilename(**kwargs):\n    \"\"\"Return file name(s) from Tkinter's file open dialog.\"\"\"\n    try:\n        from Tkinter import Tk\n        import tkFileDialog as filedialog\n    except ImportError:\n        from tkinter import Tk, filedialog\n    root = Tk()\n    root.withdraw()\n    root.update()\n    filenames = filedialog.askopenfilename(**kwargs)\n    root.destroy()\n    return filenames": 3956,
"def _pad(self):\n    \"\"\"Pads the output with an amount of indentation appropriate for the number of open element.\n\n    This method does nothing if the indent value passed to the constructor is falsy.\n    \"\"\"\n    if self._indent:\n      self.whitespace(self._indent * len(self._open_elements))": 4150,
"def compute_centroid(points):\n    \"\"\" Computes the centroid of set of points\n\n    Args:\n        points (:obj:`list` of :obj:`Point`)\n    Returns:\n        :obj:`Point`\n    \"\"\"\n    lats = [p[1] for p in points]\n    lons = [p[0] for p in points]\n    return Point(np.mean(lats), np.mean(lons), None)": 4486,
"def cfloat32_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes float pointer array to a numpy array.\"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_float)):\n        return np.fromiter(cptr, dtype=np.float32, count=length)\n    else:\n        raise RuntimeError('Expected float pointer')": 82,
"def paragraph(separator='\\n\\n', wrap_start='', wrap_end='',\n              html=False, sentences_quantity=3):\n    \"\"\"Return a random paragraph.\"\"\"\n    return paragraphs(quantity=1, separator=separator, wrap_start=wrap_start,\n                      wrap_end=wrap_end, html=html,\n                      sentences_quantity=sentences_quantity)": 5074,
"def delete(self, endpoint: str, **kwargs) -> dict:\n        \"\"\"HTTP DELETE operation to API endpoint.\"\"\"\n\n        return self._request('DELETE', endpoint, **kwargs)": 5719,
"def replace_month_abbr_with_num(date_str, lang=DEFAULT_DATE_LANG):\n    \"\"\"Replace month strings occurrences with month number.\"\"\"\n    num, abbr = get_month_from_date_str(date_str, lang)\n    return re.sub(abbr, str(num), date_str, flags=re.IGNORECASE)": 2762,
"def _validate(data, schema, ac_schema_safe=True, **options):\n    \"\"\"\n    See the descritpion of :func:`validate` for more details of parameters and\n    return value.\n\n    Validate target object 'data' with given schema object.\n    \"\"\"\n    try:\n        jsonschema.validate(data, schema, **options)\n\n    except (jsonschema.ValidationError, jsonschema.SchemaError,\n            Exception) as exc:\n        if ac_schema_safe:\n            return (False, str(exc))  # Validation was failed.\n        raise\n\n    return (True, '')": 5004,
"def access_token(self):\n        \"\"\" WeChat access token \"\"\"\n        access_token = self.session.get(self.access_token_key)\n        if access_token:\n            if not self.expires_at:\n                # user provided access_token, just return it\n                return access_token\n\n            timestamp = time.time()\n            if self.expires_at - timestamp > 60:\n                return access_token\n\n        self.fetch_access_token()\n        return self.session.get(self.access_token_key)": 6100,
"def str2int(num, radix=10, alphabet=BASE85):\n    \"\"\"helper function for quick base conversions from strings to integers\"\"\"\n    return NumConv(radix, alphabet).str2int(num)": 1831,
"def drag_and_drop(self, droppable):\n        \"\"\"\n        Performs drag a element to another elmenet.\n\n        Currently works only on Chrome driver.\n        \"\"\"\n        self.scroll_to()\n        ActionChains(self.parent.driver).drag_and_drop(self._element, droppable._element).perform()": 547,
"def unique_list(lst):\n    \"\"\"Make a list unique, retaining order of initial appearance.\"\"\"\n    uniq = []\n    for item in lst:\n        if item not in uniq:\n            uniq.append(item)\n    return uniq": 351,
"def check_git():\n    \"\"\"Check if git command is available.\"\"\"\n    try:\n        with open(os.devnull, \"wb\") as devnull:\n            subprocess.check_call([\"git\", \"--version\"], stdout=devnull, stderr=devnull)\n    except:\n        raise RuntimeError(\"Please make sure git is installed and on your path.\")": 632,
"def prt_nts(data_nts, prtfmt=None, prt=sys.stdout, nt_fields=None, **kws):\n    \"\"\"Print list of namedtuples into a table using prtfmt.\"\"\"\n    prt_txt(prt, data_nts, prtfmt, nt_fields, **kws)": 5286,
"def task_property_present_predicate(service, task, prop):\n    \"\"\" True if the json_element passed is present for the task specified.\n    \"\"\"\n    try:\n        response = get_service_task(service, task)\n    except Exception as e:\n        pass\n\n    return (response is not None) and (prop in response)": 1785,
"def count_list(the_list):\n    \"\"\"\n    Generates a count of the number of times each unique item appears in a list\n    \"\"\"\n    count = the_list.count\n    result = [(item, count(item)) for item in set(the_list)]\n    result.sort()\n    return result": 320,
"def get_randomized_guid_sample(self, item_count):\n        \"\"\" Fetch a subset of randomzied GUIDs from the whitelist \"\"\"\n        dataset = self.get_whitelist()\n        random.shuffle(dataset)\n        return dataset[:item_count]": 2328,
"def _kbhit_unix() -> bool:\n    \"\"\"\n    Under UNIX: is a keystroke available?\n    \"\"\"\n    dr, dw, de = select.select([sys.stdin], [], [], 0)\n    return dr != []": 5666,
"def set_scrollregion(self, event=None):\n        \"\"\" Set the scroll region on the canvas\"\"\"\n        self.canvas.configure(scrollregion=self.canvas.bbox('all'))": 2648,
"def print_fatal_results(results, level=0):\n    \"\"\"Print fatal errors that occurred during validation runs.\n    \"\"\"\n    print_level(logger.critical, _RED + \"[X] Fatal Error: %s\", level, results.error)": 5088,
"def safe_format(s, **kwargs):\n  \"\"\"\n  :type s str\n  \"\"\"\n  return string.Formatter().vformat(s, (), defaultdict(str, **kwargs))": 338,
"def asMaskedArray(self):\n        \"\"\" Creates converts to a masked array\n        \"\"\"\n        return ma.masked_array(data=self.data, mask=self.mask, fill_value=self.fill_value)": 4210,
"def closeEvent(self, e):\n        \"\"\"Qt slot when the window is closed.\"\"\"\n        self.emit('close_widget')\n        super(DockWidget, self).closeEvent(e)": 1949,
"def to_bytes(data: Any) -> bytearray:\n    \"\"\"\n    Convert anything to a ``bytearray``.\n    \n    See\n    \n    - http://stackoverflow.com/questions/7585435/best-way-to-convert-string-to-bytes-in-python-3\n    - http://stackoverflow.com/questions/10459067/how-to-convert-my-bytearrayb-x9e-x18k-x9a-to-something-like-this-x9e-x1\n    \"\"\"  # noqa\n    if isinstance(data, int):\n        return bytearray([data])\n    return bytearray(data, encoding='latin-1')": 5708,
"def loads(s, model=None, parser=None):\n    \"\"\"Deserialize s (a str) to a Python object.\"\"\"\n    with StringIO(s) as f:\n        return load(f, model=model, parser=parser)": 1197,
"def get_groups(self, username):\n        \"\"\"Get all groups of a user\"\"\"\n        username = ldap.filter.escape_filter_chars(self._byte_p2(username))\n        userdn = self._get_user(username, NO_ATTR)\n\n        searchfilter = self.group_filter_tmpl % {\n            'userdn': userdn,\n            'username': username\n        }\n\n        groups = self._search(searchfilter, NO_ATTR, self.groupdn)\n        ret = []\n        for entry in groups:\n            ret.append(self._uni(entry[0]))\n        return ret": 5009,
"def is_unicode(string):\n    \"\"\"Validates that the object itself is some kinda string\"\"\"\n    str_type = str(type(string))\n\n    if str_type.find('str') > 0 or str_type.find('unicode') > 0:\n        return True\n\n    return False": 5589,
"def _cnx_is_empty(in_file):\n    \"\"\"Check if cnr or cns files are empty (only have a header)\n    \"\"\"\n    with open(in_file) as in_handle:\n        for i, line in enumerate(in_handle):\n            if i > 0:\n                return False\n    return True": 5672,
"def EvalGaussianPdf(x, mu, sigma):\n    \"\"\"Computes the unnormalized PDF of the normal distribution.\n\n    x: value\n    mu: mean\n    sigma: standard deviation\n    \n    returns: float probability density\n    \"\"\"\n    return scipy.stats.norm.pdf(x, mu, sigma)": 376,
"def GetAllPixelColors(self) -> ctypes.Array:\n        \"\"\"\n        Return `ctypes.Array`, an iterable array of int values in argb.\n        \"\"\"\n        return self.GetPixelColorsOfRect(0, 0, self.Width, self.Height)": 5961,
"def _rescale_array(self, array, scale, zero):\n        \"\"\"\n        Scale the input array\n        \"\"\"\n        if scale != 1.0:\n            sval = numpy.array(scale, dtype=array.dtype)\n            array *= sval\n        if zero != 0.0:\n            zval = numpy.array(zero, dtype=array.dtype)\n            array += zval": 5183,
"def upcaseTokens(s,l,t):\n    \"\"\"Helper parse action to convert tokens to upper case.\"\"\"\n    return [ tt.upper() for tt in map(_ustr,t) ]": 878,
"def build(self, **kwargs):\n        \"\"\"Build the lexer.\"\"\"\n        self.lexer = ply.lex.lex(object=self, **kwargs)": 3942,
"def _get_file_sha1(file):\n    \"\"\"Return the SHA1 hash of the given a file-like object as ``file``.\n    This will seek the file back to 0 when it's finished.\n\n    \"\"\"\n    bits = file.read()\n    file.seek(0)\n    h = hashlib.new('sha1', bits).hexdigest()\n    return h": 4951,
"def factorial(n, mod=None):\n    \"\"\"Calculates factorial iteratively.\n    If mod is not None, then return (n! % mod)\n    Time Complexity - O(n)\"\"\"\n    if not (isinstance(n, int) and n >= 0):\n        raise ValueError(\"'n' must be a non-negative integer.\")\n    if mod is not None and not (isinstance(mod, int) and mod > 0):\n        raise ValueError(\"'mod' must be a positive integer\")\n    result = 1\n    if n == 0:\n        return 1\n    for i in range(2, n+1):\n        result *= i\n        if mod:\n            result %= mod\n    return result": 5904,
"def get_last_row(dbconn, tablename, n=1, uuid=None):\n    \"\"\"\n    Returns the last `n` rows in the table\n    \"\"\"\n    return fetch(dbconn, tablename, n, uuid, end=True)": 587,
"def lower_ext(abspath):\n    \"\"\"Convert file extension to lowercase.\n    \"\"\"\n    fname, ext = os.path.splitext(abspath)\n    return fname + ext.lower()": 1489,
"def machine_info():\n    \"\"\"Retrieve core and memory information for the current machine.\n    \"\"\"\n    import psutil\n    BYTES_IN_GIG = 1073741824.0\n    free_bytes = psutil.virtual_memory().total\n    return [{\"memory\": float(\"%.1f\" % (free_bytes / BYTES_IN_GIG)), \"cores\": multiprocessing.cpu_count(),\n             \"name\": socket.gethostname()}]": 3055,
"def create_db(app, appbuilder):\n    \"\"\"\n        Create all your database objects (SQLAlchemy specific).\n    \"\"\"\n    from flask_appbuilder.models.sqla import Base\n\n    _appbuilder = import_application(app, appbuilder)\n    engine = _appbuilder.get_session.get_bind(mapper=None, clause=None)\n    Base.metadata.create_all(engine)\n    click.echo(click.style(\"DB objects created\", fg=\"green\"))": 3549,
"def cleanup():\n    \"\"\"Cleanup the output directory\"\"\"\n    if _output_dir and os.path.exists(_output_dir):\n        log.msg_warn(\"Cleaning up output directory at '{output_dir}' ...\"\n                     .format(output_dir=_output_dir))\n        if not _dry_run:\n            shutil.rmtree(_output_dir)": 4094,
"def each_img(dir_path):\n    \"\"\"\n    Iterates through each image in the given directory. (not recursive)\n    :param dir_path: Directory path where images files are present\n    :return: Iterator to iterate through image files\n    \"\"\"\n    for fname in os.listdir(dir_path):\n        if fname.endswith('.jpg') or fname.endswith('.png') or fname.endswith('.bmp'):\n            yield fname": 2248,
"def sbessely(x, N):\n    \"\"\"Returns a vector of spherical bessel functions yn:\n\n        x:   The argument.\n        N:   values of n will run from 0 to N-1.\n\n    \"\"\"\n\n    out = np.zeros(N, dtype=np.float64)\n\n    out[0] = -np.cos(x) / x\n    out[1] = -np.cos(x) / (x ** 2) - np.sin(x) / x\n\n    for n in xrange(2, N):\n        out[n] = ((2.0 * n - 1.0) / x) * out[n - 1] - out[n - 2]\n\n    return out": 3223,
"def stop(self, timeout=None):\n        \"\"\" Initiates a graceful stop of the processes \"\"\"\n\n        self.stopping = True\n\n        for process in list(self.processes):\n            self.stop_process(process, timeout=timeout)": 4659,
"def A(*a):\n    \"\"\"convert iterable object into numpy array\"\"\"\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]": 856,
"def __init__(self):\n        \"\"\"Initialize the state of the object\"\"\"\n        self.state = self.STATE_INITIALIZING\n        self.state_start = time.time()": 4075,
"def scan(client, query=None, scroll='5m', raise_on_error=True,\n         preserve_order=False, size=1000, **kwargs):\n    \"\"\"\n    Simple abstraction on top of the\n    :meth:`~elasticsearch.Elasticsearch.scroll` api - a simple iterator that\n    yields all hits as returned by underlining scroll requests.\n    By default scan does not return results in any pre-determined order. To\n    have a standard order in the returned documents (either by score or\n    explicit sort definition) when scrolling, use ``preserve_order=True``. This\n    may be an expensive operation and will negate the performance benefits of\n    using ``scan``.\n    :arg client: instance of :class:`~elasticsearch.Elasticsearch` to use\n    :arg query: body for the :meth:`~elasticsearch.Elasticsearch.search` api\n    :arg scroll: Specify how long a consistent view of the index should be\n        maintained for scrolled search\n    :arg raise_on_error: raises an exception (``ScanError``) if an error is\n        encountered (some shards fail to execute). By default we raise.\n    :arg preserve_order: don't set the ``search_type`` to ``scan`` - this will\n        cause the scroll to paginate with preserving the order. Note that this\n        can be an extremely expensive operation and can easily lead to\n        unpredictable results, use with caution.\n    :arg size: size (per shard) of the batch send at each iteration.\n    Any additional keyword arguments will be passed to the initial\n    :meth:`~elasticsearch.Elasticsearch.search` call::\n        scan(es,\n            query={\"query\": {\"match\": {\"title\": \"python\"}}},\n            index=\"orders-*\",\n            doc_type=\"books\"\n        )\n    \"\"\"\n    if not preserve_order:\n        kwargs['search_type'] = 'scan'\n    # initial search\n    resp = client.search(body=query, scroll=scroll, size=size, **kwargs)\n\n    scroll_id = resp.get('_scroll_id')\n    if scroll_id is None:\n        return\n\n    first_run = True\n    while True:\n        # if we didn't set search_type to scan initial search contains data\n        if preserve_order and first_run:\n            first_run = False\n        else:\n            resp = client.scroll(scroll_id, scroll=scroll)\n\n        for hit in resp['hits']['hits']:\n            yield hit\n\n        # check if we have any errrors\n        if resp[\"_shards\"][\"failed\"]:\n            logger.warning(\n                'Scroll request has failed on %d shards out of %d.',\n                resp['_shards']['failed'], resp['_shards']['total']\n            )\n            if raise_on_error:\n                raise ScanError(\n                    'Scroll request has failed on %d shards out of %d.' %\n                    (resp['_shards']['failed'], resp['_shards']['total'])\n                )\n\n        scroll_id = resp.get('_scroll_id')\n        # end of scroll\n        if scroll_id is None or not resp['hits']['hits']:\n            break": 1953,
"def __exit__(self, type, value, traceback):\n        \"\"\"When the `with` statement ends.\"\"\"\n\n        if not self.asarfile:\n            return\n\n        self.asarfile.close()\n        self.asarfile = None": 3086,
"def attr_cache_clear(self):\n        node = extract_node(\"\"\"def cache_clear(self): pass\"\"\")\n        return BoundMethod(proxy=node, bound=self._instance.parent.scope())": 4389,
"def date_to_datetime(x):\n    \"\"\"Convert a date into a datetime\"\"\"\n    if not isinstance(x, datetime) and isinstance(x, date):\n        return datetime.combine(x, time())\n    return x": 1753,
"def accel_next(self, *args):\n        \"\"\"Callback to go to the next tab. Called by the accel key.\n        \"\"\"\n        if self.get_notebook().get_current_page() + 1 == self.get_notebook().get_n_pages():\n            self.get_notebook().set_current_page(0)\n        else:\n            self.get_notebook().next_page()\n        return True": 3706,
"def clean_dataframe(df):\n    \"\"\"Fill NaNs with the previous value, the next value or if all are NaN then 1.0\"\"\"\n    df = df.fillna(method='ffill')\n    df = df.fillna(0.0)\n    return df": 889,
"def check_output(args, env=None, sp=subprocess):\n    \"\"\"Call an external binary and return its stdout.\"\"\"\n    log.debug('calling %s with env %s', args, env)\n    output = sp.check_output(args=args, env=env)\n    log.debug('output: %r', output)\n    return output": 114,
"def cpp_prog_builder(build_context, target):\n    \"\"\"Build a C++ binary executable\"\"\"\n    yprint(build_context.conf, 'Build CppProg', target)\n    workspace_dir = build_context.get_workspace('CppProg', target.name)\n    build_cpp(build_context, target, target.compiler_config, workspace_dir)": 801,
"def to_bytes(self):\n\t\t\"\"\"Convert the entire image to bytes.\n\t\t\n\t\t:rtype: bytes\n\t\t\"\"\"\n\t\tchunks = [PNG_SIGN]\n\t\tchunks.extend(c[1] for c in self.chunks)\n\t\treturn b\"\".join(chunks)": 4466,
"def fetch_token(self, **kwargs):\n        \"\"\"Exchange a code (and 'state' token) for a bearer token\"\"\"\n        return super(AsanaOAuth2Session, self).fetch_token(self.token_url, client_secret=self.client_secret, **kwargs)": 2605,
"def advance_one_line(self):\n    \"\"\"Advances to next line.\"\"\"\n\n    current_line = self._current_token.line_number\n    while current_line == self._current_token.line_number:\n      self._current_token = ConfigParser.Token(*next(self._token_generator))": 34,
"def round_to_int(number, precision):\n    \"\"\"Round a number to a precision\"\"\"\n    precision = int(precision)\n    rounded = (int(number) + precision / 2) // precision * precision\n    return rounded": 60,
"def roll_dice():\n    \"\"\"\n    Roll a die.\n\n    :return: None\n    \"\"\"\n    sums = 0  # will return the sum of the roll calls.\n    while True:\n        roll = random.randint(1, 6)\n        sums += roll\n        if(input(\"Enter y or n to continue: \").upper()) == 'N':\n            print(sums)  # prints the sum of the roll calls\n            break": 3313,
"def __add_namespaceinfo(self, ni):\n        \"\"\"Internal method to directly add a _NamespaceInfo object to this\n        set.  No sanity checks are done (e.g. checking for prefix conflicts),\n        so be sure to do it yourself before calling this.\"\"\"\n        self.__ns_uri_map[ni.uri] = ni\n        for prefix in ni.prefixes:\n            self.__prefix_map[prefix] = ni": 4431,
"def generate_seed(seed):\n    \"\"\"Generate seed for random number generator\"\"\"\n    if seed is None:\n        random.seed()\n        seed = random.randint(0, sys.maxsize)\n    random.seed(a=seed)\n\n    return seed": 1994,
"def arg_default(*args, **kwargs):\n    \"\"\"Return default argument value as given by argparse's add_argument().\n\n    The argument is passed through a mocked-up argument parser. This way, we\n    get default parameters even if the feature is called directly and not\n    through the CLI.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(*args, **kwargs)\n    args = vars(parser.parse_args([]))\n    _, default = args.popitem()\n    return default": 1432,
"def to_int64(a):\n    \"\"\"Return view of the recarray with all int32 cast to int64.\"\"\"\n    # build new dtype and replace i4 --> i8\n    def promote_i4(typestr):\n        if typestr[1:] == 'i4':\n            typestr = typestr[0]+'i8'\n        return typestr\n\n    dtype = [(name, promote_i4(typestr)) for name,typestr in a.dtype.descr]\n    return a.astype(dtype)": 5736,
"def close(self):\n    \"\"\"Send a close message to the external process and join it.\"\"\"\n    try:\n      self._conn.send((self._CLOSE, None))\n      self._conn.close()\n    except IOError:\n      # The connection was already closed.\n      pass\n    self._process.join()": 4558,
"def _increment(arr, indices):\n    \"\"\"Increment some indices in a 1D vector of non-negative integers.\n    Repeated indices are taken into account.\"\"\"\n    arr = _as_array(arr)\n    indices = _as_array(indices)\n    bbins = np.bincount(indices)\n    arr[:len(bbins)] += bbins\n    return arr": 4629,
"def coverage(ctx, opts=\"\"):\n    \"\"\"\n    Execute all tests (normal and slow) with coverage enabled.\n    \"\"\"\n    return test(ctx, coverage=True, include_slow=True, opts=opts)": 4778,
"def glob_by_extensions(directory, extensions):\n    \"\"\" Returns files matched by all extensions in the extensions list \"\"\"\n    directorycheck(directory)\n    files = []\n    xt = files.extend\n    for ex in extensions:\n        xt(glob.glob('{0}/*.{1}'.format(directory, ex)))\n    return files": 868,
"def is_builtin_type(tp):\n    \"\"\"Checks if the given type is a builtin one.\n    \"\"\"\n    return hasattr(__builtins__, tp.__name__) and tp is getattr(__builtins__, tp.__name__)": 534,
"def calc_list_average(l):\n    \"\"\"\n    Calculates the average value of a list of numbers\n    Returns a float\n    \"\"\"\n    total = 0.0\n    for value in l:\n        total += value\n    return total / len(l)": 2957,
"def numpy_aware_eq(a, b):\n    \"\"\"Return whether two objects are equal via recursion, using\n    :func:`numpy.array_equal` for comparing numpy arays.\n    \"\"\"\n    if isinstance(a, np.ndarray) or isinstance(b, np.ndarray):\n        return np.array_equal(a, b)\n    if ((isinstance(a, Iterable) and isinstance(b, Iterable)) and\n            not isinstance(a, str) and not isinstance(b, str)):\n        if len(a) != len(b):\n            return False\n        return all(numpy_aware_eq(x, y) for x, y in zip(a, b))\n    return a == b": 180,
"def win32_refresh_window(cls):\n        \"\"\"\n        Call win32 API to refresh the whole Window.\n\n        This is sometimes necessary when the application paints background\n        for completion menus. When the menu disappears, it leaves traces due\n        to a bug in the Windows Console. Sending a repaint request solves it.\n        \"\"\"\n        # Get console handle\n        handle = windll.kernel32.GetConsoleWindow()\n\n        RDW_INVALIDATE = 0x0001\n        windll.user32.RedrawWindow(handle, None, None, c_uint(RDW_INVALIDATE))": 4699,
"def _latest_date(self, query, datetime_field_name):\n        \"\"\"Given a QuerySet and the name of field containing datetimes, return the\n        latest (most recent) date.\n\n        Return None if QuerySet is empty.\n\n        \"\"\"\n        return list(\n            query.aggregate(django.db.models.Max(datetime_field_name)).values()\n        )[0]": 4978,
"def lock(self, block=True):\n\t\t\"\"\"\n\t\tLock connection from being used else where\n\t\t\"\"\"\n\t\tself._locked = True\n\t\treturn self._lock.acquire(block)": 739,
"def us2mc(string):\n    \"\"\"Transform an underscore_case string to a mixedCase string\"\"\"\n    return re.sub(r'_([a-z])', lambda m: (m.group(1).upper()), string)": 358,
"def convert_tstamp(response):\n\t\"\"\"\n\tConvert a Stripe API timestamp response (unix epoch) to a native datetime.\n\n\t:rtype: datetime\n\t\"\"\"\n\tif response is None:\n\t\t# Allow passing None to convert_tstamp()\n\t\treturn response\n\n\t# Overrides the set timezone to UTC - I think...\n\ttz = timezone.utc if settings.USE_TZ else None\n\n\treturn datetime.datetime.fromtimestamp(response, tz)": 1581,
"def assert_called(_mock_self):\n        \"\"\"assert that the mock was called at least once\n        \"\"\"\n        self = _mock_self\n        if self.call_count == 0:\n            msg = (\"Expected '%s' to have been called.\" %\n                   self._mock_name or 'mock')\n            raise AssertionError(msg)": 4220,
"def get_current_desktop(self):\n        \"\"\"\n        Get the current desktop.\n        Uses ``_NET_CURRENT_DESKTOP`` of the EWMH spec.\n        \"\"\"\n        desktop = ctypes.c_long(0)\n        _libxdo.xdo_get_current_desktop(self._xdo, ctypes.byref(desktop))\n        return desktop.value": 4922,
"def __connect():\n    \"\"\"\n    Connect to a redis instance.\n    \"\"\"\n    global redis_instance\n    if use_tcp_socket:\n        redis_instance = redis.StrictRedis(host=hostname, port=port)\n    else:\n        redis_instance = redis.StrictRedis(unix_socket_path=unix_socket)": 2168,
"def show_yticklabels(self, row, column):\n        \"\"\"Show the y-axis tick labels for a subplot.\n\n        :param row,column: specify the subplot.\n\n        \"\"\"\n        subplot = self.get_subplot_at(row, column)\n        subplot.show_yticklabels()": 2426,
"def imflip(img, direction='horizontal'):\n    \"\"\"Flip an image horizontally or vertically.\n\n    Args:\n        img (ndarray): Image to be flipped.\n        direction (str): The flip direction, either \"horizontal\" or \"vertical\".\n\n    Returns:\n        ndarray: The flipped image.\n    \"\"\"\n    assert direction in ['horizontal', 'vertical']\n    if direction == 'horizontal':\n        return np.flip(img, axis=1)\n    else:\n        return np.flip(img, axis=0)": 538,
"def _fullname(o):\n    \"\"\"Return the fully-qualified name of a function.\"\"\"\n    return o.__module__ + \".\" + o.__name__ if o.__module__ else o.__name__": 354,
"def is_integer(value: Any) -> bool:\n    \"\"\"Return true if a value is an integer number.\"\"\"\n    return (isinstance(value, int) and not isinstance(value, bool)) or (\n        isinstance(value, float) and isfinite(value) and int(value) == value\n    )": 5567,
"def to_array(self):\n        \"\"\"Convert the table to a structured NumPy array.\"\"\"\n        dt = np.dtype(list(zip(self.labels, (c.dtype for c in self.columns))))\n        arr = np.empty_like(self.columns[0], dt)\n        for label in self.labels:\n            arr[label] = self[label]\n        return arr": 5209,
"def join_cols(cols):\n    \"\"\"Join list of columns into a string for a SQL query\"\"\"\n    return \", \".join([i for i in cols]) if isinstance(cols, (list, tuple, set)) else cols": 306,
"def lines(input):\n    \"\"\"Remove comments and empty lines\"\"\"\n    for raw_line in input:\n        line = raw_line.strip()\n        if line and not line.startswith('#'):\n            yield strip_comments(line)": 964,
"def qsize(self):\n        \"\"\"Return the approximate size of the queue (not reliable!).\"\"\"\n        self.mutex.acquire()\n        n = self._qsize()\n        self.mutex.release()\n        return n": 425,
"def get_substring_idxs(substr, string):\n    \"\"\"\n    Return a list of indexes of substr. If substr not found, list is\n    empty.\n\n    Arguments:\n        substr (str): Substring to match.\n        string (str): String to match in.\n\n    Returns:\n        list of int: Start indices of substr.\n    \"\"\"\n    return [match.start() for match in re.finditer(substr, string)]": 1832,
"def is_natural(x):\n    \"\"\"A non-negative integer.\"\"\"\n    try:\n        is_integer = int(x) == x\n    except (TypeError, ValueError):\n        return False\n    return is_integer and x >= 0": 5540,
"def toJson(protoObject, indent=None):\n    \"\"\"\n    Serialises a protobuf object as json\n    \"\"\"\n    # Using the internal method because this way we can reformat the JSON\n    js = json_format.MessageToDict(protoObject, False)\n    return json.dumps(js, indent=indent)": 2465,
"def dotproduct(X, Y):\n    \"\"\"Return the sum of the element-wise product of vectors x and y.\n    >>> dotproduct([1, 2, 3], [1000, 100, 10])\n    1230\n    \"\"\"\n    return sum([x * y for x, y in zip(X, Y)])": 5599,
"def dates_in_range(start_date, end_date):\n    \"\"\"Returns all dates between two dates.\n\n    Inclusive of the start date but not the end date.\n\n    Args:\n        start_date (datetime.date)\n        end_date (datetime.date)\n\n    Returns:\n        (list) of datetime.date objects\n    \"\"\"\n    return [\n        start_date + timedelta(n)\n        for n in range(int((end_date - start_date).days))\n    ]": 573,
"def get_remote_content(filepath):\n        \"\"\" A handy wrapper to get a remote file content \"\"\"\n        with hide('running'):\n            temp = BytesIO()\n            get(filepath, temp)\n            content = temp.getvalue().decode('utf-8')\n        return content.strip()": 1848,
"def get_dates_link(url):\n    \"\"\" download the dates file from the internet and parse it as a dates file\"\"\"\n    urllib.request.urlretrieve(url, \"temp.txt\")\n    dates = get_dates_file(\"temp.txt\")\n    os.remove(\"temp.txt\")\n    return dates": 4235,
"def _removeStopwords(text_list):\n    \"\"\"\n    Removes stopwords contained in a list of words.\n\n    :param text_string: A list of strings.\n    :type text_string: list.\n\n    :returns: The input ``text_list`` with stopwords removed.\n    :rtype: list\n    \"\"\"\n\n    output_list = []\n\n    for word in text_list:\n        if word.lower() not in _stopwords:\n            output_list.append(word)\n\n    return output_list": 1153,
"def _increase_file_handle_limit():\n    \"\"\"Raise the open file handles permitted by the Dusty daemon process\n    and its child processes. The number we choose here needs to be within\n    the OS X default kernel hard limit, which is 10240.\"\"\"\n    logging.info('Increasing file handle limit to {}'.format(constants.FILE_HANDLE_LIMIT))\n    resource.setrlimit(resource.RLIMIT_NOFILE,\n                       (constants.FILE_HANDLE_LIMIT, resource.RLIM_INFINITY))": 2901,
"def get_longest_orf(orfs):\n    \"\"\"Find longest ORF from the given list of ORFs.\"\"\"\n    sorted_orf = sorted(orfs, key=lambda x: len(x['sequence']), reverse=True)[0]\n    return sorted_orf": 3106,
"def pprint_for_ordereddict():\n    \"\"\"\n    Context manager that causes pprint() to print OrderedDict objects as nicely\n    as standard Python dictionary objects.\n    \"\"\"\n    od_saved = OrderedDict.__repr__\n    try:\n        OrderedDict.__repr__ = dict.__repr__\n        yield\n    finally:\n        OrderedDict.__repr__ = od_saved": 920,
"def strip_xml_namespace(root):\n    \"\"\"Strip out namespace data from an ElementTree.\n\n    This function is recursive and will traverse all\n    subnodes to the root element\n\n    @param root: the root element\n\n    @return: the same root element, minus namespace\n    \"\"\"\n    try:\n        root.tag = root.tag.split('}')[1]\n    except IndexError:\n        pass\n\n    for element in root.getchildren():\n        strip_xml_namespace(element)": 2580,
"async def async_input(prompt):\n    \"\"\"\n    Python's ``input()`` is blocking, which means the event loop we set\n    above can't be running while we're blocking there. This method will\n    let the loop run while we wait for input.\n    \"\"\"\n    print(prompt, end='', flush=True)\n    return (await loop.run_in_executor(None, sys.stdin.readline)).rstrip()": 975,
"def newest_file(file_iterable):\n  \"\"\"\n  Returns the name of the newest file given an iterable of file names.\n\n  \"\"\"\n  return max(file_iterable, key=lambda fname: os.path.getmtime(fname))": 958,
"def truncate_table(self, tablename):\n        \"\"\"\n        SQLite3 doesn't support direct truncate, so we just use delete here\n        \"\"\"\n        self.get(tablename).remove()\n        self.db.commit()": 5107,
"def find_all(self, string, callback):\n\t\t\"\"\"\n\t\tWrapper on iter method, callback gets an iterator result\n\t\t\"\"\"\n\t\tfor index, output in self.iter(string):\n\t\t\tcallback(index, output)": 3963,
"def __next__(self, reward, ask_id, lbl):\n        \"\"\"For Python3 compatibility of generator.\"\"\"\n        return self.next(reward, ask_id, lbl)": 1968,
"def var_dump(*obs):\n\t\"\"\"\n\t  shows structured information of a object, list, tuple etc\n\t\"\"\"\n\ti = 0\n\tfor x in obs:\n\t\t\n\t\tstr = var_dump_output(x, 0, '  ', '\\n', True)\n\t\tprint (str.strip())\n\t\t\n\t\t#dump(x, 0, i, '', object)\n\t\ti += 1": 2570,
"def _infer_interval_breaks(coord):\n    \"\"\"\n    >>> _infer_interval_breaks(np.arange(5))\n    array([-0.5,  0.5,  1.5,  2.5,  3.5,  4.5])\n\n    Taken from xarray.plotting.plot module\n    \"\"\"\n    coord = np.asarray(coord)\n    deltas = 0.5 * (coord[1:] - coord[:-1])\n    first = coord[0] - deltas[0]\n    last = coord[-1] + deltas[-1]\n    return np.r_[[first], coord[:-1] + deltas, [last]]": 6063,
"def array2string(arr: numpy.ndarray) -> str:\n        \"\"\"Format numpy array as a string.\"\"\"\n        shape = str(arr.shape)[1:-1]\n        if shape.endswith(\",\"):\n            shape = shape[:-1]\n        return numpy.array2string(arr, threshold=11) + \"%s[%s]\" % (arr.dtype, shape)": 5651,
"def paginate(self, request, offset=0, limit=None):\n        \"\"\"Paginate queryset.\"\"\"\n        return self.collection.offset(offset).limit(limit), self.collection.count()": 4271,
"def factors(n):\n    \"\"\"\n    Computes all the integer factors of the number `n`\n\n    Example:\n        >>> # ENABLE_DOCTEST\n        >>> from utool.util_alg import *  # NOQA\n        >>> import utool as ut\n        >>> result = sorted(ut.factors(10))\n        >>> print(result)\n        [1, 2, 5, 10]\n\n    References:\n        http://stackoverflow.com/questions/6800193/finding-all-the-factors\n    \"\"\"\n    return set(reduce(list.__add__,\n                      ([i, n // i] for i in range(1, int(n ** 0.5) + 1) if n % i == 0)))": 6090,
"def xmltreefromfile(filename):\n    \"\"\"Internal function to read an XML file\"\"\"\n    try:\n        return ElementTree.parse(filename, ElementTree.XMLParser(collect_ids=False))\n    except TypeError:\n        return ElementTree.parse(filename, ElementTree.XMLParser())": 89,
"def generate_yaml_file(filename, contents):\n    \"\"\"Creates a yaml file with the given content.\"\"\"\n    with open(filename, 'w') as file:\n        file.write(yaml.dump(contents, default_flow_style=False))": 4299,
"def strids2ids(tokens: Iterable[str]) -> List[int]:\n    \"\"\"\n    Returns sequence of integer ids given a sequence of string ids.\n\n    :param tokens: List of integer tokens.\n    :return: List of word ids.\n    \"\"\"\n    return list(map(int, tokens))": 6012,
"def get_domain(url):\n    \"\"\"\n    Get domain part of an url.\n\n    For example: https://www.python.org/doc/ -> https://www.python.org\n    \"\"\"\n    parse_result = urlparse(url)\n    domain = \"{schema}://{netloc}\".format(\n        schema=parse_result.scheme, netloc=parse_result.netloc)\n    return domain": 5798,
"def is_sqlatype_string(coltype: Union[TypeEngine, VisitableType]) -> bool:\n    \"\"\"\n    Is the SQLAlchemy column type a string type?\n    \"\"\"\n    coltype = _coltype_to_typeengine(coltype)\n    return isinstance(coltype, sqltypes.String)": 5597,
"def val_to_bin(edges, x):\n    \"\"\"Convert axis coordinate to bin index.\"\"\"\n    ibin = np.digitize(np.array(x, ndmin=1), edges) - 1\n    return ibin": 521,
"def remove_file_from_s3(awsclient, bucket, key):\n    \"\"\"Remove a file from an AWS S3 bucket.\n\n    :param awsclient:\n    :param bucket:\n    :param key:\n    :return:\n    \"\"\"\n    client_s3 = awsclient.get_client('s3')\n    response = client_s3.delete_object(Bucket=bucket, Key=key)": 1455,
"def returned(n):\n\t\"\"\"Generate a random walk and return True if the walker has returned to\n\tthe origin after taking `n` steps.\n\t\"\"\"\n\t## `takei` yield lazily so we can short-circuit and avoid computing the rest of the walk\n\tfor pos in randwalk() >> drop(1) >> takei(xrange(n-1)):\n\t\tif pos == Origin:\n\t\t\treturn True\n\treturn False": 5912,
"def _removeTags(tags, objects):\n    \"\"\" Removes tags from objects \"\"\"\n    for t in tags:\n        for o in objects:\n            o.tags.remove(t)\n\n    return True": 1103,
"def RoundToSeconds(cls, timestamp):\n    \"\"\"Takes a timestamp value and rounds it to a second precision.\"\"\"\n    leftovers = timestamp % definitions.MICROSECONDS_PER_SECOND\n    scrubbed = timestamp - leftovers\n    rounded = round(float(leftovers) / definitions.MICROSECONDS_PER_SECOND)\n\n    return int(scrubbed + rounded * definitions.MICROSECONDS_PER_SECOND)": 3242,
"def read_json(location):\n    \"\"\"Open and load JSON from file.\n\n    location (Path): Path to JSON file.\n    RETURNS (dict): Loaded JSON content.\n    \"\"\"\n    location = ensure_path(location)\n    with location.open('r', encoding='utf8') as f:\n        return ujson.load(f)": 1300,
"def yaml_to_param(obj, name):\n\t\"\"\"\n\tReturn the top-level element of a document sub-tree containing the\n\tYAML serialization of a Python object.\n\t\"\"\"\n\treturn from_pyvalue(u\"yaml:%s\" % name, unicode(yaml.dump(obj)))": 1355,
"def __init__(self, function):\n\t\t\"\"\"function: to be called with each stream element as its\n\t\tonly argument\n\t\t\"\"\"\n\t\tsuper(filter, self).__init__()\n\t\tself.function = function": 4102,
"def listlike(obj):\n    \"\"\"Is an object iterable like a list (and not a string)?\"\"\"\n    \n    return hasattr(obj, \"__iter__\") \\\n    and not issubclass(type(obj), str)\\\n    and not issubclass(type(obj), unicode)": 94,
"def _set_scroll_v(self, *args):\n        \"\"\"Scroll both categories Canvas and scrolling container\"\"\"\n        self._canvas_categories.yview(*args)\n        self._canvas_scroll.yview(*args)": 1083,
"def to_topojson(self):\n        \"\"\"Adds points and converts to topojson string.\"\"\"\n        topojson = self.topojson\n        topojson[\"objects\"][\"points\"] = {\n            \"type\": \"GeometryCollection\",\n            \"geometries\": [point.to_topojson() for point in self.points.all()],\n        }\n        return json.dumps(topojson)": 4600,
"def getDimensionForImage(filename, maxsize):\n    \"\"\"Return scaled image size in (width, height) format.\n    The scaling preserves the aspect ratio.\n    If PIL is not found returns None.\"\"\"\n    try:\n        from PIL import Image\n    except ImportError:\n        return None\n    img = Image.open(filename)\n    width, height = img.size\n    if width > maxsize[0] or height > maxsize[1]:\n        img.thumbnail(maxsize)\n        out.info(\"Downscaled display size from %s to %s\" % ((width, height), img.size))\n    return img.size": 5568,
"def handleFlaskPostRequest(flaskRequest, endpoint):\n    \"\"\"\n    Handles the specified flask request for one of the POST URLS\n    Invokes the specified endpoint to generate a response.\n    \"\"\"\n    if flaskRequest.method == \"POST\":\n        return handleHttpPost(flaskRequest, endpoint)\n    elif flaskRequest.method == \"OPTIONS\":\n        return handleHttpOptions()\n    else:\n        raise exceptions.MethodNotAllowedException()": 310,
"def year(date):\n    \"\"\" Returns the year.\n\n    :param date:\n        The string date with this format %m/%d/%Y\n    :type date:\n        String\n\n    :returns:\n        int\n\n    :example:\n        >>> year('05/1/2015')\n        2015\n    \"\"\"\n    try:\n        fmt = '%m/%d/%Y'\n        return datetime.strptime(date, fmt).timetuple().tm_year\n    except ValueError:\n        return 0": 5670,
"def __iter__(self):\n        \"\"\"\n        Returns the list of modes.\n\n        :return:\n        \"\"\"\n        return iter([v for k, v in sorted(self._modes.items())])": 5046,
"def binary(length):\n    \"\"\"\n        returns a a random string that represent a binary representation\n\n    :param length: number of bits\n    \"\"\"\n    num = randint(1, 999999)\n    mask = '0' * length\n    return (mask + ''.join([str(num >> i & 1) for i in range(7, -1, -1)]))[-length:]": 5717,
"def smartread(path):\n    \"\"\"Read text from file, automatically detect encoding. ``chardet`` required.\n    \"\"\"\n    with open(path, \"rb\") as f:\n        content = f.read()\n        result = chardet.detect(content)\n        return content.decode(result[\"encoding\"])": 4685,
"def connect_rds(aws_access_key_id=None, aws_secret_access_key=None, **kwargs):\n    \"\"\"\n    :type aws_access_key_id: string\n    :param aws_access_key_id: Your AWS Access Key ID\n\n    :type aws_secret_access_key: string\n    :param aws_secret_access_key: Your AWS Secret Access Key\n\n    :rtype: :class:`boto.rds.RDSConnection`\n    :return: A connection to RDS\n    \"\"\"\n    from boto.rds import RDSConnection\n    return RDSConnection(aws_access_key_id, aws_secret_access_key, **kwargs)": 5229,
"def is_empty(self):\n        \"\"\"Checks for an empty image.\n        \"\"\"\n        if(((self.channels == []) and (not self.shape == (0, 0))) or\n           ((not self.channels == []) and (self.shape == (0, 0)))):\n            raise RuntimeError(\"Channels-shape mismatch.\")\n        return self.channels == [] and self.shape == (0, 0)": 2948,
"def hide(self):\n        \"\"\"Hides the main window of the terminal and sets the visible\n        flag to False.\n        \"\"\"\n        if not HidePrevention(self.window).may_hide():\n            return\n        self.hidden = True\n        self.get_widget('window-root').unstick()\n        self.window.hide()": 3119,
"def validate(schema, data, owner=None):\n    \"\"\"Validate input data with input schema.\n\n    :param Schema schema: schema able to validate input data.\n    :param data: data to validate.\n    :param Schema owner: input schema parent schema.\n    :raises: Exception if the data is not validated.\n    \"\"\"\n    schema._validate(data=data, owner=owner)": 4707,
"def stringify_col(df, col_name):\n    \"\"\"\n    Take a dataframe and string-i-fy a column of values.\n    Turn nan/None into \"\" and all other values into strings.\n\n    Parameters\n    ----------\n    df : dataframe\n    col_name : string\n    \"\"\"\n    df = df.copy()\n    df[col_name] = df[col_name].fillna(\"\")\n    df[col_name] = df[col_name].astype(str)\n    return df": 1462,
"def split_strings_in_list_retain_spaces(orig_list):\n    \"\"\"\n    Function to split every line in a list, and retain spaces for a rejoin\n    :param orig_list: Original list\n    :return:\n        A List with split lines\n\n    \"\"\"\n    temp_list = list()\n    for line in orig_list:\n        line_split = __re.split(r'(\\s+)', line)\n        temp_list.append(line_split)\n\n    return temp_list": 1146,
"def keys_to_snake_case(camel_case_dict):\n    \"\"\"\n    Make a copy of a dictionary with all keys converted to snake case. This is just calls to_snake_case on\n    each of the keys in the dictionary and returns a new dictionary.\n\n    :param camel_case_dict: Dictionary with the keys to convert.\n    :type camel_case_dict: Dictionary.\n\n    :return: Dictionary with the keys converted to snake case.\n    \"\"\"\n    return dict((to_snake_case(key), value) for (key, value) in camel_case_dict.items())": 173,
"def equal(list1, list2):\n    \"\"\" takes flags returns indexes of True values \"\"\"\n    return [item1 == item2 for item1, item2 in broadcast_zip(list1, list2)]": 480,
"def process_request(self, request, response):\n        \"\"\"Logs the basic endpoint requested\"\"\"\n        self.logger.info('Requested: {0} {1} {2}'.format(request.method, request.relative_uri, request.content_type))": 2496,
"def glr_path_static():\n    \"\"\"Returns path to packaged static files\"\"\"\n    return os.path.abspath(os.path.join(os.path.dirname(__file__), '_static'))": 2404,
"def validate(request: Union[Dict, List], schema: dict) -> Union[Dict, List]:\n    \"\"\"\n    Wraps jsonschema.validate, returning the same object passed in.\n\n    Args:\n        request: The deserialized-from-json request.\n        schema: The jsonschema schema to validate against.\n\n    Raises:\n        jsonschema.ValidationError\n    \"\"\"\n    jsonschema_validate(request, schema)\n    return request": 6156,
"def good(txt):\n    \"\"\"Print, emphasized 'good', the given 'txt' message\"\"\"\n\n    print(\"%s# %s%s%s\" % (PR_GOOD_CC, get_time_stamp(), txt, PR_NC))\n    sys.stdout.flush()": 362,
"def im2mat(I):\n    \"\"\"Converts and image to matrix (one pixel per line)\"\"\"\n    return I.reshape((I.shape[0] * I.shape[1], I.shape[2]))": 1120,
"def wait(self, timeout=None):\n    \"\"\"\n    Block until all jobs in the ThreadPool are finished. Beware that this can\n    make the program run into a deadlock if another thread adds new jobs to the\n    pool!\n\n    # Raises\n    Timeout: If the timeout is exceeded.\n    \"\"\"\n\n    if not self.__running:\n      raise RuntimeError(\"ThreadPool ain't running\")\n    self.__queue.wait(timeout)": 5005,
"def seconds(num):\n    \"\"\"\n    Pause for this many seconds\n    \"\"\"\n    now = pytime.time()\n    end = now + num\n    until(end)": 2450,
"def str_to_time(time_str: str) -> datetime.datetime:\n    \"\"\"\n    Convert human readable string to datetime.datetime.\n    \"\"\"\n    pieces: Any = [int(piece) for piece in time_str.split('-')]\n    return datetime.datetime(*pieces)": 5606,
"def is_executable(path):\n  \"\"\"Returns whether a path names an existing executable file.\"\"\"\n  return os.path.isfile(path) and os.access(path, os.X_OK)": 2939,
"def full(self):\n        \"\"\"Return ``True`` if the queue is full, ``False``\n        otherwise (not reliable!).\n\n        Only applicable if :attr:`maxsize` is set.\n\n        \"\"\"\n        return self.maxsize and len(self.list) >= self.maxsize or False": 5555,
"def search(self, filterstr, attrlist):\n        \"\"\"Query the configured LDAP server.\"\"\"\n        return self._paged_search_ext_s(self.settings.BASE, ldap.SCOPE_SUBTREE, filterstr=filterstr,\n                                        attrlist=attrlist, page_size=self.settings.PAGE_SIZE)": 5470,
"def fill_document(doc):\n    \"\"\"Add a section, a subsection and some text to the document.\n\n    :param doc: the document\n    :type doc: :class:`pylatex.document.Document` instance\n    \"\"\"\n    with doc.create(Section('A section')):\n        doc.append('Some regular text and some ')\n        doc.append(italic('italic text. '))\n\n        with doc.create(Subsection('A subsection')):\n            doc.append('Also some crazy characters: $&#{}')": 1938,
"def _serialize_json(obj, fp):\n    \"\"\" Serialize ``obj`` as a JSON formatted stream to ``fp`` \"\"\"\n    json.dump(obj, fp, indent=4, default=serialize)": 1198,
"def last_location_of_minimum(x):\n    \"\"\"\n    Returns the last location of the minimal value of x.\n    The position is calculated relatively to the length of x.\n\n    :param x: the time series to calculate the feature of\n    :type x: numpy.ndarray\n    :return: the value of this feature\n    :return type: float\n    \"\"\"\n    x = np.asarray(x)\n    return 1.0 - np.argmin(x[::-1]) / len(x) if len(x) > 0 else np.NaN": 5578,
"def expect_all(a, b):\n    \"\"\"\\\n    Asserts that two iterables contain the same values.\n    \"\"\"\n    assert all(_a == _b for _a, _b in zip_longest(a, b))": 2621,
"def load(self):\n        \"\"\"Load proxy list from configured proxy source\"\"\"\n        self._list = self._source.load()\n        self._list_iter = itertools.cycle(self._list)": 934,
"def lognorm(x, mu, sigma=1.0):\n    \"\"\" Log-normal function from scipy \"\"\"\n    return stats.lognorm(sigma, scale=mu).pdf(x)": 741,
"def gcd_float(numbers, tol=1e-8):\n    \"\"\"\n    Returns the greatest common divisor for a sequence of numbers.\n    Uses a numerical tolerance, so can be used on floats\n\n    Args:\n        numbers: Sequence of numbers.\n        tol: Numerical tolerance\n\n    Returns:\n        (int) Greatest common divisor of numbers.\n    \"\"\"\n\n    def pair_gcd_tol(a, b):\n        \"\"\"Calculate the Greatest Common Divisor of a and b.\n\n        Unless b==0, the result will have the same sign as b (so that when\n        b is divided by it, the result comes out positive).\n        \"\"\"\n        while b > tol:\n            a, b = b, a % b\n        return a\n\n    n = numbers[0]\n    for i in numbers:\n        n = pair_gcd_tol(n, i)\n    return n": 5816,
"def Flush(self):\n    \"\"\"Flush all items from cache.\"\"\"\n    while self._age:\n      node = self._age.PopLeft()\n      self.KillObject(node.data)\n\n    self._hash = dict()": 254,
"def vector_distance(a, b):\n    \"\"\"The Euclidean distance between two vectors.\"\"\"\n    a = np.array(a)\n    b = np.array(b)\n    return np.linalg.norm(a - b)": 466,
"def auto():\n\t\"\"\"set colouring on if STDOUT is a terminal device, off otherwise\"\"\"\n\ttry:\n\t\tStyle.enabled = False\n\t\tStyle.enabled = sys.stdout.isatty()\n\texcept (AttributeError, TypeError):\n\t\tpass": 1007,
"def from_years_range(start_year, end_year):\n        \"\"\"Transform a range of years (two ints) to a DateRange object.\"\"\"\n        start = datetime.date(start_year, 1 , 1)\n        end = datetime.date(end_year, 12 , 31)\n        return DateRange(start, end)": 3206,
"def safe_dump(data, stream=None, **kwds):\n    \"\"\"implementation of safe dumper using Ordered Dict Yaml Dumper\"\"\"\n    return yaml.dump(data, stream=stream, Dumper=ODYD, **kwds)": 1351,
"def is_array(type_):\n    \"\"\"returns True, if type represents C++ array type, False otherwise\"\"\"\n    nake_type = remove_alias(type_)\n    nake_type = remove_reference(nake_type)\n    nake_type = remove_cv(nake_type)\n    return isinstance(nake_type, cpptypes.array_t)": 5116,
"def apply(self, func, args=(), kwds=dict()):\n        \"\"\"Equivalent of the apply() builtin function. It blocks till\n        the result is ready.\"\"\"\n        return self.apply_async(func, args, kwds).get()": 4964,
"def reload(self, save_config=True):\n        \"\"\"Reload the device.\n\n        !!!WARNING! there is unsaved configuration!!!\n        This command will reboot the system. (y/n)?  [n]\n        \"\"\"\n        if save_config:\n            self.device.send(\"copy running-config startup-config\")\n        self.device(\"reload\", wait_for_string=\"This command will reboot the system\")\n        self.device.ctrl.sendline(\"y\")": 4804,
"def conv_dict(self):\n        \"\"\"dictionary of conversion\"\"\"\n        return dict(integer=self.integer, real=self.real, no_type=self.no_type)": 650,
"def to_0d_array(value: Any) -> np.ndarray:\n    \"\"\"Given a value, wrap it in a 0-D numpy.ndarray.\n    \"\"\"\n    if np.isscalar(value) or (isinstance(value, np.ndarray) and\n                              value.ndim == 0):\n        return np.array(value)\n    else:\n        return to_0d_object_array(value)": 5815,
"def get_tokens(line: str) -> Iterator[str]:\n    \"\"\"\n    Yields tokens from input string.\n\n    :param line: Input string.\n    :return: Iterator over tokens.\n    \"\"\"\n    for token in line.rstrip().split():\n        if len(token) > 0:\n            yield token": 6106,
"def ansi(color, text):\n    \"\"\"Wrap text in an ansi escape sequence\"\"\"\n    code = COLOR_CODES[color]\n    return '\\033[1;{0}m{1}{2}'.format(code, text, RESET_TERM)": 2234,
"def has_value(cls, value: int) -> bool:\n        \"\"\"True if specified value exists in int enum; otherwise, False.\"\"\"\n        return any(value == item.value for item in cls)": 5812,
"def get_table_names(connection):\n\t\"\"\"\n\tReturn a list of the table names in the database.\n\t\"\"\"\n\tcursor = connection.cursor()\n\tcursor.execute(\"SELECT name FROM sqlite_master WHERE type == 'table'\")\n\treturn [name for (name,) in cursor]": 716,
"def parse_query_string(query):\n    \"\"\"\n    parse_query_string:\n    very simplistic. won't do the right thing with list values\n    \"\"\"\n    result = {}\n    qparts = query.split('&')\n    for item in qparts:\n        key, value = item.split('=')\n        key = key.strip()\n        value = value.strip()\n        result[key] = unquote_plus(value)\n    return result": 2201,
"def isolate_element(self, x):\n        \"\"\"Isolates `x` from its equivalence class.\"\"\"\n        members = list(self.members(x))\n        self.delete_set(x)\n        self.union(*(v for v in members if v != x))": 3147,
"def get_list_from_file(file_name):\n    \"\"\"read the lines from a file into a list\"\"\"\n    with open(file_name, mode='r', encoding='utf-8') as f1:\n        lst = f1.readlines()\n    return lst": 3132,
"def update(self, params):\n        \"\"\"Update the dev_info data from a dictionary.\n\n        Only updates if it already exists in the device.\n        \"\"\"\n        dev_info = self.json_state.get('deviceInfo')\n        dev_info.update({k: params[k] for k in params if dev_info.get(k)})": 2899,
"def right_replace(string, old, new, count=1):\n    \"\"\"\n    Right replaces ``count`` occurrences of ``old`` with ``new`` in ``string``.\n    For example::\n\n        right_replace('one_two_two', 'two', 'three') -> 'one_two_three'\n    \"\"\"\n    if not string:\n        return string\n    return new.join(string.rsplit(old, count))": 5625,
"def get_attribute_name_id(attr):\n    \"\"\"\n    Return the attribute name identifier\n    \"\"\"\n    return attr.value.id if isinstance(attr.value, ast.Name) else None": 1522,
"def object_as_dict(obj):\n    \"\"\"Turn an SQLAlchemy model into a dict of field names and values.\n\n    Based on https://stackoverflow.com/a/37350445/1579058\n    \"\"\"\n    return {c.key: getattr(obj, c.key)\n            for c in inspect(obj).mapper.column_attrs}": 1849,
"def fetchvalue(self, sql: str, *args) -> Optional[Any]:\n        \"\"\"Executes SQL; returns the first value of the first row, or None.\"\"\"\n        row = self.fetchone(sql, *args)\n        if row is None:\n            return None\n        return row[0]": 5806,
"def add_url_rule(self, route, endpoint, handler):\n        \"\"\"Add a new url route.\n\n        Args:\n            See flask.Flask.add_url_route().\n        \"\"\"\n        self.app.add_url_rule(route, endpoint, handler)": 3536,
"def get_default_args(func):\n    \"\"\"\n    returns a dictionary of arg_name:default_values for the input function\n    \"\"\"\n    args, varargs, keywords, defaults = getargspec_no_self(func)\n    return dict(zip(args[-len(defaults):], defaults))": 139,
"def _fill(self):\n    \"\"\"Advance the iterator without returning the old head.\"\"\"\n    try:\n      self._head = self._iterable.next()\n    except StopIteration:\n      self._head = None": 2052,
"def getBitmap(self):\n        \"\"\" Captures screen area of this region, at least the part that is on the screen\n\n        Returns image as numpy array\n        \"\"\"\n        return PlatformManager.getBitmapFromRect(self.x, self.y, self.w, self.h)": 4850,
"def setup_environment():\n    \"\"\"Set up neccessary environment variables\n\n    This appends all path of sys.path to the python path\n    so mayapy will find all installed modules.\n    We have to make sure, that we use maya libs instead of\n    libs of the virtual env. So we insert all the libs for mayapy\n    first.\n\n    :returns: None\n    :rtype: None\n    :raises: None\n    \"\"\"\n    osinter = ostool.get_interface()\n    pypath = osinter.get_maya_envpath()\n    for p in sys.path:\n        pypath = os.pathsep.join((pypath, p))\n    os.environ['PYTHONPATH'] = pypath": 4771,
"def uppercase_chars(string: any) -> str:\n        \"\"\"Return all (and only) the uppercase chars in the given string.\"\"\"\n        return ''.join([c if c.isupper() else '' for c in str(string)])": 5661,
"def get_last_commit(git_path=None):\n    \"\"\"\n    Get the HEAD commit SHA1 of repository in current dir.\n    \"\"\"\n    if git_path is None: git_path = GIT_PATH\n    line = get_last_commit_line(git_path)\n    revision_id = line.split()[1]\n    return revision_id": 421,
"def do_restart(self, line):\n        \"\"\"Request that the Outstation perform a cold restart. Command syntax is: restart\"\"\"\n        self.application.master.Restart(opendnp3.RestartType.COLD, restart_callback)": 2293,
"def __run(self):\n    \"\"\"Hacked run function, which installs the trace.\"\"\"\n    sys.settrace(self.globaltrace)\n    self.__run_backup()\n    self.run = self.__run_backup": 2799,
"def clean(dry_run='n'):\n    \"\"\"Wipes compiled and cached python files. To simulate: pynt clean[dry_run=y]\"\"\"\n    file_patterns = ['*.pyc', '*.pyo', '*~']\n    dir_patterns = ['__pycache__']\n    recursive_pattern_delete(project_paths.root, file_patterns, dir_patterns, dry_run=bool(dry_run.lower() == 'y'))": 4126,
"def test3():\n    \"\"\"Test the multiprocess\n    \"\"\"\n    import time\n    \n    p = MVisionProcess()\n    p.start()\n    time.sleep(5)\n    p.stop()": 2206,
"def walk_tree(root):\n    \"\"\"Pre-order depth-first\"\"\"\n    yield root\n\n    for child in root.children:\n        for el in walk_tree(child):\n            yield el": 1282,
"def timeit(func, *args, **kwargs):\n    \"\"\"\n    Time execution of function. Returns (res, seconds).\n\n    >>> res, timing = timeit(time.sleep, 1)\n    \"\"\"\n    start_time = time.time()\n    res = func(*args, **kwargs)\n    timing = time.time() - start_time\n    return res, timing": 5785,
"def stop(self):\n        \"\"\"Stops playback\"\"\"\n        if self.isPlaying is True:\n            self._execute(\"stop\")\n            self._changePlayingState(False)": 4166,
"def dictlist_replace(dict_list: Iterable[Dict], key: str, value: Any) -> None:\n    \"\"\"\n    Process an iterable of dictionaries. For each dictionary ``d``, change\n    (in place) ``d[key]`` to ``value``.\n    \"\"\"\n    for d in dict_list:\n        d[key] = value": 6132,
"def do(self):\n        \"\"\"\n        Set a restore point (copy the object), then call the method.\n        :return: obj.do_method(*args)\n        \"\"\"\n        self.restore_point = self.obj.copy()\n        return self.do_method(self.obj, *self.args)": 4536,
"def read_raw(data_path):\n    \"\"\"\n    Parameters\n    ----------\n    data_path : str\n    \"\"\"\n    with open(data_path, 'rb') as f:\n        data = pickle.load(f)\n    return data": 4715,
"def flatten(nested):\n    \"\"\" Return a flatten version of the nested argument \"\"\"\n    flat_return = list()\n\n    def __inner_flat(nested,flat):\n        for i in nested:\n            __inner_flat(i, flat) if isinstance(i, list) else flat.append(i)\n        return flat\n\n    __inner_flat(nested,flat_return)\n\n    return flat_return": 1816,
"def indented_show(text, howmany=1):\n        \"\"\"Print a formatted indented text.\n        \"\"\"\n        print(StrTemplate.pad_indent(text=text, howmany=howmany))": 1446,
"def _isint(string):\n    \"\"\"\n    >>> _isint(\"123\")\n    True\n    >>> _isint(\"123.45\")\n    False\n    \"\"\"\n    return type(string) is int or \\\n           (isinstance(string, _binary_type) or isinstance(string, _text_type)) and \\\n           _isconvertible(int, string)": 5776,
"def read_set_from_file(filename: str) -> Set[str]:\n    \"\"\"\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    \"\"\"\n    collection = set()\n    with open(filename, 'r') as file_:\n        for line in file_:\n            collection.add(line.rstrip())\n    return collection": 5611,
"def __init__(self):\n        \"\"\"__init__: Performs basic initialisations\"\"\"\n        # Root parser\n        self.parser = argparse.ArgumentParser()\n        # Subparsers\n        self.subparsers = self.parser.add_subparsers()\n        # Parser dictionary, to avoir overwriting existing parsers\n        self.parsers = {}": 3225,
"def nonull_dict(self):\n        \"\"\"Like dict, but does not hold any null values.\n\n        :return:\n\n        \"\"\"\n        return {k: v for k, v in six.iteritems(self.dict) if v and k != '_codes'}": 193,
"def generate_hash(filepath):\n    \"\"\"Public function that reads a local file and generates a SHA256 hash digest for it\"\"\"\n    fr = FileReader(filepath)\n    data = fr.read_bin()\n    return _calculate_sha256(data)": 3336,
"def parse_func_kwarg_keys(func, with_vals=False):\n    \"\"\" hacky inference of kwargs keys\n\n    SeeAlso:\n        argparse_funckw\n        recursive_parse_kwargs\n        parse_kwarg_keys\n        parse_func_kwarg_keys\n        get_func_kwargs\n\n    \"\"\"\n    sourcecode = get_func_sourcecode(func, strip_docstr=True,\n                                     strip_comments=True)\n    kwkeys = parse_kwarg_keys(sourcecode, with_vals=with_vals)\n    #ut.get_func_kwargs  TODO\n    return kwkeys": 3562,
"def extract_words(lines):\n    \"\"\"\n    Extract from the given iterable of lines the list of words.\n\n    :param lines: an iterable of lines;\n    :return: a generator of words of lines.\n    \"\"\"\n    for line in lines:\n        for word in re.findall(r\"\\w+\", line):\n            yield word": 2261,
"def put(self, endpoint: str, **kwargs) -> dict:\n        \"\"\"HTTP PUT operation to API endpoint.\"\"\"\n\n        return self._request('PUT', endpoint, **kwargs)": 6123,
"def threadid(self):\n        \"\"\"\n        Current thread ident. If current thread is main thread then it returns ``None``.\n\n        :type: int or None\n        \"\"\"\n        current = self.thread.ident\n        main = get_main_thread()\n        if main is None:\n            return current\n        else:\n            return current if current != main.ident else None": 2525,
"def filtany(entities, **kw):\n  \"\"\"Filter a set of entities based on method return. Use keyword arguments.\n  \n  Example:\n    filtmeth(entities, id='123')\n    filtmeth(entities, name='bart')\n\n  Multiple filters are 'OR'.\n  \"\"\"\n  ret = set()\n  for k,v in kw.items():\n    for entity in entities:\n      if getattr(entity, k)() == v:\n        ret.add(entity)\n  return ret": 2850,
"def flatten_list(x: List[Any]) -> List[Any]:\n    \"\"\"\n    Converts a list of lists into a flat list.\n    \n    Args:\n        x: list of lists \n\n    Returns:\n        flat list\n        \n    As per\n    http://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python\n\n    \"\"\"  # noqa\n    return [item for sublist in x for item in sublist]": 5658,
"def numpy_to_yaml(representer: Representer, data: np.ndarray) -> Sequence[Any]:\n    \"\"\" Write a numpy array to YAML.\n\n    It registers the array under the tag ``!numpy_array``.\n\n    Use with:\n\n    .. code-block:: python\n\n        >>> yaml = ruamel.yaml.YAML()\n        >>> yaml.representer.add_representer(np.ndarray, yaml.numpy_to_yaml)\n\n    Note:\n        We cannot use ``yaml.register_class`` because it won't register the proper type.\n        (It would register the type of the class, rather than of `numpy.ndarray`). Instead,\n        we use the above approach to register this method explicitly with the representer.\n    \"\"\"\n    return representer.represent_sequence(\n        \"!numpy_array\",\n        data.tolist()\n    )": 6117,
"def get_user_by_id(self, id):\n        \"\"\"Retrieve a User object by ID.\"\"\"\n        return self.db_adapter.get_object(self.UserClass, id=id)": 620,
"def count(args):\n    \"\"\" count occurences in a list of lists\n    >>> count([['a','b'],['a']])\n    defaultdict(int, {'a' : 2, 'b' : 1})\n    \"\"\"\n    counts = defaultdict(int)\n    for arg in args:\n        for item in arg:\n            counts[item] = counts[item] + 1\n    return counts": 5768,
"def impute_data(self,x):\n        \"\"\"Imputes data set containing Nan values\"\"\"\n        imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n        return imp.fit_transform(x)": 3840,
"def revrank_dict(dict, key=lambda t: t[1], as_tuple=False):\n    \"\"\" Reverse sorts a #dict by a given key, optionally returning it as a\n        #tuple. By default, the @dict is sorted by it's value.\n\n        @dict: the #dict you wish to sorts\n        @key: the #sorted key to use\n        @as_tuple: returns result as a #tuple ((k, v),...)\n\n        -> :class:OrderedDict or #tuple\n    \"\"\"\n    sorted_list = sorted(dict.items(), key=key, reverse=True)\n    return OrderedDict(sorted_list) if not as_tuple else tuple(sorted_list)": 5999,
"def MatrixInverse(a, adj):\n    \"\"\"\n    Matrix inversion op.\n    \"\"\"\n    return np.linalg.inv(a if not adj else _adjoint(a)),": 2512,
"def norm_slash(name):\n    \"\"\"Normalize path slashes.\"\"\"\n\n    if isinstance(name, str):\n        return name.replace('/', \"\\\\\") if not is_case_sensitive() else name\n    else:\n        return name.replace(b'/', b\"\\\\\") if not is_case_sensitive() else name": 1288,
"def compose(func_list):\n    \"\"\"\n    composion of preprocessing functions\n    \"\"\"\n\n    def f(G, bim):\n        for func in func_list:\n            G, bim = func(G, bim)\n        return G, bim\n\n    return f": 3964,
"def getRandomBinaryTreeLeafNode(binaryTree):\n    \"\"\"Get random binary tree node.\n    \"\"\"\n    if binaryTree.internal == True:\n        if random.random() > 0.5:\n            return getRandomBinaryTreeLeafNode(binaryTree.left)\n        else:\n            return getRandomBinaryTreeLeafNode(binaryTree.right)\n    else:\n        return binaryTree": 5871,
"def get_user_name():\n    \"\"\"Get user name provide by operating system\n    \"\"\"\n\n    if sys.platform == 'win32':\n        #user = os.getenv('USERPROFILE')\n        user = os.getenv('USERNAME')\n    else:\n        user = os.getenv('LOGNAME')\n\n    return user": 965,
"def __next__(self):\n    \"\"\"Pop the head off the iterator and return it.\"\"\"\n    res = self._head\n    self._fill()\n    if res is None:\n      raise StopIteration()\n    return res": 659,
"def check_create_folder(filename):\n    \"\"\"Check if the folder exisits. If not, create the folder\"\"\"\n    os.makedirs(os.path.dirname(filename), exist_ok=True)": 1598,
"def is_relative_url(url):\n    \"\"\" simple method to determine if a url is relative or absolute \"\"\"\n    if url.startswith(\"#\"):\n        return None\n    if url.find(\"://\") > 0 or url.startswith(\"//\"):\n        # either 'http(s)://...' or '//cdn...' and therefore absolute\n        return False\n    return True": 5758,
"def to_snake_case(text):\n    \"\"\"Convert to snake case.\n\n    :param str text:\n    :rtype: str\n    :return:\n    \"\"\"\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', text)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()": 1763,
"def println(msg):\n    \"\"\"\n    Convenience function to print messages on a single line in the terminal\n    \"\"\"\n    sys.stdout.write(msg)\n    sys.stdout.flush()\n    sys.stdout.write('\\x08' * len(msg))\n    sys.stdout.flush()": 3858,
"def force_iterable(f):\n    \"\"\"Will make any functions return an iterable objects by wrapping its result in a list.\"\"\"\n    def wrapper(*args, **kwargs):\n        r = f(*args, **kwargs)\n        if hasattr(r, '__iter__'):\n            return r\n        else:\n            return [r]\n    return wrapper": 570,
"def _float_feature(value):\n  \"\"\"Wrapper for inserting float features into Example proto.\"\"\"\n  if not isinstance(value, list):\n    value = [value]\n  return tf.train.Feature(float_list=tf.train.FloatList(value=value))": 4349,
"def _interval_to_bound_points(array):\n    \"\"\"\n    Helper function which returns an array\n    with the Intervals' boundaries.\n    \"\"\"\n\n    array_boundaries = np.array([x.left for x in array])\n    array_boundaries = np.concatenate(\n        (array_boundaries, np.array([array[-1].right])))\n\n    return array_boundaries": 140,
"def _requiredSize(shape, dtype):\n\t\"\"\"\n\tDetermines the number of bytes required to store a NumPy array with\n\tthe specified shape and datatype.\n\t\"\"\"\n\treturn math.floor(np.prod(np.asarray(shape, dtype=np.uint64)) * np.dtype(dtype).itemsize)": 1319,
"def remove_elements(target, indices):\n    \"\"\"Remove multiple elements from a list and return result.\n    This implementation is faster than the alternative below.\n    Also note the creation of a new list to avoid altering the\n    original. We don't have any current use for the original\n    intact list, but may in the future...\"\"\"\n\n    copied = list(target)\n\n    for index in reversed(indices):\n        del copied[index]\n    return copied": 837,
"def get_propety_by_name(pif, name):\n    \"\"\"Get a property by name\"\"\"\n    warn(\"This method has been deprecated in favor of get_property_by_name\")\n    return next((x for x in pif.properties if x.name == name), None)": 2898,
"def _is_iterable(item):\n    \"\"\" Checks if an item is iterable (list, tuple, generator), but not string \"\"\"\n    return isinstance(item, collections.Iterable) and not isinstance(item, six.string_types)": 2522,
"def prepend_line(filepath, line):\n    \"\"\"Rewrite a file adding a line to its beginning.\n    \"\"\"\n    with open(filepath) as f:\n        lines = f.readlines()\n\n    lines.insert(0, line)\n\n    with open(filepath, 'w') as f:\n        f.writelines(lines)": 629,
"def _split(string, splitters):\n    \"\"\"Splits a string into parts at multiple characters\"\"\"\n    part = ''\n    for character in string:\n        if character in splitters:\n            yield part\n            part = ''\n        else:\n            part += character\n    yield part": 1545,
"def index(self, item):\n        \"\"\" Not recommended for use on large lists due to time\n            complexity, but it works\n\n            -> #int list index of @item\n        \"\"\"\n        for i, x in enumerate(self.iter()):\n            if x == item:\n                return i\n        return None": 6214,
"def _dotify(cls, data):\n    \"\"\"Add dots.\"\"\"\n    return ''.join(char if char in cls.PRINTABLE_DATA else '.' for char in data)": 2350,
"def pop(h):\n    \"\"\"Pop the heap value from the heap.\"\"\"\n    n = h.size() - 1\n    h.swap(0, n)\n    down(h, 0, n)\n    return h.pop()": 400,
"def visit_BinOp(self, node):\n        \"\"\" Return type depend from both operand of the binary operation. \"\"\"\n        args = [self.visit(arg) for arg in (node.left, node.right)]\n        return list({frozenset.union(*x) for x in itertools.product(*args)})": 4402,
"def sort_filenames(filenames):\n    \"\"\"\n    sort a list of files by filename only, ignoring the directory names\n    \"\"\"\n    basenames = [os.path.basename(x) for x in filenames]\n    indexes = [i[0] for i in sorted(enumerate(basenames), key=lambda x:x[1])]\n    return [filenames[x] for x in indexes]": 707,
"def world_to_view(v):\n    \"\"\"world coords to view coords; v an eu.Vector2, returns (float, float)\"\"\"\n    return v.x * config.scale_x, v.y * config.scale_y": 3293,
"def sort_data(x, y):\n    \"\"\"Sort the data.\"\"\"\n    xy = sorted(zip(x, y))\n    x, y = zip(*xy)\n    return x, y": 3198,
"def save_notebook(work_notebook, write_file):\n    \"\"\"Saves the Jupyter work_notebook to write_file\"\"\"\n    with open(write_file, 'w') as out_nb:\n        json.dump(work_notebook, out_nb, indent=2)": 2462,
"def _remove_dict_keys_with_value(dict_, val):\n  \"\"\"Removes `dict` keys which have have `self` as value.\"\"\"\n  return {k: v for k, v in dict_.items() if v is not val}": 185,
"def clean_out_dir(directory):\n    \"\"\"\n    Delete all the files and subdirectories in a directory.\n    \"\"\"\n    if not isinstance(directory, path):\n        directory = path(directory)\n    for file_path in directory.files():\n        file_path.remove()\n    for dir_path in directory.dirs():\n        dir_path.rmtree()": 1906,
"def push(h, x):\n    \"\"\"Push a new value into heap.\"\"\"\n    h.push(x)\n    up(h, h.size()-1)": 47,
"def chmod_add_excute(filename):\n        \"\"\"\n        Adds execute permission to file.\n        :param filename:\n        :return:\n        \"\"\"\n        st = os.stat(filename)\n        os.chmod(filename, st.st_mode | stat.S_IEXEC)": 1152,
"def fetch_event(urls):\n    \"\"\"\n    This parallel fetcher uses gevent one uses gevent\n    \"\"\"\n    rs = (grequests.get(u) for u in urls)\n    return [content.json() for content in grequests.map(rs)]": 478,
"def clean(s):\n  \"\"\"Removes trailing whitespace on each line.\"\"\"\n  lines = [l.rstrip() for l in s.split('\\n')]\n  return '\\n'.join(lines)": 2581,
"def get_python(self):\n        \"\"\"Only return cursor instance if configured for multiselect\"\"\"\n        if self.multiselect:\n            return super(MultiSelectField, self).get_python()\n\n        return self._get()": 3498,
"def go_to_new_line(self):\n        \"\"\"Go to the end of the current line and create a new line\"\"\"\n        self.stdkey_end(False, False)\n        self.insert_text(self.get_line_separator())": 428,
"def rgba_bytes_tuple(self, x):\n        \"\"\"Provides the color corresponding to value `x` in the\n        form of a tuple (R,G,B,A) with int values between 0 and 255.\n        \"\"\"\n        return tuple(int(u*255.9999) for u in self.rgba_floats_tuple(x))": 1551,
"def purge_dict(idict):\n    \"\"\"Remove null items from a dictionary \"\"\"\n    odict = {}\n    for key, val in idict.items():\n        if is_null(val):\n            continue\n        odict[key] = val\n    return odict": 1017,
"def pprint(obj, verbose=False, max_width=79, newline='\\n'):\n    \"\"\"\n    Like `pretty` but print to stdout.\n    \"\"\"\n    printer = RepresentationPrinter(sys.stdout, verbose, max_width, newline)\n    printer.pretty(obj)\n    printer.flush()\n    sys.stdout.write(newline)\n    sys.stdout.flush()": 2225,
"def determine_interactive(self):\n\t\t\"\"\"Determine whether we're in an interactive shell.\n\t\tSets interactivity off if appropriate.\n\t\tcf http://stackoverflow.com/questions/24861351/how-to-detect-if-python-script-is-being-run-as-a-background-process\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif not sys.stdout.isatty() or os.getpgrp() != os.tcgetpgrp(sys.stdout.fileno()):\n\t\t\t\tself.interactive = 0\n\t\t\t\treturn False\n\t\texcept Exception:\n\t\t\tself.interactive = 0\n\t\t\treturn False\n\t\tif self.interactive == 0:\n\t\t\treturn False\n\t\treturn True": 2779,
"def pid_exists(pid):\n    \"\"\" Determines if a system process identifer exists in process table.\n        \"\"\"\n    try:\n        os.kill(pid, 0)\n    except OSError as exc:\n        return exc.errno == errno.EPERM\n    else:\n        return True": 528,
"def insert_one(self, mongo_collection, doc, mongo_db=None, **kwargs):\n        \"\"\"\n        Inserts a single document into a mongo collection\n        https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.insert_one\n        \"\"\"\n        collection = self.get_collection(mongo_collection, mongo_db=mongo_db)\n\n        return collection.insert_one(doc, **kwargs)": 4267,
"def _read_json_file(self, json_file):\n        \"\"\" Helper function to read JSON file as OrderedDict \"\"\"\n\n        self.log.debug(\"Reading '%s' JSON file...\" % json_file)\n\n        with open(json_file, 'r') as f:\n            return json.load(f, object_pairs_hook=OrderedDict)": 3131,
"async def join(self, ctx, *, channel: discord.VoiceChannel):\n        \"\"\"Joins a voice channel\"\"\"\n\n        if ctx.voice_client is not None:\n            return await ctx.voice_client.move_to(channel)\n\n        await channel.connect()": 1923,
"def test():\n    \"\"\"Run the unit tests.\"\"\"\n    import unittest\n    tests = unittest.TestLoader().discover('tests')\n    unittest.TextTestRunner(verbosity=2).run(tests)": 199,
"async def _send_plain_text(self, request: Request, stack: Stack):\n        \"\"\"\n        Sends plain text using `_send_text()`.\n        \"\"\"\n\n        await self._send_text(request, stack, None)": 1510,
"def _format_title_string(self, title_string):\n        \"\"\" format mpv's title \"\"\"\n        return self._title_string_format_text_tag(title_string.replace(self.icy_tokkens[0], self.icy_title_prefix))": 4355,
"def downsample(array, k):\n    \"\"\"Choose k random elements of array.\"\"\"\n    length = array.shape[0]\n    indices = random.sample(xrange(length), k)\n    return array[indices]": 794,
"def get_file_string(filepath):\n    \"\"\"Get string from file.\"\"\"\n    with open(os.path.abspath(filepath)) as f:\n        return f.read()": 1051,
"def distance(vec1, vec2):\n        \"\"\"Calculate the distance between two Vectors\"\"\"\n        if isinstance(vec1, Vector2) \\\n                and isinstance(vec2, Vector2):\n            dist_vec = vec2 - vec1\n            return dist_vec.length()\n        else:\n            raise TypeError(\"vec1 and vec2 must be Vector2's\")": 2719,
"def get_dimension_array(array):\n    \"\"\"\n    Get dimension of an array getting the number of rows and the max num of\n    columns.\n    \"\"\"\n    if all(isinstance(el, list) for el in array):\n        result = [len(array), len(max([x for x in array], key=len,))]\n\n    # elif array and isinstance(array, list):\n    else:\n        result = [len(array), 1]\n\n    return result": 2080,
"def comma_delimited_to_list(list_param):\n    \"\"\"Convert comma-delimited list / string into a list of strings\n\n    :param list_param: Comma-delimited string\n    :type list_param: str | unicode\n    :return: A list of strings\n    :rtype: list\n    \"\"\"\n    if isinstance(list_param, list):\n        return list_param\n    if isinstance(list_param, str):\n        return list_param.split(',')\n    else:\n        return []": 3278,
"def dictlist_wipe_key(dict_list: Iterable[Dict], key: str) -> None:\n    \"\"\"\n    Process an iterable of dictionaries. For each dictionary ``d``, delete\n    ``d[key]`` if it exists.\n    \"\"\"\n    for d in dict_list:\n        d.pop(key, None)": 5594,
"def set_value(self, value):\n        \"\"\"Set value of the checkbox.\n\n        Parameters\n        ----------\n        value : bool\n            value for the checkbox\n\n        \"\"\"\n        if value:\n            self.setChecked(Qt.Checked)\n        else:\n            self.setChecked(Qt.Unchecked)": 1655,
"def Softsign(a):\n    \"\"\"\n    Softsign op.\n    \"\"\"\n    return np.divide(a, np.add(np.abs(a), 1)),": 2107,
"def __len__(self):\n\t\t\"\"\"Get a list of the public data attributes.\"\"\"\n\t\treturn len([i for i in (set(dir(self)) - self._STANDARD_ATTRS) if i[0] != '_'])": 4818,
"def read(self):\n        \"\"\"https://picamera.readthedocs.io/en/release-1.13/recipes1.html#capturing-to-a-pil-image\"\"\"\n        stream = BytesIO()\n        self.cam.capture(stream, format='png')\n        # \"Rewind\" the stream to the beginning so we can read its content\n        stream.seek(0)\n        return Image.open(stream)": 3731,
"def logout(cache):\n    \"\"\"\n    Logs out the current session by removing it from the cache. This is\n    expected to only occur when a session has\n    \"\"\"\n    cache.set(flask.session['auth0_key'], None)\n    flask.session.clear()\n    return True": 1809,
"def save(self):\n        \"\"\"Saves the updated model to the current entity db.\n        \"\"\"\n        self.session.add(self)\n        self.session.flush()\n        return self": 3229,
"def do_next(self, args):\n        \"\"\"Step over the next statement\n        \"\"\"\n        self._do_print_from_last_cmd = True\n        self._interp.step_over()\n        return True": 36,
"def is_string(obj):\n    \"\"\"Is this a string.\n\n    :param object obj:\n    :rtype: bool\n    \"\"\"\n    if PYTHON3:\n        str_type = (bytes, str)\n    else:\n        str_type = (bytes, str, unicode)\n    return isinstance(obj, str_type)": 1789,
"def log_loss(preds, labels):\n    \"\"\"Logarithmic loss with non-necessarily-binary labels.\"\"\"\n    log_likelihood = np.sum(labels * np.log(preds)) / len(preds)\n    return -log_likelihood": 1366,
"def __init__(self, master=None, compound=tk.RIGHT, autohidescrollbar=True, **kwargs):\n        \"\"\"\n        Create a Listbox with a vertical scrollbar.\n\n        :param master: master widget\n        :type master: widget\n        :param compound: side for the Scrollbar to be on (:obj:`tk.LEFT` or :obj:`tk.RIGHT`)\n        :type compound: str\n        :param autohidescrollbar: whether to use an :class:`~ttkwidgets.AutoHideScrollbar` or a :class:`ttk.Scrollbar`\n        :type autohidescrollbar: bool\n        :param kwargs: keyword arguments passed on to the :class:`tk.Listbox` initializer\n        \"\"\"\n        ttk.Frame.__init__(self, master)\n        self.columnconfigure(1, weight=1)\n        self.rowconfigure(0, weight=1)\n        self.listbox = tk.Listbox(self, **kwargs)\n        if autohidescrollbar:\n            self.scrollbar = AutoHideScrollbar(self, orient=tk.VERTICAL, command=self.listbox.yview)\n        else:\n            self.scrollbar = ttk.Scrollbar(self, orient=tk.VERTICAL, command=self.listbox.yview)\n        self.config_listbox(yscrollcommand=self.scrollbar.set)\n        if compound is not tk.LEFT and compound is not tk.RIGHT:\n            raise ValueError(\"Invalid compound value passed: {0}\".format(compound))\n        self.__compound = compound\n        self._grid_widgets()": 2585,
"def most_significant_bit(lst: np.ndarray) -> int:\n    \"\"\"\n    A helper function that finds the position of the most significant bit in a 1darray of 1s and 0s,\n    i.e. the first position where a 1 appears, reading left to right.\n\n    :param lst: a 1d array of 0s and 1s with at least one 1\n    :return: the first position in lst that a 1 appears\n    \"\"\"\n    return np.argwhere(np.asarray(lst) == 1)[0][0]": 5604,
"def _tab(content):\n    \"\"\"\n    Helper funcation that converts text-based get response\n    to tab separated values for additional manipulation.\n    \"\"\"\n    response = _data_frame(content).to_csv(index=False,sep='\\t')\n    return response": 3949,
"def normalize(data):\n    \"\"\"Normalize the data to be in the [0, 1] range.\n\n    :param data:\n    :return: normalized data\n    \"\"\"\n    out_data = data.copy()\n\n    for i, sample in enumerate(out_data):\n        out_data[i] /= sum(out_data[i])\n\n    return out_data": 4155,
"def is_finite(value: Any) -> bool:\n    \"\"\"Return true if a value is a finite number.\"\"\"\n    return isinstance(value, int) or (isinstance(value, float) and isfinite(value))": 5686,
"def remove_blank_lines(string):\n    \"\"\" Removes all blank lines in @string\n\n        -> #str without blank lines\n    \"\"\"\n    return \"\\n\".join(line\n                     for line in string.split(\"\\n\")\n                     if len(line.strip()))": 5725,
"def find_duplicates(l: list) -> set:\n    \"\"\"\n    Return the duplicates in a list.\n\n    The function relies on\n    https://stackoverflow.com/questions/9835762/find-and-list-duplicates-in-a-list .\n    Parameters\n    ----------\n    l : list\n        Name\n\n    Returns\n    -------\n    set\n        Duplicated values\n\n    >>> find_duplicates([1,2,3])\n    set()\n    >>> find_duplicates([1,2,1])\n    {1}\n    \"\"\"\n    return set([x for x in l if l.count(x) > 1])": 5743,
"def label_saves(name):\n    \"\"\"Labels plots and saves file\"\"\"\n    plt.legend(loc=0)\n    plt.ylim([0, 1.025])\n    plt.xlabel('$U/D$', fontsize=20)\n    plt.ylabel('$Z$', fontsize=20)\n    plt.savefig(name, dpi=300, format='png',\n            transparent=False, bbox_inches='tight', pad_inches=0.05)": 4900,
"def itemlist(item, sep, suppress_trailing=True):\n    \"\"\"Create a list of items seperated by seps.\"\"\"\n    return condense(item + ZeroOrMore(addspace(sep + item)) + Optional(sep.suppress() if suppress_trailing else sep))": 5110,
"def to_list(self):\n        \"\"\"Convert this confusion matrix into a 2x2 plain list of values.\"\"\"\n        return [[int(self.table.cell_values[0][1]), int(self.table.cell_values[0][2])],\n                [int(self.table.cell_values[1][1]), int(self.table.cell_values[1][2])]]": 2686,
"def cross_v2(vec1, vec2):\n    \"\"\"Return the crossproduct of the two vectors as a Vec2.\n    Cross product doesn't really make sense in 2D, but return the Z component\n    of the 3d result.\n    \"\"\"\n\n    return vec1.y * vec2.x - vec1.x * vec2.y": 4513,
"def Fsphere(q, R):\n    \"\"\"Scattering form-factor amplitude of a sphere normalized to F(q=0)=V\n\n    Inputs:\n    -------\n        ``q``: independent variable\n        ``R``: sphere radius\n\n    Formula:\n    --------\n        ``4*pi/q^3 * (sin(qR) - qR*cos(qR))``\n    \"\"\"\n    return 4 * np.pi / q ** 3 * (np.sin(q * R) - q * R * np.cos(q * R))": 1008,
"def is_readable_dir(path):\n  \"\"\"Returns whether a path names an existing directory we can list and read files from.\"\"\"\n  return os.path.isdir(path) and os.access(path, os.R_OK) and os.access(path, os.X_OK)": 1644,
"def assert_exactly_one_true(bool_list):\n    \"\"\"This method asserts that only one value of the provided list is True.\n\n    :param bool_list: List of booleans to check\n    :return: True if only one value is True, False otherwise\n    \"\"\"\n    assert isinstance(bool_list, list)\n    counter = 0\n    for item in bool_list:\n        if item:\n            counter += 1\n    return counter == 1": 69,
"def EnumValueName(self, enum, value):\n    \"\"\"Returns the string name of an enum value.\n\n    This is just a small helper method to simplify a common operation.\n\n    Args:\n      enum: string name of the Enum.\n      value: int, value of the enum.\n\n    Returns:\n      string name of the enum value.\n\n    Raises:\n      KeyError if either the Enum doesn't exist or the value is not a valid\n        value for the enum.\n    \"\"\"\n    return self.enum_types_by_name[enum].values_by_number[value].name": 471,
"def POINTER(obj):\n    \"\"\"\n    Create ctypes pointer to object.\n\n    Notes\n    -----\n    This function converts None to a real NULL pointer because of bug\n    in how ctypes handles None on 64-bit platforms.\n\n    \"\"\"\n\n    p = ctypes.POINTER(obj)\n    if not isinstance(p.from_param, classmethod):\n        def from_param(cls, x):\n            if x is None:\n                return cls()\n            else:\n                return x\n        p.from_param = classmethod(from_param)\n\n    return p": 1683,
"def md5_string(s):\n    \"\"\"\n    Shortcut to create md5 hash\n    :param s:\n    :return:\n    \"\"\"\n    m = hashlib.md5()\n    m.update(s)\n    return str(m.hexdigest())": 1193,
"def intersect(d1, d2):\n    \"\"\"Intersect dictionaries d1 and d2 by key *and* value.\"\"\"\n    return dict((k, d1[k]) for k in d1 if k in d2 and d1[k] == d2[k])": 556,
"def convertToBool():\n    \"\"\" Convert a byte value to boolean (0 or 1) if\n    the global flag strictBool is True\n    \"\"\"\n    if not OPTIONS.strictBool.value:\n        return []\n\n    REQUIRES.add('strictbool.asm')\n\n    result = []\n    result.append('pop af')\n    result.append('call __NORMALIZE_BOOLEAN')\n    result.append('push af')\n\n    return result": 257,
"def append_query_parameter(url, parameters, ignore_if_exists=True):\n    \"\"\" quick and dirty appending of query parameters to a url \"\"\"\n    if ignore_if_exists:\n        for key in parameters.keys():\n            if key + \"=\" in url:\n                del parameters[key]\n    parameters_str = \"&\".join(k + \"=\" + v for k, v in parameters.items())\n    append_token = \"&\" if \"?\" in url else \"?\"\n    return url + append_token + parameters_str": 4628,
"def is_static(*p):\n    \"\"\" A static value (does not change at runtime)\n    which is known at compile time\n    \"\"\"\n    return all(is_CONST(x) or\n               is_number(x) or\n               is_const(x)\n               for x in p)": 1184,
"def _(f, x):\n    \"\"\"\n    filter for dict, note `f` should have signature: `f::key->value->bool`\n    \"\"\"\n    return {k: v for k, v in x.items() if f(k, v)}": 5644,
"def from_file(file_path) -> dict:\n        \"\"\" Load JSON file \"\"\"\n        with io.open(file_path, 'r', encoding='utf-8') as json_stream:\n            return Json.parse(json_stream, True)": 5563,
"def shape_list(l,shape,dtype):\n    \"\"\" Shape a list of lists into the appropriate shape and data type \"\"\"\n    return np.array(l, dtype=dtype).reshape(shape)": 2814,
"def random_str(size=10):\n    \"\"\"\n    create random string of selected size\n\n    :param size: int, length of the string\n    :return: the string\n    \"\"\"\n    return ''.join(random.choice(string.ascii_lowercase) for _ in range(size))": 276,
"def try_cast_int(s):\n    \"\"\"(str) -> int\n    All the digits in a given string are concatenated and converted into a single number.\n    \"\"\"\n    try:\n        temp = re.findall('\\d', str(s))\n        temp = ''.join(temp)\n        return int(temp)\n    except:\n        return s": 5603,
"def column_names(self, table):\n      \"\"\"An iterable of column names, for a particular table or\n      view.\"\"\"\n\n      table_info = self.execute(\n        u'PRAGMA table_info(%s)' % quote(table))\n      return (column['name'] for column in table_info)": 2535,
"def get_files(dir_name):\n    \"\"\"Simple directory walker\"\"\"\n    return [(os.path.join('.', d), [os.path.join(d, f) for f in files]) for d, _, files in os.walk(dir_name)]": 2992,
"def _get_str_columns(sf):\n    \"\"\"\n    Returns a list of names of columns that are string type.\n    \"\"\"\n    return [name for name in sf.column_names() if sf[name].dtype == str]": 1858,
"def as_dict(self):\n        \"\"\"Return all child objects in nested dict.\"\"\"\n        dicts = [x.as_dict for x in self.children]\n        return {'{0} {1}'.format(self.name, self.value): dicts}": 3775,
"def numpy(self):\n        \"\"\" Grabs image data and converts it to a numpy array \"\"\"\n        # load GDCM's image reading functionality\n        image_reader = gdcm.ImageReader()\n        image_reader.SetFileName(self.fname)\n        if not image_reader.Read():\n            raise IOError(\"Could not read DICOM image\")\n        pixel_array = self._gdcm_to_numpy(image_reader.GetImage())\n        return pixel_array": 1089,
"def define_macro(self, name, themacro):\n        \"\"\"Define a new macro\n\n        Parameters\n        ----------\n        name : str\n            The name of the macro.\n        themacro : str or Macro\n            The action to do upon invoking the macro.  If a string, a new\n            Macro object is created by passing the string to it.\n        \"\"\"\n\n        from IPython.core import macro\n\n        if isinstance(themacro, basestring):\n            themacro = macro.Macro(themacro)\n        if not isinstance(themacro, macro.Macro):\n            raise ValueError('A macro must be a string or a Macro instance.')\n        self.user_ns[name] = themacro": 4263,
"def timedelta_seconds(timedelta):\n    \"\"\"Returns the total timedelta duration in seconds.\"\"\"\n    return (timedelta.total_seconds() if hasattr(timedelta, \"total_seconds\")\n            else timedelta.days * 24 * 3600 + timedelta.seconds +\n                 timedelta.microseconds / 1000000.)": 4766,
"def string(value) -> str:\n        \"\"\" string dict/object/value to JSON \"\"\"\n        return system_json.dumps(Json(value).safe_object(), ensure_ascii=False)": 5541,
"def get_trace_id_from_flask():\n    \"\"\"Get trace_id from flask request headers.\n\n    :rtype: str\n    :returns: TraceID in HTTP request headers.\n    \"\"\"\n    if flask is None or not flask.request:\n        return None\n\n    header = flask.request.headers.get(_FLASK_TRACE_HEADER)\n\n    if header is None:\n        return None\n\n    trace_id = header.split(\"/\", 1)[0]\n\n    return trace_id": 1456,
"def gen_lower(x: Iterable[str]) -> Generator[str, None, None]:\n    \"\"\"\n    Args:\n        x: iterable of strings\n\n    Yields:\n        each string in lower case\n    \"\"\"\n    for string in x:\n        yield string.lower()": 5592,
"def insort_no_dup(lst, item):\n    \"\"\"\n    If item is not in lst, add item to list at its sorted position\n    \"\"\"\n    import bisect\n    ix = bisect.bisect_left(lst, item)\n    if lst[ix] != item: \n        lst[ix:ix] = [item]": 3348,
"def normalize_column_names(df):\n    r\"\"\" Clean up whitespace in column names. See better version at `pugnlp.clean_columns`\n\n    >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['Hello World', 'not here'])\n    >>> normalize_column_names(df)\n    ['hello_world', 'not_here']\n    \"\"\"\n    columns = df.columns if hasattr(df, 'columns') else df\n    columns = [c.lower().replace(' ', '_') for c in columns]\n    return columns": 6049,
"def mean(inlist):\n    \"\"\"\nReturns the arithematic mean of the values in the passed list.\nAssumes a '1D' list, but will function on the 1st dim of an array(!).\n\nUsage:   lmean(inlist)\n\"\"\"\n    sum = 0\n    for item in inlist:\n        sum = sum + item\n    return sum / float(len(inlist))": 1278,
"def mkhead(repo, path):\n    \"\"\":return: New branch/head instance\"\"\"\n    return git.Head(repo, git.Head.to_full_path(path))": 4425,
"def make_lambda(call):\n    \"\"\"Wrap an AST Call node to lambda expression node.\n    call: ast.Call node\n    \"\"\"\n    empty_args = ast.arguments(args=[], vararg=None, kwarg=None, defaults=[])\n    return ast.Lambda(args=empty_args, body=call)": 2067,
"def is_punctuation(text):\n    \"\"\"Check if given string is a punctuation\"\"\"\n    return not (text.lower() in config.AVRO_VOWELS or\n                text.lower() in config.AVRO_CONSONANTS)": 3520,
"def parse(self, data, mimetype):\n        \"\"\"\n        Parses a byte array containing a JSON document and returns a Python object.\n        :param data: The byte array containing a JSON document.\n        :param MimeType mimetype: The mimetype chose to parse the data.\n        :return: A Python object.\n        \"\"\"\n        encoding = mimetype.params.get('charset') or 'utf-8'\n\n        return json.loads(data.decode(encoding))": 2695,
"def get_data(self):\n        \"\"\"\n        Fetch the data field if it does not exist.\n        \"\"\"\n        try:\n            return DocumentDataDict(self.__dict__['data'])\n        except KeyError:\n            self._lazy_load()\n            return DocumentDataDict(self.__dict__['data'])": 2830,
"def synthesize(self, duration):\n        \"\"\"\n        Synthesize white noise\n\n        Args:\n            duration (numpy.timedelta64): The duration of the synthesized sound\n        \"\"\"\n        sr = self.samplerate.samples_per_second\n        seconds = duration / Seconds(1)\n        samples = np.random.uniform(low=-1., high=1., size=int(sr * seconds))\n        return AudioSamples(samples, self.samplerate)": 694,
"def seq_to_str(obj, sep=\",\"):\n    \"\"\"\n    Given a sequence convert it to a comma separated string.\n    If, however, the argument is a single object, return its string\n    representation.\n    \"\"\"\n    if isinstance(obj, string_classes):\n        return obj\n    elif isinstance(obj, (list, tuple)):\n        return sep.join([str(x) for x in obj])\n    else:\n        return str(obj)": 1439,
"def set_xlimits(self, min=None, max=None):\n        \"\"\"Set limits for the x-axis.\n\n        :param min: minimum value to be displayed.  If None, it will be\n            calculated.\n        :param max: maximum value to be displayed.  If None, it will be\n            calculated.\n\n        \"\"\"\n        self.limits['xmin'] = min\n        self.limits['xmax'] = max": 3834,
"def enable_ssl(self, *args, **kwargs):\n        \"\"\"\n        Transforms the regular socket.socket to an ssl.SSLSocket for secure\n        connections. Any arguments are passed to ssl.wrap_socket:\n        http://docs.python.org/dev/library/ssl.html#ssl.wrap_socket\n        \"\"\"\n        if self.handshake_sent:\n            raise SSLError('can only enable SSL before handshake')\n\n        self.secure = True\n        self.sock = ssl.wrap_socket(self.sock, *args, **kwargs)": 2787,
"def to_bytes(value):\n    \"\"\" str to bytes (py3k) \"\"\"\n    vtype = type(value)\n\n    if vtype == bytes or vtype == type(None):\n        return value\n\n    try:\n        return vtype.encode(value)\n    except UnicodeEncodeError:\n        pass\n    return value": 1377,
"def from_file(cls, file_path, validate=True):\n        \"\"\" Creates a Python object from a XML file\n\n        :param file_path: Path to the XML file\n        :param validate: XML should be validated against the embedded XSD definition\n        :type validate: Boolean\n        :returns: the Python object\n        \"\"\"\n        return xmlmap.load_xmlobject_from_file(file_path, xmlclass=cls, validate=validate)": 1677,
"def expandpath(path):\n    \"\"\"\n    Expand a filesystem path that may or may not contain user/env vars.\n\n    :param str path: path to expand\n    :return str: expanded version of input path\n    \"\"\"\n    return os.path.expandvars(os.path.expanduser(path)).replace(\"//\", \"/\")": 3524,
"def index():\n    \"\"\" Display productpage with normal user and test user buttons\"\"\"\n    global productpage\n\n    table = json2html.convert(json = json.dumps(productpage),\n                              table_attributes=\"class=\\\"table table-condensed table-bordered table-hover\\\"\")\n\n    return render_template('index.html', serviceTable=table)": 4050,
"def s3(ctx, bucket_name, data_file, region):\n    \"\"\"Use the S3 SWAG backend.\"\"\"\n    if not ctx.data_file:\n        ctx.data_file = data_file\n\n    if not ctx.bucket_name:\n        ctx.bucket_name = bucket_name\n\n    if not ctx.region:\n        ctx.region = region\n\n    ctx.type = 's3'": 1312,
"def list(self):\n        \"\"\"position in 3d space\"\"\"\n        return [self._pos3d.x, self._pos3d.y, self._pos3d.z]": 1270,
"def _num_cpus_darwin():\n    \"\"\"Return the number of active CPUs on a Darwin system.\"\"\"\n    p = subprocess.Popen(['sysctl','-n','hw.ncpu'],stdout=subprocess.PIPE)\n    return p.stdout.read()": 956,
"def get_dict_to_encoded_url(data):\n    \"\"\"\n    Converts a dict to an encoded URL.\n    Example: given  data = {'a': 1, 'b': 2}, it returns 'a=1&b=2'\n    \"\"\"\n    unicode_data = dict([(k, smart_str(v)) for k, v in data.items()])\n    encoded = urllib.urlencode(unicode_data)\n    return encoded": 2486,
"def smooth_gaussian(image, sigma=1):\n    \"\"\"Returns Gaussian smoothed image.\n\n    :param image: numpy array or :class:`jicimagelib.image.Image`\n    :param sigma: standard deviation\n    :returns: :class:`jicimagelib.image.Image`\n    \"\"\"\n    return scipy.ndimage.filters.gaussian_filter(image, sigma=sigma, mode=\"nearest\")": 374,
"def replace_list(items, match, replacement):\n    \"\"\"Replaces occurrences of a match string in a given list of strings and returns\n    a list of new strings. The match string can be a regex expression.\n\n    Args:\n        items (list):       the list of strings to modify.\n        match (str):        the search expression.\n        replacement (str):  the string to replace with.\n    \"\"\"\n    return [replace(item, match, replacement) for item in items]": 3362,
"def ranks(self, key, value):\n    \"\"\"Populate the ``ranks`` key.\"\"\"\n    return [normalize_rank(el) for el in force_list(value.get('a'))]": 4604,
"def is_valid_file(parser, arg):\n    \"\"\"Check if arg is a valid file that already exists on the file system.\"\"\"\n    arg = os.path.abspath(arg)\n    if not os.path.exists(arg):\n        parser.error(\"The file %s does not exist!\" % arg)\n    else:\n        return arg": 2931,
"def get_parent_dir(name):\n    \"\"\"Get the parent directory of a filename.\"\"\"\n    parent_dir = os.path.dirname(os.path.dirname(name))\n    if parent_dir:\n        return parent_dir\n    return os.path.abspath('.')": 415,
"def resize(self, size):\n        \"\"\"Return a new Image instance with the given size.\"\"\"\n        return Image(self.pil_image.resize(size, PIL.Image.ANTIALIAS))": 2018,
"def compute_boxplot(self, series):\n        \"\"\"\n        Compute boxplot for given pandas Series.\n        \"\"\"\n        from matplotlib.cbook import boxplot_stats\n        series = series[series.notnull()]\n        if len(series.values) == 0:\n            return {}\n        elif not is_numeric_dtype(series):\n            return self.non_numeric_stats(series)\n        stats = boxplot_stats(list(series.values))[0]\n        stats['count'] = len(series.values)\n        stats['fliers'] = \"|\".join(map(str, stats['fliers']))\n        return stats": 2783,
"def glpk_read_cplex(path):\n    \"\"\"Reads cplex file and returns glpk problem.\n\n    Returns\n    -------\n    glp_prob\n        A glpk problems (same type as returned by glp_create_prob)\n    \"\"\"\n    from swiglpk import glp_create_prob, glp_read_lp\n\n    problem = glp_create_prob()\n    glp_read_lp(problem, None, path)\n    return problem": 4588,
"def join(self):\n\t\t\"\"\"Note that the Executor must be close()'d elsewhere,\n\t\tor join() will never return.\n\t\t\"\"\"\n\t\tself.inputfeeder_thread.join()\n\t\tself.pool.join()\n\t\tself.resulttracker_thread.join()\n\t\tself.failuretracker_thread.join()": 1252,
"def one_hot2string(arr, vocab):\n    \"\"\"Convert a one-hot encoded array back to string\n    \"\"\"\n    tokens = one_hot2token(arr)\n    indexToLetter = _get_index_dict(vocab)\n\n    return [''.join([indexToLetter[x] for x in row]) for row in tokens]": 1405,
"def add_blank_row(self, label):\n        \"\"\"\n        Add a blank row with only an index value to self.df.\n        This is done inplace.\n        \"\"\"\n        col_labels = self.df.columns\n        blank_item = pd.Series({}, index=col_labels, name=label)\n        # use .loc to add in place (append won't do that)\n        self.df.loc[blank_item.name] = blank_item\n        return self.df": 27,
"def open_file(file, mode):\n\t\"\"\"Open a file.\n\n\t:arg file: file-like or path-like object.\n\t:arg str mode: ``mode`` argument for :func:`open`.\n\t\"\"\"\n\tif hasattr(file, \"read\"):\n\t\treturn file\n\tif hasattr(file, \"open\"):\n\t\treturn file.open(mode)\n\treturn open(file, mode)": 1796,
"def string_input(prompt=''):\n    \"\"\"Python 3 input()/Python 2 raw_input()\"\"\"\n    v = sys.version[0]\n    if v == '3':\n        return input(prompt)\n    else:\n        return raw_input(prompt)": 63,
"def parse(self):\n        \"\"\"\n        Parse file specified by constructor.\n        \"\"\"\n        f = open(self.parse_log_path, \"r\")\n        self.parse2(f)\n        f.close()": 1429,
"def format(x, format):\n    \"\"\"Uses http://www.cplusplus.com/reference/string/to_string/ for formatting\"\"\"\n    # don't change the dtype, otherwise for each block the dtype may be different (string length)\n    sl = vaex.strings.format(x, format)\n    return column.ColumnStringArrow(sl.bytes, sl.indices, sl.length, sl.offset, string_sequence=sl)": 3291,
"def selectnotnone(table, field, complement=False):\n    \"\"\"Select rows where the given field is not `None`.\"\"\"\n\n    return select(table, field, lambda v: v is not None,\n                  complement=complement)": 1092,
"def is_symbol(string):\n    \"\"\"\n    Return true if the string is a mathematical symbol.\n    \"\"\"\n    return (\n        is_int(string) or is_float(string) or\n        is_constant(string) or is_unary(string) or\n        is_binary(string) or\n        (string == '(') or (string == ')')\n    )": 4548,
"def ensure_hbounds(self):\n        \"\"\"Ensure the cursor is within horizontal screen bounds.\"\"\"\n        self.cursor.x = min(max(0, self.cursor.x), self.columns - 1)": 365,
"def create_ellipse(width,height,angle):\n    \"\"\"Create parametric ellipse from 200 points.\"\"\"\n    angle = angle / 180.0 * np.pi\n    thetas = np.linspace(0,2*np.pi,200)\n    a = width / 2.0\n    b = height / 2.0\n\n    x = a*np.cos(thetas)*np.cos(angle) - b*np.sin(thetas)*np.sin(angle)\n    y = a*np.cos(thetas)*np.sin(angle) + b*np.sin(thetas)*np.cos(angle)\n    z = np.zeros(thetas.shape)\n    return np.vstack((x,y,z)).T": 1016,
"def _sim_fill(r1, r2, imsize):\n    \"\"\"\n        calculate the fill similarity over the image\n    \"\"\"\n    bbsize = (\n        (max(r1[\"max_x\"], r2[\"max_x\"]) - min(r1[\"min_x\"], r2[\"min_x\"]))\n        * (max(r1[\"max_y\"], r2[\"max_y\"]) - min(r1[\"min_y\"], r2[\"min_y\"]))\n    )\n    return 1.0 - (bbsize - r1[\"size\"] - r2[\"size\"]) / imsize": 1294,
"def pass_from_pipe(cls):\n        \"\"\"Return password from pipe if not on TTY, else False.\n        \"\"\"\n        is_pipe = not sys.stdin.isatty()\n        return is_pipe and cls.strip_last_newline(sys.stdin.read())": 3248,
"def list_move_to_front(l,value='other'):\n    \"\"\"if the value is in the list, move it to the front and return it.\"\"\"\n    l=list(l)\n    if value in l:\n        l.remove(value)\n        l.insert(0,value)\n    return l": 1236,
"def _wrap(text, columns=80):\n    \"\"\"\n    Own \"dumb\" reimplementation of textwrap.wrap().\n\n    This is because calling .wrap() on bigger strings can take a LOT of\n    processor power. And I mean like 8 seconds of 3GHz CPU just to wrap 20kB of\n    text without spaces.\n\n    Args:\n        text (str): Text to wrap.\n        columns (int): Wrap after `columns` characters.\n\n    Returns:\n        str: Wrapped text.\n    \"\"\"\n    out = []\n    for cnt, char in enumerate(text):\n        out.append(char)\n\n        if (cnt + 1) % columns == 0:\n            out.append(\"\\n\")\n\n    return \"\".join(out)": 4399,
"def warn_if_nans_exist(X):\n    \"\"\"Warn if nans exist in a numpy array.\"\"\"\n    null_count = count_rows_with_nans(X)\n    total = len(X)\n    percent = 100 * null_count / total\n\n    if null_count > 0:\n        warning_message = \\\n            'Warning! Found {} rows of {} ({:0.2f}%) with nan values. Only ' \\\n            'complete rows will be plotted.'.format(null_count, total, percent)\n        warnings.warn(warning_message, DataWarning)": 5888,
"def list_to_csv(value):\n    \"\"\"\n    Converts list to string with comma separated values. For string is no-op.\n    \"\"\"\n    if isinstance(value, (list, tuple, set)):\n        value = \",\".join(value)\n    return value": 77,
"def disable_insecure_request_warning():\n    \"\"\"Suppress warning about untrusted SSL certificate.\"\"\"\n    import requests\n    from requests.packages.urllib3.exceptions import InsecureRequestWarning\n    requests.packages.urllib3.disable_warnings(InsecureRequestWarning)": 2308,
"def pdf(x, mu, std):\n    \"\"\"Probability density function (normal distribution)\"\"\"\n    return (1.0 / (std * sqrt(2 * pi))) * np.exp(-(x - mu) ** 2 / (2 * std ** 2))": 96,
"def is_orthogonal(\n        matrix: np.ndarray,\n        *,\n        rtol: float = 1e-5,\n        atol: float = 1e-8) -> bool:\n    \"\"\"Determines if a matrix is approximately orthogonal.\n\n    A matrix is orthogonal if it's square and real and its transpose is its\n    inverse.\n\n    Args:\n        matrix: The matrix to check.\n        rtol: The per-matrix-entry relative tolerance on equality.\n        atol: The per-matrix-entry absolute tolerance on equality.\n\n    Returns:\n        Whether the matrix is orthogonal within the given tolerance.\n    \"\"\"\n    return (matrix.shape[0] == matrix.shape[1] and\n            np.all(np.imag(matrix) == 0) and\n            np.allclose(matrix.dot(matrix.T), np.eye(matrix.shape[0]),\n                        rtol=rtol,\n                        atol=atol))": 5774,
"def do_striptags(value):\n    \"\"\"Strip SGML/XML tags and replace adjacent whitespace by one space.\n    \"\"\"\n    if hasattr(value, '__html__'):\n        value = value.__html__()\n    return Markup(unicode(value)).striptags()": 3792,
"def center_text(text, width=80):\n    \"\"\"Center all lines of the text.\n\n    It is assumed that all lines width is smaller then B{width}, because the\n    line width will not be checked.\n\n    Args:\n        text (str): Text to wrap.\n        width (int): Maximum number of characters per line.\n\n    Returns:\n        str: Centered text.\n    \"\"\"\n    centered = []\n    for line in text.splitlines():\n        centered.append(line.center(width))\n    return \"\\n\".join(centered)": 156,
"def get_keys_from_class(cc):\n    \"\"\"Return list of the key property names for a class \"\"\"\n    return [prop.name for prop in cc.properties.values() \\\n            if 'key' in prop.qualifiers]": 387,
"def is_listish(obj):\n    \"\"\"Check if something quacks like a list.\"\"\"\n    if isinstance(obj, (list, tuple, set)):\n        return True\n    return is_sequence(obj)": 755,
"def is_image(filename):\n    \"\"\"Determine if given filename is an image.\"\"\"\n    # note: isfile() also accepts symlinks\n    return os.path.isfile(filename) and filename.lower().endswith(ImageExts)": 1636,
"def _preprocess(df):\n    \"\"\"\n    given a DataFrame where records are stored row-wise, rearrange it\n    such that records are stored column-wise.\n    \"\"\"\n\n    df = df.stack()\n\n    df.index.rename([\"id\", \"time\"], inplace=True)  # .reset_index()\n    df.name = \"value\"\n    df = df.reset_index()\n\n    return df": 4720,
"def sub(name, func,**kwarg):\n    \"\"\" Add subparser\n\n    \"\"\"\n    sp = subparsers.add_parser(name, **kwarg)\n    sp.set_defaults(func=func)\n    sp.arg = sp.add_argument\n    return sp": 2600,
"def print_err(*args, end='\\n'):\n    \"\"\"Similar to print, but prints to stderr.\n    \"\"\"\n    print(*args, end=end, file=sys.stderr)\n    sys.stderr.flush()": 3811,
"def unit_key_from_name(name):\n  \"\"\"Return a legal python name for the given name for use as a unit key.\"\"\"\n  result = name\n\n  for old, new in six.iteritems(UNIT_KEY_REPLACEMENTS):\n    result = result.replace(old, new)\n\n  # Collapse redundant underscores and convert to uppercase.\n  result = re.sub(r'_+', '_', result.upper())\n\n  return result": 1602,
"def mouse_move_event(self, event):\n        \"\"\"\n        Forward mouse cursor position events to the example\n        \"\"\"\n        self.example.mouse_position_event(event.x(), event.y())": 984,
"def service_available(service_name):\n    \"\"\"Determine whether a system service is available\"\"\"\n    try:\n        subprocess.check_output(\n            ['service', service_name, 'status'],\n            stderr=subprocess.STDOUT).decode('UTF-8')\n    except subprocess.CalledProcessError as e:\n        return b'unrecognized service' not in e.output\n    else:\n        return True": 235,
"def issuperset(self, items):\n        \"\"\"Return whether this collection contains all items.\n\n        >>> Unique(['spam', 'eggs']).issuperset(['spam', 'spam', 'spam'])\n        True\n        \"\"\"\n        return all(_compat.map(self._seen.__contains__, items))": 6019,
"def decode(self, bytes, raw=False):\n        \"\"\"decode(bytearray, raw=False) -> value\n\n        Decodes the given bytearray according to this PrimitiveType\n        definition.\n\n        NOTE: The parameter ``raw`` is present to adhere to the\n        ``decode()`` inteface, but has no effect for PrimitiveType\n        definitions.\n        \"\"\"\n        return struct.unpack(self.format, buffer(bytes))[0]": 5882,
"def as_list(self):\n        \"\"\"Return all child objects in nested lists of strings.\"\"\"\n        return [self.name, self.value, [x.as_list for x in self.children]]": 633,
"def _replace_nan(a, val):\n    \"\"\"\n    replace nan in a by val, and returns the replaced array and the nan\n    position\n    \"\"\"\n    mask = isnull(a)\n    return where_method(val, mask, a), mask": 1025,
"def check_key(self, key: str) -> bool:\n        \"\"\"\n        Checks if key exists in datastore. True if yes, False if no.\n\n        :param: SHA512 hash key\n\n        :return: whether or key not exists in datastore\n        \"\"\"\n        keys = self.get_keys()\n        return key in keys": 5872,
"def point8_to_box(points):\n    \"\"\"\n    Args:\n        points: (nx4)x2\n    Returns:\n        nx4 boxes (x1y1x2y2)\n    \"\"\"\n    p = points.reshape((-1, 4, 2))\n    minxy = p.min(axis=1)   # nx2\n    maxxy = p.max(axis=1)   # nx2\n    return np.concatenate((minxy, maxxy), axis=1)": 5215,
"def get_enum_from_name(self, enum_name):\n        \"\"\"\n            Return an enum from a name\n        Args:\n            enum_name (str): name of the enum\n        Returns:\n            Enum\n        \"\"\"\n        return next((e for e in self.enums if e.name == enum_name), None)": 4091,
"def add_arrow(self, x1, y1, x2, y2, **kws):\n        \"\"\"add arrow to plot\"\"\"\n        self.panel.add_arrow(x1, y1, x2, y2, **kws)": 3302,
"def clean_column_names(df: DataFrame) -> DataFrame:\n    \"\"\"\n    Strip the whitespace from all column names in the given DataFrame\n    and return the result.\n    \"\"\"\n    f = df.copy()\n    f.columns = [col.strip() for col in f.columns]\n    return f": 5616,
"def astensor(array: TensorLike) -> BKTensor:\n    \"\"\"Covert numpy array to tensorflow tensor\"\"\"\n    tensor = tf.convert_to_tensor(value=array, dtype=CTYPE)\n    return tensor": 5649,
"def _unzip_handle(handle):\n    \"\"\"Transparently unzip the file handle\"\"\"\n    if isinstance(handle, basestring):\n        handle = _gzip_open_filename(handle)\n    else:\n        handle = _gzip_open_handle(handle)\n    return handle": 1220
}